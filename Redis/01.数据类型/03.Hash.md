# 3 Redis-Hash

Redis 是一个 K-V 的数据存储系统, 通过 K 可以找到对应的 V。而 Hash 结构的话, 其 V 也是一个包含 K-V 的无序散列表。
在使用中, 可以通过 2 个 K 得到最终的 value (key - Field - Value)。 Hash 最终的这个 value 只能是字符串了, 不能是其他类型。而不像 Java 中的 Hash, 可以无限嵌套。

## 3.1 Hash 常用的一些命令

[Hash 常用命令](https://redis.io/commands#hash)

## 3.2 Hash 和 String 的区别
> 1. 可以把相关的值聚集到一个 key 中, 节省内存空间
> 2. 只使用一个 key, 减少 key 的冲突
> 3. 当需要批量获取值的时候, 只需要使用一个命令, 减少 内存 / IO / CPU 消耗

## 3.2 Hash 不适用的场景
> 1. 没法单独对 Field 设置过期时间, 设置过期时间的话, 所有的 Field 都会起作用
> 2. 没有 bit 操作
> 3. 数据分布不均匀 (value 值非常大的话, 无法分布到多个节点, Redis 的数据分布是通过 Key 实现)

## 3.3 Hash 的编码

Reids 中 Hash 类型的数据, 在实现上有 2 种 编码方式

> 1. ziplist (OBJ_ENCODING_ZIPLIST): 压缩列表
> 2. dict (OBJ_ENCODING_HT): 字典

## 3.4 ziplist

首先看一下官方的介绍

```
The ziplist is a specially encoded dually linked list that is designed
to be very memory efficient. It stores both strings and integer values,
where integers are encoded as actual integers instead of a series of
characters. It allows push and pop operations on either side of the list
in O(1) time. However, because every operation requires a reallocation of
the memory used by the ziplist, the actual complexity is related to the
amount of memory used by the ziplist.

ziplist 是一个经过特殊编码的内存高效的双向链表。
它同时存储字符串和整数值，其中整数被编码为实际整数，而不是一系列字符。
它允许在 O(1) 时间内对列表的两边进行 push 和 pop 操作。
但是, 因为每个操作都需要重新分配 ziplist 所使用的内存, 所以实际的复杂性与 ziplist 所使用的内存数量有关。
```

ziplist 是一个双向链表。但是它不存储指向上一个链表节点和指向下一个链表节点的指针, 而是存储上一个节点长度和当前节点长度。
通过牺牲部分读写性能, 来换取高效的内存空间利用率, 是一种时间换空间的思想。

### 3.4.1 ziplist 的实现逻辑

在 Redis 中, ziplist 虽然是一个双向链表, 却是通过一个 **char[]** 数组实现的, 先后遍历时, 借助在存储数据时冗余的上一个节点长度和当前节点长度, 计算后得到上下节点的位置。
所以, 在 Reids 中, **ziplist == char[]**。

首先明确一点, 在 C 语言中, char 类型只占 8 位 (这个很重要, 因为下面的内容基本都是会涉及到很多的字节内容), 整个 char[] 数组会被按照下面的格式进行划分。

![Alt 'ZipListCharArrFormat'](https://raw.githubusercontent.com/PictureRespository/MiddleWare/main/Redis/ZipListCharArrFormat.png)


其中的 entry 就是存储数据的元素。

整个 char[] 数组的划分如下:  
> 1. 0 ~ 3 位, 4 个字节, 叫做 **zlbytes**, 表示当前整个 ziplist 的字节长度, 也就是整个数组的长度, 因此压缩列表最多有 2^32 - 1 个字节
> 2. 4 ~ 7 位, 4 个字节, 叫做 **zltail**, 表示当前 ziplist 的起始位置到最后一个 entry 元素的起始位置相差的字节数, 也就是 ziplist 的起始位置 + zltail = ziplist 最后一个 entry 的起始位置 (简单理解就是, 数组的第几位是最后一个 entry 的开始位置)  
> 3. 8 ~ 9 位, 2 个字节, 叫做 **zllen**, 表示当前整个 ziplist 中的 entry 个数, 也就是整个 ziplist 最多有 2^16 - 1 个 entry
> 4. 10 ~ n 位, 字节数不定, 就是真正存储数据的 entry 集合
> 5. 最后 1 位, 1 个字节, 叫做 **zlend**, 表示整个 ziplist 的结束位, 固定为 0xFF (255, 1111 1111), 也就是 


#### 3.4.1.1 entry 

整个 ziplist 的大体布局了解完了, 看一下存储数据的 entry, 整个 entry 的话分成了 3 部分

> 1. previous_entry_length: 当前 entry 的前一个 entry 的占的字节长度
> 2. encoding: 当前 entry 存储的数据内容是什么类型, 大体有 2 种：整数和字节数组 (也就是字符串)
> 3. content： 真正存储的内容的地方

**previous_entry_length**  

表示前一个 entry 的字节长度，会占 1 个或者 5 个字节, 占的字节数取决于上一个 entry 的的字节长度。  
当前一个 entry 的长度小于 254 字节时，用 1 个字节表示。  
当前一个 entry 的长度大于或等于 254 字节时，用 5 个字节来表示, 这 5 个字节中第一个固定为 0xFE (254, 1111 1110)

**encoding**  

当前 entry 的编码, 不同的编码，表示后面的 content 是不同的内容, 会占 1, 2 或者 5 个字节, 占的字节取决于存储在当前 entry 内的内容的格式

| encoding 占的字节数 | encoding 的二进制 | 二进制的前 2 位的 | 表示的内容 |
| :-: | :-: | :-:| :-:|
| 1 |  00 bbbbbb |  00 | 长度最大为 63 的字节数组,  encoding 后面的 6 位用来存储字节数组的长度 |
| 1 |  1100 0000 |  11 | int_16 的整数 | 
| 1 |  1101 0000 | 11 | int 32 的整数 |
| 1 |  1110 0000 | 11 | int 64 的整数 |
| 1 |  1111 0000 | 11 | int 24 位的整数 |
| 1 |  1111 1110 | 11 | 8 位的整数 |
| 1 |  1111 bbbb | 11 | 后面的 bbbb 的取值范围为 0001 到 1101 (避免和上面的 24 位和 8 位整数的影响), 表示 1 - 13, 这个编码表示的是后面没有 content 字段, 值存储在 encoding 后面 4 位, 表示值为 0 - 12, 进制值减 1 |
| 2 | 01 bbbbbb aaaa aaaa | 01 |  长度最大为 2^14 - 1 的字节数组, 2 个字节的 encoding 后面的 14 位用来存储字节数组的长度 |
| 4 | 10_ bbbb bbbb aaaa aaaa cccc cccc dddd dddd  | 10 | 长度最大为 2^32 - 1 的字节数组, 5 个字节的 encoding 用后面的 4 个字节, 32 位用来存储字节数组的长度 | 

从上面的编码可以看出, encoding 的第一个字节的前二位可以确定后面 content 的数据类型了, 11xx xxxx 为整数, 不是 11xx xxxx 就是字节数组, 字节数组再判断前二位, 知道具体的长度类型, 最终得到了存储数据长度。

**content**
没什么好说的, 真正存储的数据。

#### 3.4.1.2 ZlEntry
通过上面的 entry 几个布局的分析可以知道, 整体的数据都是压缩在 entry 中的, 这个存储没问题, 但是在代码的处理中, 不可能说是需要用就进行一次解析, 比如需要内容的长度, 解析对应的 entry, 需要内容的具体值, 再解析对应的 entry。  
这个基本不实际, 一般都是直接将一个 entry 解析完成, 在整个方法域中都能起作用。在 Redis 中, entry 解析成的对象就是 ZlEntry, 解析后, 在整个方法的执行中都能通过这个 ZlEntry 获取到整个 entry 的内容。

ZlEntry 的定义  

```C
typedef struct zlentry {

    /** previous_entry_length 占用了多少个字节, 取值为 1 或者 5 */
    unsigned int prevrawlensize; 

    /** previous_entry_length 的表示的值 */
    unsigned int prevrawlen; 

    /** encoding 占用了多少个字节  1,2,5 */
    unsigned int lensize; 

    /** content 占用的字节数 */
    unsigned int len; 

    /** 
     * content 的数据类型, 用一些枚举替代, 不保存具体的值
     * 取值范围:
     * 0000 0000 长度最大为 63 的字节数组
     * 0100 0000 最大长度为 2^14 - 1 的字节数组 
     * 1000 0000 最大长度为 2^32 - 1 的字节数组
     * 1100 0000 整数
     */
    unsigned char encoding; 

    /** 头部的长度占用的长度, 等于 prevrawlensize + lensize */
    unsigned int headersize; 

    /** 当前 entry 在字节数组中的开始位置, 指向这个 entry 的指针开始 */
    unsigned char *p;

} zlentry;
```

在 Redis 的源码中, entry 解析为 zlentry 的方法有 2 个 **zipEntry** 和 **zipEntrySafe**, 2 个的逻辑的一样的, 不同的时,   
后面的 zipEntrySafe 会加上字节长度的校验, 确保当前 entry 的内容不会超过当前存储内容的 char[] 数组的长度。

下面的代码, 经过调整, 更容易理解, 所以和源码有点区别
```C

/**
 * @param p 就是需要解析的 entry 的指针地址, 转为为 Java 就是 可以理解为一个 int, 表示在 char[] 数组的这个位置 entry 的开始位置
 * @param e 就是一个 zlentry 的地址引用, 将解析后的结果存入到这个 zlentry
 */
void zipEntry(unsigned char *p, zlentry *e) {

    // 从 p 的开始位置, 也就是 previous_entry_length 的位置解析出 prevrawlensize 和 prevrawlen, 存入到 e 对应的位置
    zip_decode_prevlen(p, e->prevrawlensize, e->prevrawlen);

    // 从 p + prevrawlensize 的位置, 也就是到了encoding 的位置, 解析出 encoding,
    zip_entry_encoding(p + e->prevrawlensize, e->encoding)

    // 从 p + prevrawlensize 的位置, 也就是到了encoding 的位置, 解析出 encoding, lensize, len 存入到 e 对应的位置
    zip_decode_length(p + e->prevrawlensize, e-> encoding, e->lensize, e->len);

    // e 的 headersize 的值等于 prevrawlensize + lensize 的值
    e->headersize = e->prevrawlensize + e->lensize; 

    // e 的 p 值等于入参的 p 值, 也就是 entry 开始的位置
    e->p = p;
}

void zip_decode_prelen(ptr, prevlensize, prevlen) {

    // 解析 previous_entry_length 占的字节数
    // ZIP_BIG_PREVLEN = 0xfe, 1111 1110 
    // 上面说过了 previous_entry_length 的字节长度只有 1 和 5
    // 如果 5 个字节的话, 第一位必定是 0xfe
    // 所以 第一位如果是 0xfe, 那么 previous_entry_length 必定是 5 个字节, 否则就是 1 个字节
    (prevlensize) = (prt)[0] < ZIP_BIG_PREVLEN ? 1 : 5;

    if ((prevlensize) == 1) {
        // 1 个字节, 那么第一个字节就是 previous_entry_length 的值
        (prevlen) = (prt)[0]
    } else {
        // 不是 1 个字节, 那么就是 5 个字节, 取后面的 4 个字节拼接成一个 int 值
        (prevlen) = ((prt)[4] <<24)| ((prt)[3] <<16) | ((prt)[2] <<8)  | ((prt)[1])  
    }
}

void zip_entry_encoding(ptr, encoding) {

    // 注意此处的 ptr 不是 entry 的开始位置, 而是 entry + previous_entry_length 后的位置, 也就是 encoding 的开始位置
    // encoding 等于当前 encoding 的第一个字节
    (encoding) = ((ptr)[0]);

    // ZIP_STR_MASK = 0xc0, 二进制 1100 0000
    // 当前 ptr[0] 小于 1100 0000, 表示 encoding 当前表示的是字节数组
    if ((encoding) < ZIP_STR_MASK) {
        // encoding & 1100 0000, 只取前 2 位, 即可
        (encoding) &= ZIP_STR_MASK; 
    }
}

void zip_decode_length(ptr, encoding, lensize, len) {

    // encoding < 1100 0000, 字节数组
    if ((encoding) < ZIP_STR_MASK) {  

        if ((encoding) == ZIP_STR_06B) {

            // ZIP_STR_06B = 0, 二进制 0000 0000
            // 结果: 字节数组, 长度最大为 63 的字节数组, encoding 只需要使用 1 个字节存储
            (lensize) = 1;                                            
            // 0x3f = 63, 二进制 0011 1111, & 上 0011 1111, 得到 encoding 去掉前 2 位后的值, 也就是 content 的字节长度          
            (len) = (ptr)[0] & 0x3f; 

        } else if ((encoding) == ZIP_STR_14B) {  

            // ZIP_STR_14B = 64, 二进制 0100 0000
            // 结果: 字节数组, 2^14 - 1 的字节数组, encoding 需要使用 2 个字节存储
            (lensize) = 2;                                             
            // 得到存储在 encoding 2 个字节中 content 字节长度        
            (len) = (((ptr)[0] & 0x3f) << 8) | (ptr)[1];

        } else if ((encoding) == ZIP_STR_32B) {

            // ZIP_STR_32B = 128, 二进制 10000000
            // 结果: 字节数组, 2^32 - 1 的字节数组, encoding 需要使用 5 个字节存储
            (lensize) = 5;  
            (len) = ((ptr)[1] << 24) | ((ptr)[2] << 16) | ((ptr)[3] <<  8) | ((ptr)[4]); 
        } else {

            // 异常情况处理
            (lensize) = 0;
            (len) = 0;
        }    

    } else {

        // 整数处理
        // 整数的话, 默认 encoding 只需要一个字节
        (lensize) = 1;

        // ZIP_INT_8B = 254, 二进制 11111110, 表示 8 位的整数, content 只需要 1 个字节
        if ((encoding) == ZIP_INT_8B)  (len) = 1; 
        
        // ZIP_INT_16B = 192, 二进制 1100 0000, 表示 16 位的整数, content 需要 2 个字节
        else if ((encoding) == ZIP_INT_16B) (len) = 2;                         
        
        // ZIP_INT_24B = 240, 二进制 1111 0000, 表示 24 位的整数, content 需要 3 个字节
        else if ((encoding) == ZIP_INT_24B) (len) = 3;  

        // ZIP_INT_32B = 208, 二进制 1101 0000, 表示 32 位的整数, content 需要 4 个字节
        else if ((encoding) == ZIP_INT_32B) (len) = 4;                         

        // ZIP_INT_64B = 224, 二进制 1110 0000, 表示 64 位的整数, content 需要 5 个字节
        else if ((encoding) == ZIP_INT_64B) (len) = 8; 

        // ZIP_INT_IMM_MIN = 241, 二进制 1111 0001 
        // ZIP_INT_IMM_MAX = 253, 二进制 1111 1101
        // 1111 0001 <= encoding <= 1111 1101, 没有 content，值直接存储在 encoding 
        else if (encoding >= ZIP_INT_IMM_MIN && encoding <= ZIP_INT_IMM_MAX)
            (len) = 0;
        else 
        // 异常情况处理
            (lensize) = (len) = 0;    
    }
}
```

上面的就是 entry 解码为 zlentry 的过程, 同样的 zlentry 编码为 entry， 就是过程逆过来的处理, 就不展开了。

### 3.4.2 ziplist 节省的空间

我们可以知道 ziplist 是一个双向链表, 可以从 2 侧遍历。
通过 **zltail** 可以获取到最后一个 entry 的起始位置, 同时通过 entry 的 previous_entry_length 属性, 可以得到上一个 entry 的字节长度, 从而达到从后到前的遍历。  
而从 ziplist 的 char[] 数组的第 10 位开始就是第一个 entry, 通过解码每一个 entry, 获取到每一个 entry 的长度, 也可以得到下一个 entry 的开始位置, 从而达到从前往后的遍历。  
通过这种方式达到了用数组实现双向链表的操作。  
而之所以使用这种方式, 而不是正常的双向链表的, 就是这种方式虽然需要解码编码, 浪费了时间, 影响执行效率, 但是节省了空间, 那么节省了哪些空间呢?

传统的双向链表中的每一个节点需要
> 1. 指向前驱节点的指针, 64 位的系统中, 这个指针需要 8 个字节的内存
> 2. 执行后驱节点的指针, 同样是 8 个字节的内存
> 3. 节点中的内容指针, 指向存储的字符串的指针, 8 个字节
> 4. C 语言中, 字符串的特殊处理, 末尾加上 \0 的结束符
最终需要 25 个字节的辅助, 假设现在有 3 个字符串 **one**, **two**, **three**, 内存中的情况如下:

![Alt 'DoublyLnkedList.png'](https://raw.githubusercontent.com/PictureRespository/MiddleWare/main/Redis/DoublyLnkedList.png.png)

而通过上面的 entry 进行存储时
> 1. previous_entry_length: 受前面的 entry 的长度影响, 但是最大为 5 个字节
> 2. encoding: 受当前存储的 entry 的内容影响, 最大为 5 个字节
> 3. content: 可以不需要借助 \0 结束
所以最终最坏的情况需要 10 个字节的辅助。

### 3.4.3 ziplist 在使用上的一些情况

下面以插入 (伪代码) 为例, 进行分析
```C
/**
 * @param zl 插入的压缩列表
 * @param p 插入的位置指针, 原位置的 entry 变为当前插入 entry 的后一个节点
 * @param s 需要插入的字符串
 * @param slen 插入的字符串的长度
 */
unsigned char *ziplistInsert(unsigned char *zl, unsigned char *p, unsigned char *s, unsigned int slen) {

    // 向压缩列表插入元素有 4 种情况
	// 1. 列表没有数据的插入
	// 2. 列表有数据, 在尾部插入
	// 3. 列表有数据, 在中间插入
	// 4. 列表有数据, 在首部插入

    // 插入位置当前的 entry 的 previous_entry_length 占的字节数
    int prevlensize = 0;

    // 插入位置当前的 entry 的 previous_entry_length 的值, 也就是当前插入的位置前一个 entry 的字节长度
    int prevlen = 0;

    // ZIP_END = 0xff, 二进制 1111 1111
    if (p[0] != ZIP_END) {

        // 插入的位置不是压缩列表的尾部, 插入的情况 3, 4
        
        // 获取当前插入位置的 entry 的 previous_entry_length
        // 获取到的 prevlen 就等于插入 entry 的 previous_entry_length
        zip_decode_prevlen(p, prevlensize, prevlen);

    } else {

        // 插入的位置是压缩列表的尾部, 插入的情况 1，2

        // 获取到 zltail 指向的位置, zltail 一般指向的是最后一个 entry 的起始位置
        // 当没有 entry 在当前压缩列表, zltai 指向的位置就是 zllen, 值为 0xff
        char *ptail = getZlTailPos(zl);

        if (ptail[0] != ZIP_END) {

            // ptail 也就是 zltail 对应的位置的第一个字节不是 0xff, 表示插入的压缩列表有数据了, 情况 2
            // 获取 ptail 位置 entry 的字节长度, 也就是插入 entry 的 previous_entry_length
            prevlen = getPreEntryLength(zl, ptail);
        }
    }

    // 给予一个初始值, 避免警告, 同时给一个容易排查的值, 便于后面没有初始时排查
    long long value = 123456789;
    
    // 插入的 entry 的编码
    char encoding = 0;
    
    // 插入的 entry 的 content 需要的字节长度
    int reqlen = 0;

    // zipTryEncoding 的作用
    // 尝试将传入的 s 转为整数, 如果可以转换将转换后的值放到 value, 同时将其编码放到 encoding, 同时返回 true
    // 不能转换, 返回 false
    if (zipTryEncoding(s, slen, &value, &encoding)) {
        // 可以转换
        // 通过 encoding 获取当前的 int 需要的字节数, 也就是 content 的字节长度
        reqlen = zipIntSize(encoding);

    } else {
        // 不可以转换   
        // 那么字符串的长度是多少, 需要的字节数就是多少
        reqlen = slen;
    }

    // 加上上一个 entry 的长度
    // reqLen 的长度 = previous_entry_length + content
    reqlen += prevlen;

    // 加上当前的 encoding 需要的字节数
    // previous_entry_length + encoding + content, 这时候 reqLen 就是当前存储内容需要的字节数
    reqlen += getEncodingLength(encoding, slen);

    // 当前的位置已经有 entry 的情况
    // 插入的位置的当前的 entry, 将会变为插入 entry 的后一个 entry 
    // 那么当前的 entry 的 previous_entry_length 的字节数存储插入 entry 的字节长度 reqlen, 还需要多少个字节
    
    // 三种情况 4, -4, 0
    int nextdiff = (p[0] != ZIP_END) ? zipPrevLenByteDiff(p,reqlen) : 0;

    // 获取当前的压缩列表的字节长度
    int curlen = getZlbytes(zl);

    // 最新的压缩列表需要的在字节长度
    newlen = curlen + reqlen + nextdiff;

    // 按照新内存重新分配一个新的压缩列表, 会将旧的压缩列表的内容全部拷贝到新的压缩列表
    zl = ziplistResize(zl,newlen);

    // 更新 zlBytes 属性
    updateZlBytes(zl);
    // 更新 zlend 属性
    updateZlend(zl, newlen);

    // 插入的位置不是尾部, 需要迁移数据
    if (p[0] != ZIP_END) {

        // 空出一个 reqlen + nextdiff 的空间, 存放插入的 entry
        memmove(p+reqlen, p - nextdiff, curlen - offset - 1 + nextdiff);

        // 更新当前需要插入的位置的下一个 entry 的 previous_entry_length
        updateNextEntryPreviousEntryLength(p + reqlen, reqlen);

        // 更新 zlTail 属性
        updateZlTail(getZlTail() + reqlen + nextdiff);
    }

    // 当后一个 entry 的 previous_entry_length 的字节有变动, 进行连续更新的检查
    if (nextdiff != 0) {

        // 连续更新检查, 如果需要进行连续更新处理
        // 连续更新后面聊
        zl = ziplistCascadeUpdate(zl,p+reqlen);
    }

    // 更新当前 entry 的 previous_entry_length
    updateCurEntryPreviousEntryLength(p, prevlen);

    // 更新当前 entry 的 encoding
    updateCurEntryEncoding(p, encoding, slen);

    // 更新当前 entry 的 content
    if (zip2Str(encoding)) {
        // 字符串内容
        memcpy(p, s, slen);
    } else {
        // 整数内容
        zipSaveInteger(p, value, encoding);
    }

    // 更新 zlLen 属性
    updateZlLen(getZlLen() + 1);
    return zl;
}
```

从中可以看到整个新增的过程
> 1. 如果插入的位置, 后面有 entry, 获取插入位置的 entry 的 previous_entry_length, 这个就是等一下插入 entry 的 previous_entry_length 值
> 2. 如果插入的位置, 后面没有 entry, 需要获取到前一个 entry 的字节长度, 这个长度就是等一下插入 entry 的 previous_entry_length 值
> 3. 获取当前插入的 entry 的编码 encoding
> 4. 计算插入的 entry 需要的字节长度
> 5. 计算插入的 entry 需要的字节长度 存入到插入位置的 entry 的 previous_entry_length, 还需要多少个字节 (0, 4, -4)
> 6. 重新分配新的压缩列表, 更新 zlbytes, zlend
> 7. 将新分配的压缩列表的要插入位置后面的内容, 往后移动, 空出需要插入的 entry 的空间
> 8. 更新当前需要插入的位置的下一个 entry 的 previous_entry_length 为插入 entry 的字节长度
> 9. 更新新的压缩列表的 zltail
> 10. 当前需要插入的位置的下一个 entry 的 previous_entry_length 变动了, 进行连续更新的检查
> 11. 逐步将需要插入的 entry 的 previous_entry_length, encoding, content 更新到新的压缩列表
> 12. 更新新的压缩列表的 zllen

整个过程很复杂
> 1. 涉及到插入 entry 的解码, 编码
> 3. 新压缩列表的内存分配和旧数据的迁移
> 4. 新的 entry 的编码
> 5. 还有一个连续更新的问题

**连锁更新**

假设现在有一个列表 A(p_e_l=5) B(p_e_l=5) C(p_e_l=5), 这时候如果插入一个只需要 1 个字节的 entry,  
I(p_e_l=5) A(p_e_l=1) A 需要的字节数变小了, 假设刚好变为只需要 1 个字节，那么后面的 B 的 previous_entry_length 也需要变小,
导致 B 也变为只需要 1 个字节了, 导致 C 也需要变小, 从而引起了后面的连续更新

连锁更新会导致多次重新分配内存及数据复制，效率很低, 出现的情况在新增, 删除, 更新都有可能。   
但是出现这种情况的概率是很低的, 所以 Redis 并没有为了避免连锁更新而采取措施。

上面的就是新增 entry 的过程, 基本可以从这个过程推导出更新删除的过程。

## 3.5 dict

dict 字典, 其本质就是一个散列表 (hashtable), 只是在散列表的上面多做了一层封装。 

散列表, 用来存储**键值对**的一种数据结构。整体的实现和 Java 中的 HashMap 有很多相似的地方, 同样采用了数组加链表的形式存储数据, 在出现 hash 冲突时, 通过**拉链法**解决等。

> 1. 同样是用 1 个数组做出存储数据, 数据的每一个元素就是存储的数据
> 2. 新增时, 通过一个函数对 key 计算出一个 hash 值, 通过 hash 值模于数组的长度得到数据存储的位置
> 3. 出现 hash 冲突时, 也是通过拉链法解析冲突

正常情况下, 一个 hashtable 可以满足日常的使用了。但是在实际的代码中, Reids 将 hashtable 做多了一层的封装， 叫做字典 (Dictionary), 用于在一些特殊操作, 如扩容数据迁移等, 进行辅助操作。    
所以在实际中, Hash 的 OBJ_ENCODING_HT 的真正实现为字典。

整个 OBJ_ENCODING_HT 编码对应的实现 dict 的结构如下:

![Alt 'DictStructure'](https://raw.githubusercontent.com/PictureRespository/MiddleWare/main/Redis/DictStructure.png)

### 3.5.1 数据的封装对象 dictEntry

```C
typedef struct dictEntry {

    /** key 值, void 表示任意类型指针 */
    void *key;

    /** value 值, 是一个联合体, 在不同的场景下，选择不同的字段进行存储 */
    union {
        
        void *val;

        uint64_t u64;

        int64_t s64;

        double d;

    } v;

    /** 单链表, 下一个节点, 用于 hash 冲突*/
    struct dictEntry *next; 

} dictEntry;

```

上面就是 hashtable 中对数据进行封装的结构体 dictEntry。

### 3.5.2 hashtable 散列表的定义

```C
typedef struct dictht {

    /** 存储数据的数组 */
    dictEntry **table;

    /** table 数组的大小 */
    unsigned long size; 

    /** 掩码, 等于 size - 1 */
    unsigned long sizemask;

    /* table 数组已存元素个数，包含 next 单链表的数据 */
    unsigned long used; 
}
```

sizemask 字段用来计算键的索引值，sizemask 的值恒等于 size – 1。

Redis 中的 hashtable 和 Java 中的 HashMap 类似的。 存储数据的 table 的容量设定也是 2 的 n 次方, 每次扩容都是原来的 2 倍。  
size 在 二进制中必定是 1 {n 个 0}, 那么 sizemark 也就是 1 {n 个 1}。 那么 key 的 hash 值 & sizemask 的结果就等于 key 的 hash 值 % 数组的长度。

到此基本可以看出 dictht 的实现逻辑和 Java 中 HashMap 类似。

### 3.5.3 最终的结构字典 - dict 的定义

```C
typedef struct dict {

    /** 函数管理, 该字典对应的特定操作函数  */
    dictType *type;
    
    /** 该字典依赖的数据, 配合 type 字段指向的函数一起使用 */
    void *privdata;

    /** 一个字典有两个哈希表, 便于后面的扩容, 但一般情况下只会使用 ht[0], ht[1] 在扩容, 缩容时使用 */ 
    dictht ht[2]; 

    /** 重新扩容的标识,  == -1 表示不需要扩容, != -1, 代表扩容中的一些特殊情况 */
    long rehashidx;

    /** 当前正在使用的迭代器数量, 有迭代器在时, 不会进行 rehash 操作 */  
    unsigned long iterators; 

} dict;
```

上面的就是 OBJ_ENCODING_HT 编码最终的实现结构： 字典。

可以看出字典中有一个特殊属性 dictType， 他的定义如下:

```C
typedef struct dictType {

    /** 该字典对应的 Hash 函数 */
    uint64_t (*hashFunction)(const void *key); 

    /** key 对应的复制函数 */
    void *(*keyDup)(void *privdata, const void *key); 

    /** value 对应的复制函数 */
    void *(*valDup)(void *privdata, const void *obj); 

    /** key 的比较函数 */
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);

    /** key 的销毁函数 */
    void (*keyDestructor)(void *privdata, void *key); 

    /** value 的销毁函数 */
    void (*valDestructor)(void *privdata, void *obj);
} dictType;

```

字典这个结构除了用来实现 k-v 数据的存储外, 还在很多地方用到。如 Redis 的哨兵模式中, 主从节点的管理就是通过字典进行保存的。

### 3.5.4 字典的一些操作

#### 3.5.4.1 字典的创建

```C
dict *dictCreate(dictType *type, void *privDataPtr) {

    // 分配内存
    dict *d = zmalloc(sizeof(*d));
    // 初始化
    _dictInit(d,type,privDataPtr);

    return d;
}


int _dictInit(dict *d, dictType *type, void *privDataPtr) {

    // 初始化第一个 hashtable
    _dictReset(&d->ht[0]);

    // 初始化第一个 hashtable
    _dictReset(&d->ht[1]);

    // 初始 type
    d->type = type;

    // 初始 privdata
    d->privdata = privDataPtr;
    
    // 初始 rehashidx
    d->rehashidx = -1;
    
    // 初始 iterators 
    d->iterators = 0;

    return DICT_OK;
}

static void _dictReset(dictht *ht) {
    ht->table = NULL;
    ht->size = 0;
    ht->sizemask = 0;
    ht->used = 0;
}
```

#### 3.5.4.2 查找元素

```C
dictFind(dict *d, const void *key){

    // hashtable 中没有数据
    if (d->ht[0].used + d->ht[1].used == 0) 
        return NULL;

    // 判断对应的 dic 的 rehashidex != -1
    if (dictIsRehashing(d)) 
        // 不等于 -1, 也就是在需要在 rehash 中, 那么先进入 rehash 操作
        _dictRehashStep(d);

    dictEntry *he;
    uint64_t h, idx, table;    

    //得到 key 的 Hash 值
    h = dictHashKey(d, key); 

    // 遍历 hashtable ht[0] 与 ht[1]
    for (table = 0; table <= 1; table++) {

        // 根据 Hash 值获取到对应的索引值
        idx = h & d->ht[table].sizemask; 
        
        // 得到对应的 dictEntry
        he = d->ht[table].table[idx];

        // 遍历 dictEntry
        while(he) {
            // key 相同 或者调用 key 比较函数结果为 ture
            if (key==he->key || dictCompareKeys(d, key, he->key))
                // 返回这个 dictEntry
                return he;
            // 遍历下一个 dictEntry    
            he = he->next;
        }

        // 如果未进行 rehash 操作，则只读取 ht[0]
        if (!dictIsRehashing(d)) 
            return NULL;
    }

    return NULL;
}

// 判断 dict 的 rehashidex != -1
int dictIsRehashing(d) {
    return (d)->rehashidx != -1;
}

// 调用 dict type 上面的 hashFunction 得到 hash 值
int dictHashKey(d, key) {
    (d)->type->hashFunction(key)
} 

// 调用 dict type 上面的 keyCompare 进行 key 的比较
int dictCompareKeys(d, key1, key2) {
    return ((d)->type->keyCompare) ? (d)->type->keyCompare((d)->privdata, key1, key2) :  (key1) == (key2);
}

// 对 dict 进行 rehash 操作
static void _dictRehashStep(dict *d) {
    
    // 迭代器为 0, 可以进行 rehash 操作
    if (d->iterators == 0) 
        // 后面 rehash 分析
        dictRehash(d,1);
}

```

#### 3.5.4.4 修改元素

```C
void dbOverwrite(redisDb *db, robj *key, robj *val) {

    // 查找 key 对应的 dictEntry 是否存在
    dictEntry *de = dictFind(db->dict, key->ptr); 
    
    // 不存在则中断执行
    serverAssertWithInfo(NULL,key,de != NULL); 

    // 获取旧值
    dictEntry auxentry = *de;

    //给节点设置新的值
    dictSetVal(db->dict, de, val); 

    // 释放节点中旧值内存
    dictFreeVal(db->dict, &auxentry);
}

void dictSetVal(d, entry, _val_) {

    // 如果 dict 的 type 上配置了 valDup 值复制函数, 调用复制函数, 否则直接设值
    if ((d)->type->valDup) 
        (entry)->v.val = (d)->type->valDup((d)->privdata, _val_);
    else 
        (entry)->v.val = (_val_);   
}
```

过程:
> 1. 调用 dictFind 查找键是否存在
> 2. 不存在则中断执行
> 3. 修改节点键值对中的值为新值
> 4. 释放旧值的内存

#### 3.5.4.5 添加元素

```C
int dictAdd(dict *d, void *key, void *val) { 

    // 添加 key 对应的 dictEntry 到字典中，字典中  key 已存在则返回 NULL，否则添加
    dictEntry *entry = dictAddRaw(d,key,NULL);

    // 添加失败, 已存在，返回失败
    if (!entry) 
        return DICT_ERR;

    // 设置对应的 dictEntry 的 value 赋值
    dictSetVal(d, entry, val);
    // 返回新增成功
    return DICT_OK;
}

// 尝试在字典需要 key 对应的 entry, 不存在的情况下, 新增一个 dictEntry
dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)

    // 先判断是否需要 rehash
    if (dictIsRehashing(d)) 
        _dictRehashStep(d);

    // 等于 -1: 对应的 key 在字典中找到了 或者 判断需要扩容但是扩容失败
    if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)
        return NULL;

    // 获取当前使用的 hashtable, 在 rehash 中, 把数据放到第二个 hashtable, 否则放在第一个
    ht = dictIsRehashing(d) ? &d->ht[1] : &d->ht[0];
    // 分配一个 dictEntry
    entry = zmalloc(sizeof(*entry));
    // 设置当前的 dictEntry 的下一个节点为当前数组对应位置的头节点
    entry->next = ht->table[index];
    // 设置数组的头节点为当前的节点
    ht->table[index] = entry;
    // 已有数据 + 1
    ht->used++; 

    // 给 dictEntry 的 key 赋值
    dictSetKey(d, entry, key);
    return entry;   

}

// 尝试从字典中找到对应的 key 所在的位置
static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing) {

    // existing 有值, 先置为空
    if (existing) 
        *existing = NULL;

    unsigned long idx, table;

    dictEntry *he;

    // 是否需要扩容的判断, 如果需要, 方法内也会进行扩容
    if (_dictExpandIfNeeded(d) == DICT_ERR)
        return -1;

    //  dictFind 的逻辑   
    for (table = 0; table <= 1; table++) {

        idx = hash & d->ht[table].sizemask;
        he = d->ht[table].table[idx];

        while(he) {
            if (key==he->key || dictCompareKeys(d, key, he->key)) {
                if (existing) 
                    *existing = he;
                return -1;
            }
            he = he->next;
        }

        if (!dictIsRehashing(d)) 
            break;
    }
    return idx;
}

// 扩容判断
static int _dictExpandIfNeeded(dict *d) {

    // dict 的 rehashidx 不等于 -1, 不在 rehash 中, 直接返回
    if (dictIsRehashing(d)) 
        return DICT_OK;

    // 下面是 rehashidex == -1, 正常情况

    // 第一个 hashtable 为数据量为空, 进入扩容
    if (d->ht[0].size == 0) 
        // 容量初始化, DICT_HT_INITIAL_SIZE = 4
        // 扩容函数, 后面扩容分析
        return dictExpand(d, DICT_HT_INITIAL_SIZE);

    // dict_can_resize 默认为 1, dict_force_resize_ratio = 5
    // 已有的元素数量 >= hashtable 数组的个数  并且
    // dict_can_resize (能够扩容) 为 true 或者  hashtable 的元素个数是 hashtable 数组个数的 5 倍以上
    // 进行扩容
    if (d->ht[0].used >= d->ht[0].size && (dict_can_resize || d->ht[0].used/d->ht[0].size > dict_force_resize_ratio)){
        return dictExpand(d, d->ht[0].used*2);
    }
    return DICT_OK;
}

// 给 dictEntry 的 key 赋值
void dictSetKey(d, entry, _key_) { 
    // dict 的 type 上面维护了 key 复制函数
    if ((d)->type->keyDup) 
        (entry)->key = (d)->type->keyDup((d)->privdata, _key_); 
    else 
        (entry)->key = (_key_); 
} 

// 给 dictEntry 的 value 赋值
void dictSetVal(d, entry, _val_) {
    // dict 的 type 上面维护了 value 复制函数
    if ((d)->type->valDup)
        (entry)->v.val = (d)->type->valDup((d)->privdata, _val_);
    else 
        (entry)->v.val = (_val_);
}
```

从上面的 **_dictExpandIfNeeded**, 可以看出扩容的时机
> 1. 正常情况 (dict_can_resize 为 1), 第一个 hashtable 的已有的数据 >= 第一个 hashtable 的容量
> 2. 非正常情况 (dict_can_resize 为 0), 第一个 hashtable 的已有的数据的第一个 hashtable 的容量的 dict_force_resize_ratio 倍 (默认为 5 倍)

#### 3.5.4.6 扩容

初始一个是当前 d->ht[0] 容量 2 倍的 hashtable, 设置到 d->ht[1]。

此后，新添加的键值对都往新的 hashtable 中存储。   
而修改, 删除, 查找操作需要在 ht[0] 和 ht[1] 中进行检查, 然后再决定去对哪个 hashtable 操作。  
同时, 把老 hashtable（ht[0]）中的数据重新计算索引值后全部迁移插入到新的 hashtable (ht[1])中，此迁移过程称作 rehash。

```C
int dictExpand(dict *d, unsigned long size) {

    // dict 的 rehashidx ！= -1 或者 dict 的第一个 hashtable 已有的数据量大于总的个数
    if (dictIsRehashing(d) || d->ht[0].used > size)
        return DICT_ERR;

    // 新的容量 = 旧容量 * 2
    unsigned long realsize = _dictNextPower(size);    

    // 当前第一个 hashtable 的容量 == 计算出来的容量
    if (realsize == d->ht[0].size) return DICT_ERR;

    // 新的 hashtable
    dictht n;
    
    // 初始
    n.size = realsize;
    n.sizemask = realsize-1;
    n.table = zcalloc(realsize*sizeof(dictEntry*));
    n.used = 0;

    // 当前第一个 hashtable 为空, 将初始出来的 hashtable 赋值给第一个 hashtable
    if (d->ht[0].table == NULL) {
        d->ht[0] = n;
        return DICT_OK;
    }

    // 第二个 hashtable 等于初始出来的 hashtable 
    d->ht[1] = n;
    
    // dict 的 rehashidex = 0， 不等于 -1 了, 表示需要渐进式 rehash 
    d->rehashidx = 0;
    return DICT_OK;
}
```

#### 3.5.4.7 渐进式 rehash

```C
/**
 * @param d 需要渐进 rehash 的字典
 * @param n 进行渐进 rehash 的步数, 也就是一次迁移多少个数组的元素
 */
int dictRehash(dict *d, int n) {

    /**  访问时遇到的最大空桶数 */
    int empty_visits = n*10;

    // dict 的 rehashidx == -1, 直接结束
    if (!dictIsRehashing(d)) 
        return 0;

    // 需要迁移的位数大于 0 同时 字典的第一个 hashtable 可用的元素还是不等于 0
    while(n-- && d->ht[0].used != 0) {

        // 第一个 hashtable 的容量需要大于字典的 rehashidx
        assert(d->ht[0].size > (unsigned long)d->rehashidx);

        // 遇到的位置为空
        while(d->ht[0].table[d->rehashidx] == NULL) {
            // 字典的 rehashidex + 1; 可以遇到的空桶次数 -1 
            d->rehashidx++;
            // 当可遇到的空桶数降到 0, 直接返回
            if (--empty_visits == 0) 
                return 1;
        }

        dictEntry *de, *nextde;
        // 获取对应位置的 dictEntry
        de = d->ht[0].table[d->rehashidx];

        // 遍历对应位置的 dictEntry 链表
        while(de) {

            uint64_t h;

            // 暂存当前 dictEntry 的下一个节点
            nextde = de->next;

            /** 计算当前 dictEntry 新的位置 */
            h = dictHashKey(d, de->key) & d->ht[1].sizemask;
            // 把当前的 dict 的下一个节点为对应位置的头结点
            de->next = d->ht[1].table[h];
            // 设置对应位置的头结点为当前节点
            d->ht[1].table[h] = de;
            // 第一个 hashtable 已有数据 - 1
            d->ht[0].used--;
            // 第二个 hashtable 已有数据 + 1
            d->ht[1].used++;
            // 当前的 dictEntry = 暂存的下一个节点
            de = nextde;
        }

        // 第一个 hashtable 对应的位置设置为 空
        d->ht[0].table[d->rehashidx] = NULL;
        // 字典的 rehashidx + 1
        d->rehashidx++;
    }

    // 第一个 hashtable 已有数据为 0 了
    if (d->ht[0].used == 0) {
        // 释放当前的第一个 hashtable
        zfree(d->ht[0].table);
        // 当前字段的第一个 hashtable 等于第二个 hashtable
        d->ht[0] = d->ht[1];
        // 重新分配第二个 hashtable
        _dictReset(&d->ht[1]);
        // 字典的 rehashidex = -1
        d->rehashidx = -1;
        return 0;
    }

    return 1;
}
```
上面就是 rehash 的整个过程

将第一个 hashtable 的数据依次重新计算 hash 放到第二个 hashtable 的位置, 每次 rehash 开始的位置由字典的 rehashidex 开始, 向后 n 位。
整个处理的过程中, 每处理了第一个 hashtable 数组的一位, rehashidex 加 1。  
在内部还做了优化, 遇到数组对应位置为空, 不算 n 的次数, 但是整个过程中遇到了 10 次空, 直接直接结束这次 rehash 操作。

可以看出整个字典的 rehash 操作是通过很多次进行的, 每次增删中都会先判断一下当前字典的 rehashidex 是否等于 -1, 也就是需要 rehash, 需要进行一次 rehash。  
避免了单线程的 Redis 花费大量的时间在 rehash 中。

同时在 Redis 中有一个定时器, 对数据库中第一个遇到的、可以进行 rehash 的字典进行一次批量 rehash 操作(每次对 100 个节点进行 rehash, 执行时间最大 1 毫秒)。  
整个的链路如下: serverCron -> incrementallyRehash -> dictRehashMilliseconds -> dictRehash

其实除了扩容时会导致 rehash, 字典其本身也会缩容的, 缩容情况下也会导致 rehash。  
在字典中, 已有的数据量 < 总数据量的 10%, 会进行缩容, 容量变为大于 used 的最小 2 的 n 次方整数。  
整个的链路如下: serverCron -> tryResizeHashTables -> -> htNeedsResize (判断是否需要缩容, used/size < 10%) ->dictResize -> dictExpand 容量变小, 后面和扩容一样的 rehash 操作


#### 3.5.4.8 删除元素

dict 的元素删除的话，根据上面的分析应该也能知道大体的流程了, 对应的源码为 dict.h 里面的 dictDelete 函数。这里就不展开了, 总结一下
> 1. 是否需要渐进 rehash 判断, 需要先进行 rehash 操作
> 2. 查找该键是否存在于该字典中
> 3. 存在则把该节点从单链表中剔除
> 4. 释放该节点对应的 key 和 value 和 dictEntry 自身所占用的内存
> 5. 字典的已有数据减 1 

### 3.5.5 字典的迭代器

在字典 dic 的定义中, 有个字段 **unsigned long iterators**, 表示当前字典正在使用的迭代器数量。
迭代器主要是用于遍历字典中的数据的, 但是在使用中可能出现: **只遍历数据**和**遍历的同时删除数据**, 这里可以简单了解一下迭代器的过程。


#### 3.5.5.1 迭代器的定义

```C
typedef struct dictIterator {

    /** 迭代器处理的字典 */
    dict *d;

    /** 当前迭代到 hashtable 数组中哪个位置 */
    int index;
    
    /** table 用于表示正在迭代的是哪个 hashtable, 即 ht[0] 与 ht[1] */
    /** safe 用于标识当前的迭代器是否为一个安全的迭代器 */
    int table, safe;

    /** 当前节点, 下一个节点 */
    dictEntry *entry, *nextEntry;

    /** 字典的指纹, 当字典未发生改变时，该值不变，发生改变时则值也随着改变 
     *  字典中所有字段值组合在一起生成的Hash值
     */
    long long fingerprint;
} dictIterator;
```

根据 safe 是否等于 0 和 1, 有 2 种不同的迭代器创建方式

```C
// 普通的迭代器
dictIterator *dictGetIterator(dict *d){

    dictIterator *iter = zmalloc(sizeof(*iter));

    iter->d = d;
    iter->table = 0;
    iter->index = -1;
    iter->safe = 0;
    iter->entry = NULL;
    iter->nextEntry = NULL;
    return iter;
}

// 安全的迭代器
dictIterator *dictGetSafeIterator(dict *d) {
    
    dictIterator *i = dictGetIterator(d);
    i->safe = 1;
    return i;
}
```

#### 3.5.5.2 普通迭代器 - 只遍历数据

字典遍历的 dictNext 函数

```C
dictEntry *dictNext(dictIterator *iter){

    while (1) {

        // 当前迭代器遍历的 dictEntry 为空
        if (iter->entry == NULL) {
            
            // 第一次遍历
            // 遍历到的 index 位置的 entry 为空了

            // 获取到需要处理的字典
            dictht *ht = &iter->d->ht[iter->table];
            
            // 第一次遍历同时遍历的是第一个 hashtable
            if (iter->index == -1 && iter->table == 0) {

                // 安全迭代器, 对应的字典的迭代器数 +1
                if (iter->safe)
                    iter->d->iterators++;
                else
                    // 普通迭代器, 设置字典指纹
                    iter->fingerprint = dictFingerprint(iter->d);
            }

            iter->index++;

            // 索引已经到了对应 hashtable 的容量上限
            if (iter->index >= (long) ht->size) {
                // 在 rehash 中, 同时当前遍历的是第一个 hashtable 
                if (dictIsRehashing(iter->d) && iter->table == 0) {
                    // 开始遍历第二个 hashtable
                    iter->table++;
                    iter->index = 0;
                    ht = &iter->d->ht[1];
                } else {
                    // 结算遍历，后面返回 null
                    break;
                }
            }
            // 迭代器遍历的 entry 等于当前 hashtable 对应的索引位置
            iter->entry = ht->table[iter->index];
        } else {
            // 当前迭代器遍历的 dictEntry 为迭代器的下一个 dictEntry
            iter->entry = iter->nextEntry;
        }

        // 迭代器当前的 dictEntry 不为空
        if (iter->entry) {
            
            // 迭代器的下一个 dictEntry 为当前 dictEntry 的下一个节点
            iter->nextEntry = iter->entry->next;
            // 返回当前的 dictEntry
            return iter->entry;
        }
    }
    return NULL;
}

```


普通迭代器迭代数据的过程
> 1. 调用 dictGetIterator 函数初始化一个普通迭代器, 迭代器的 safe 为 0, 表示是普通迭代器
> 2. 循环调用字典的 dictNext 函数依次遍历字典中 hashtable 的节点，首次遍历时会通过 dictFingerprint 函数拿到当前字典的指纹值
> 3. 当调用 dictNext 函数遍历完字典所有数据，释放迭代器时会调用 dictFingerprint 函数再计算字典的指纹值，并与首次拿到的指纹值比较，不相等则输出异常 "===ASSERTION FAILED==="

普通迭代器通过步骤 1 和步骤 3 的指纹值对比，来限制整个迭代过程中只能进行迭代操作，即迭代过程中字典数据的 修改/添加/删除/查找等操作都不能进行,    
只能调用 dictNext 函数迭代整个字典，否则就报异常，由此来保证迭代器取出数据的准确性。

#### 3.5.5.3 安全迭代器 - 遍历的同时删除数据

安全迭代器和普通迭代器迭代数据原理类似，也是通过循环调用 dictNext 函数依次遍历字典中 hashtable 的节点。安全迭代器确保读取数据的准确性，不是通过限制字典的部分操作来实现的，而是通过限制
rehash 的进行来确保数据的准确性。

> 1. 调用 dictGetSafeIterator 函数初始化一个普通迭代器, 迭代器的 safe 为 1, 表示是安全迭代器
> 2. 循环调用字典的 dictNext 函数依次遍历字典中 hashtable 的节点，首次遍历时会给对应的字段的 iterators 加 1
> 3. 当调用 dictNext 函数遍历完字典所有数据，释放迭代器时会把字典中 iterators 字段进行 减 1 操作, 遍历结束

在修改/添加/删除/查找中, 判断到需要 rehash， 调用 _dictRehashStep 进行操作时, 如果 iterators 不等于 0, 不会进行 rehash 操作, 由此确 保了读取数据的准确性。  
安全迭代器是通过步骤 1 和步骤 3 中对字典的 iterators 字段进行修改，使得迭代过程中渐进式 rehash 操作被中断，由此来保证迭代器读取数据的准确性。


## 3.5 Hash 的使用场景

String 能够使用的场景, Hash 大部分情况也可以使用。

购物车: 用户 id 作为 redis 的 key, 物品 id 作为 field, 物品数量作为 value
> 1. 查询全部物品 hget 用户id
> 2. 物品加 1, hincr 
> 3. 物品减 1, hdecr 
> 4. 全选, hgetall
> 5. 商品数, hlen














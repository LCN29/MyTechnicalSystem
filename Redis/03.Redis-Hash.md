# 03. Redis-Hash

Redis 是一个 K-V 的数据存储系统, 通过 K 可以找到对应的 V。而 Hash 结构的话, 其 V 也是一个包含 K-V 的无序散列表。
在使用中, 可以通过 2 个 K 得到最终的 value (key - Field - Value)。 Hash 最终的这个 value 只能是字符串了, 不能是其他类型。而不像 Java
中的 Hash, 可以无限嵌套。

## 3.1 Hash 常用的一些命令

[Hash 常用命令](https://redis.io/commands#hash)

## 3.2 Hash 和 String 的区别
> 1. 可以把相关的值聚集到一个 key 中, 节省内存空间
> 2. 只使用一个 key, 减少 key 的冲突
> 3. 当需要批量获取值的时候, 只需要使用一个命令, 减少 内存/IO/CPU 消耗

## 3.2 Hash 不适用的场景
> 1. 没法单独对 Field 设置过期时间, 设置过期时间的话, 所有的 Field 都会其作用
> 2. 没有 bit 操作
> 3. 数据分布不均匀(value 值非常大的话, 无法分布到多个节点, Redis 的数据分布是通过 Key 实现)

## 3.3 Hash 存储 (实现) 原理

Reids 中 Hash 类型的数据, 在实现上有 2 种 编码方式

> 1. ziplist (OBJ_ENCODING_ZIPLIST): 压缩列表
> 2. hashtable (OBJ_ENCODING_HT): 哈希表格

### 3.3.1 ziplist

```
The ziplist is a specially encoded dually linked list that is designed
to be very memory efficient. It stores both strings and integer values,
where integers are encoded as actual integers instead of a series of
characters. It allows push and pop operations on either side of the list
in O(1) time. However, because every operation requires a reallocation of
the memory used by the ziplist, the actual complexity is related to the
amount of memory used by the ziplist.

ziplist 是一个经过特殊编码的内存高效的双向链表。
它同时存储字符串和整数值，其中整数被编码为实际整数，而不是一系列字符。
它允许在 O(1) 时间内对列表的两边进行 push 和 pop 操作。
但是, 因为每个操作都需要重新分配 ziplist 所使用的内存, 所以实际的复杂性与 ziplist 所使用的内存数量有关
```

ziplist 是一个双向链表。但是它不存储指向上一个链表节点和指向下一 个链表节点的指针, 而是存储上一个节点长度和当前节点长度。
通过牺牲部分读写性能, 来换取高效的内存空间利用率, 是一种时间换空间的思想。
只用在字段个数少, 字段值小的场景里面。

他的逻辑结构如下:

```C
<zlbytes> <zltail> <zllen> <entry> <entry> ... <entry> <zlend>
```

zlbytes : 压缩列表的字节长度, 占 4 个字节, 因此压缩列表最长 (2^32) - 1 字节  
zltail : 压缩列表尾元素相对于压缩列表起始地址的偏移量, 占 4 个字节  
zllen : 压缩列表的元素数目, 占两个字节; 那么当压缩列表的元素数目超过 (2^16) - 1 时, 此时通过 zllen 字段无法获得压缩列表的元素数目, 必须遍历整个压缩列表才能获取到元素数目  
entry : 压缩列表存储的若干个元素, 可以为字节数组或者整数  
zlend : 压缩列表的结尾, 占一个字节, 固定为 0xFF

#### 3.3.1.1 entry 的结构

entry 元素, 存储的可能是字节数组或整数值, 那么 entry 的结构是怎么样的呢

```C
typedef struct zlentry {

    /** 上一个链表节点占用的长度 */
    unsigned int prevrawlensize; 

    /** 存储上一个链表节点的长度数值所需要的字节数 */
    unsigned int prevrawlen; 

    /** 存储当前链表节点长度数值所需要的字节数 */
    unsigned int lensize;

    /** 当前链表节点占用的长度 */
    unsigned int len;

    /** 当前链表节点的头部大小 (prevrawlensize + lensize), 即非数据域的大小 */
    unsigned int headersize;

    /** 编码方式 */
    unsigned char encoding; 

    /** 指针指向当前节点起始位置 */
    unsigned char *p; 

} zlentry;
```

* prevrawlensize  

表示前一个元素的字节长度, 占 1 个或者 5 个字节  
当前一个元素的长度小于 254 字节时, previous_entry_length 字段用一个字节表示  
当前一个元素的长度大于等于 254 字节时, previous_entry_length 字段用 5 个字节来表示, 并且这时第一个字节是固定的标志 0xFE, 后面 4 个字节才真正表示前一个元素的长度

* encoding  

Redis 为了节省内存, 
encoding 表示当前元素的编码, 现在有 ZIP_STR_* 和 ZIP_INT_* 2 种类型, 既 encoding 可以表示字符串或者整形的数据类型, 而 content 存储真正的内容

为了节约内存, encoding 字段同样是可变长度, 同时对这个字段做了多重定义

| encoding长度 | encoding 编码| encoding 编码表示的数据类型 |
| :-:  | :-:  | :-: |
| 1 字节 |  00 xxxxxx (6 位表示存储内容长度)| 最大长度63的字节数组 |
| 2 字节 |  01 bbbbbb xxxxxxxx (14 位表示存储内容长度)| 最大长度(2^14)-1字节最大长度的字节数组 |
| 5 字节| 10__ aaaaaaaa bbbbbbbb cccccccc dddddddd (32 位表示存储内容长度) | 最大长度(2^32)-1的字节数组 |
| 1 字节 | 11 00 0000 | int16_t 类型整数 |
| 1 字节| 11 01 0000 | int32_t 类型整数 |
| 1 字节 | 11 10 0000 | int64_t 类型整数|
| 1 字节 | 11 11 0000 | 24 位整数 |
| 1 字节 | 11 11 1110 | 8 位整数 |
| 1 字节 | 11 11 xxxx| 没有 content 字段; xxxx 表示 0 ~ 12 之间的整数 |

通过上面的 encoding 编码, 就可以推测出 content 的内容是什么类型, 大小等。
最后一种情况说明一下: 当 encoding 为 **1111 xxxx**, 内容一并存储在 encoding 中, 没有 content。而
xxxx 4位只能用于表示 0001 到 1101, 既 1 ~ 13 情况 (避免和上面的 24 位和 8 位整数的影响), 然后 - 1，就得到可以表示 0 ~ 12 的整数。

![Alt 'ZipListStructure'](https://raw.githubusercontent.com/PictureRespository/Redis/main/picture/ZipListStructure.png)


#### 3.3.1.2 什么时候使用 ziplist 存储

当 Hash 对象同时满足以下两个条件的时候, 使用 ziplist 编码:
> 1. 所有的键值对的健和值的字符串长度都小于等于 64 byte (一个英文字母 一个字节)
> 2. 哈希对象保存的键值对数量小于 512 个


这 2 个都可以通过 "redis.conf" 进行修改
```shell
hash-max-ziplist-value 64           // ziplist 中最大能存放的值长度
hash-max-ziplist-entries 512        // ziplist 中最多能存放的 entry 节点数量
```


### 3.3.2 hashtable

在 Reids 中的 hashtable 和 Java 中的 HashMap 有很多相似的地方。 同样采用了数组加链表的形式存储数据, 在出现 hash 冲突时, 通过**拉链法**解决等。

Redis 是一个 K-V 的结构, 其中 K-V 都是通过 dictEntry 进行封装的。
而 Redis 对 dictEntry 有进行了多层封装, 从而形成了 hashtable.


首先是 dictEntry 本身的声明
```C
typedef struct dictEntry {
    
    /* key 关键字定义, 表示任意类型指针 */
    void *key;

    union {
        /* value 定义 */
        void *val;
        uint64_t u64;
        int64_t s64;
        double d;
    } v;

    /* 指向下一个键值对节点 */
    struct dictEntry *next;

} dictEntry;
```

dictht: dictEntry 的第一层封装

```C
typedef struct dictht {

    /** 哈希表数组 */
    dictEntry **table; 

    /** 哈希表大小 */
    unsigned long size;  
    
    /** 掩码大小，用于计算索引值。总是等于 size-1 */
    unsigned long sizemask;  
    
    /** 已有节点数 */
    unsigned long used; 
}
```

dict: dictht 的第一层封装, dictEntry 的第二层封装

```C
typedef struct dict {

    /** 函数管理  */
    dictType *type;
    
    /** 私有数据 */
    void *privdata;

    /** 一个字典有两个哈希表, 便于后面的扩容 */ 
    dictht ht[2]; 

    /** 重新扩容的标识,  == -1 表示不需要扩容 */
    long rehashidx;

    /** 当前正在使用的迭代器数量 */  
    unsigned long iterators; 
}
```

从最底层到最高层 dictEntry —— dictht —— dict

![Alt 'HashTableStructure'](https://raw.githubusercontent.com/PictureRespository/Redis/main/picture/HashTableStructure.png)


### 3.3.2.1 dict 为什么需要 2 个 dictht (dicthashtable)

redis 的 hash 默认使用的是 ht[0], ht[1] 不会初始化和分配空间。 当 hashtable 存储的元素过多, 可能由于碰撞也过多, 导致其中某条链表很长, 最后致使查找和插入时间复杂度很大。 因此当元素超过一定数量时, 需要扩容。当元素比较小的时候就需要缩容以节约不必要的内存。Redis 的作者定义这个操作叫做 rehash 操作, 通过 rehashidx 索引完成。

rehash 的步骤:
> 1. 为字符 ht[1] 哈希表分配空间, 这个哈希表的空间大小取决于要执行的操作, 以及 ht[0] 当前包含的键值对的数量。 扩容时, ht[1] = ht[0].used * 2。 收缩时, ht[1] = ht[0].used / 2;
> 2. 将所有的 ht[0] 上的节点 rehash 到 ht[1] 上, 重新计算 hash 值和索引, 然后放入指定的位置
> 3. 当 ht[0] 全部迁移到了 ht[1] 之后，释放 ht[0], 将 ht[1] 设置为 ht[0] 表, 并创建新的 ht[1], 为下次rehash 做准备

### 3.3.2.2 什么时候进行扩容

Redis **dict.c** 中声明了 2 个变量
```C
static int dict_can_resize = 1; 

/** 负载因子 */
static unsigned int dict_force_resize_ratio = 5;
```

当 dict_can_resize == 1 或者当 hashtable 中已使用的节点 / 当前 hasttable 的分配的节点大小 > 负载因子 dict_force_resize_ratio, 进行扩容。


### 3.3.2.3 渐进式 hash

为了避免在扩容时, ht[0] 中已经有大量数据, 如果直接对其进行 hash, 庞大的计算量可能会导致服务器在一段时间内停止服务。 服务器不是一次性将 ht[0 ]里面的所有键值对全部 rehash 到 ht[1], 而是 分多次, 渐进式地将 ht[0] 里面的键值对慢慢地 rehash 到 ht[1]。

> 1. 为 ht[1] 分配空间, 让字典同时持有 ht[0] 和 ht[1] 两个哈希表
> 2. 在字典中维持一个索引计数器变量 rehashidx，并将它的值设置为 0, 表示 rehash 工作正式开始
> 3. 在rehash进行期间, **每次对字典执行添加、删除、查找或者更新操作时, 程序除
了执行指定的操作以外**, 还会顺带将 ht[0] 哈希表在 rehashidx 索引上的所有键值对 rehash 到 ht[1], 当rehash 工作完成之后, 程序将 rehashidx + 1 (表示下次将 rehash 下一个桶)
> 4. 随着字典操作的不断执行, 最终在某个时间点上, ht[0] 的所有键值对都会被 rehash 至 ht[1], 这时程序将rehashidx 属性的值设为 -1, 表示 rehash 操作已完成

## 3.4 Hash 的使用场景

String 能够使用的场景, Hash 大部分情况也可以使用。

购物车

用户 id 作为 redis 的 key, 物品 id 作为 field, 物品数量作为 value

> 1. 查询全部物品 hget 用户id
> 2. 物品加 1, hincr 
> 3. 物品减 1, hdecr 
> 4. 全选, hgetall
> 5. 商品数, hlen

## 3.5 参考

[【Redis源码分析】Redis的压缩列表ZipList](https://segmentfault.com/a/1190000017328042)  
[Redis之字典(hashtable)](https://blog.csdn.net/u010710458/article/details/80604740)


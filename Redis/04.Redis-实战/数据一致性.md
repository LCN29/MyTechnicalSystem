# Redis - 数据一致性


## 1.1 缓存一致性问题

使用 Redis 作为缓存的时候, 一般流程是这样的

应用发起请求, 后台应用拿着 key 到 Redis 查询, (1) **命中缓存**, 返回 Redis 的存储结果, (2) **未命中缓存**, 到数据库查询, 查询到结果的话, 将结果写入 Redis, 返回数据库的存储结果。

因为这些数据是很少修改的, 所以在绝大部分的情况下可以命中缓存。  
但是, 一旦被缓存的数据发生变化的时候, 既要操作数据库的数据, 也要操作 Redis 的数据。  
现在我们有两种选择
> 1. 先操作 Redis 的数据再操作数据库的数据
> 2. 先操作数据库的数据再操作 Redis 的数据

无论哪种选择, 需要达到的效果都是 2 个操作同时成功。   
但是 Redis 的数据和数据库的数据是不可能通过事务达到统一的, 我们只能根据**相应的场景**和**所需要付出的代价**来采取一些措施降低数据不一致的问题出现的概率, 在数据一致性和性能之间取得一个权衡。




操作 Redis 数据的话, 可以在细分为 2 种
> 1. 直接更新 Redis
> 2. 直接删除 Redis, 后续在访问的时候, 进行填充

考虑更新缓存的代价

更新缓存之前, 是不是要经过其他表的查询, 接口调用, 计算才能得到最新的数据, 而不是直接从数据库拿到的值。  
如果是的话, 建议直接删除缓存, 这种方案更加简单, 而且避免了数据库的数据和缓存不一致的情况。 在一般情况下, 也推荐使用删除的方案。

### 先更新数据库，再删除缓存

异常情况: 
> 1. 更新数据库失败，程序捕获异常，不会走到下一步，所以数据不会出现不一致
> 2. 更新数据库成功，删除缓存失败。数据库是新数据，缓存是旧数据，发生了不一 致的情况

解决: **重试的机制**

1. 如果删除缓存失败，我们捕获这个异常，把需要删除的 key 发送到消息队列。 让后自己创建一个消费者消费，尝试再次删除这个 key, 会对业务代码造成入侵。
2. 异步更新缓存, 因为更新数据库时会往 binlog 写入日志，所以我们可以通过一个服务来监听 binlog 的变化（比如阿里的 canal），然后在客户端完成删除 key 的操作。如果删除失败的话， 再发送到消息队列


### 先删除缓存，再更新数据库

异常情况: 
> 1. 删除缓存，程序捕获异常，不会走到下一步，所以数据不会出现不一致
> 2. 删除缓存成功，更新数据库失败。 因为以数据库的数据为准，所以不存在数据 不一致的情况

线程 A 需要更新数据，首先删除了 Redis 缓存
线程 B 查询数据，发现缓存不存在，到数据库查询旧值，写入 Redis，返回
线程 A 更新了数据库

这个时候，Redis 是旧的值，数据库是新的值，发生了数据不一致的情况。

能不能让对同一条数据的访问串行化呢？  
代码肯定保证不了，因 为有多个线程，即使做了任务队列也可能有多个服务实例。数据库也保证不了，因为会有多个数据库的连接。只有一个数据库只提供一个连接的情况下，才能保证读写的操作是串行的，或者我们把所有的读写请求放到同一个内存队列当中，但是这种情况吞吐量太低了。

所以我们有一种延时双删的策略，在写入数据之后，再删除一次缓存。

删除缓存
更新数据库
休眠 500ms（这个时间，依据读取数据的耗时而定）
再次删除缓存


## 高并发

有两种情况可能会导致热点问题的产生: 
> 1. 一个是用户集中访问的数据，比如抢购的商品，明星结婚和明星出轨的微博
> 2. 在数据进行分片的情况下，负载不均衡，超过了单个服务器的承受 能力

热点问题可能引起缓存服务的不可用，最终造成压力堆积到数据库

### 3.1 热点数据发现

> 1. 在项目中手动统计 redis key 计算。这样每个地方都要修改, 重复代码较多, 同时只能统计当前客户端的热点 key
> 2. 在代理层进行统计, 比如 TwemProxy 和 Codis 
> 3. 通过 Redis 提供的功能, Redis 有个一个 monitor 的命令, 可以监控到 Redis 执行的命令

```Java
jedis.monitor(new JedisMonitor() {

    @Override
    public void onCommand(String command) {
        System.out.println("执行的命令" + command);
    }

});
```

Factbook 的 开源项目 redis-faina 就是基于这个原来实现的, 可以分析 moitor 的数据
```sh
redis-cli -p 6379 monitor | head -n 100000 | ./redis-faina.py
```

这种方法也有 2 个问题
> 1. monitor 命令在高并发的场景下, 会影响性能
> 2. 只能统计一个 Redis 节点的热点 key


>4. 机器层面
通过对 TCP 协议进行抓包, 同样也有一些开源软件 ELK 的 packetbeat 插件



热点数据在高并发下会出现的问题, 和解决方案

**缓存雪崩**  

Redis 的大量热点数据同时过期 (失效), 因为设置了相同的过期时间, 刚好这个时候 Redis 请求的并发量又很大, 导致所有的请求落到数据库

解决方案
> 1. 加互斥锁或者使用队列, 针对同一个 key 只允许一个线程到数据库查询
> 2. 缓存定时预先更新, 避免同时失效
> 3. 通过加随机数, 使 key 在不同的时间过期
> 4. 缓存永不过期

**缓存穿透**

在高并发下, 频繁地查询一个缓存和数据库中都没有的数据，由于缓存是不命中, 每次请求都落到了数据上，失去了缓存的意义。

解决方案
> 1. 缓存空数据
> 2. 缓存特殊字符串, 比如 &&

在缓存中缓存一个空字符串或者特殊的字符串, 在应用中里面可以拿到这个特殊字符串的时候, 就知道数据库没有值，就不需要再到数据库查询

注意: 需要给这个缓存添加一个过期时间, 不然在数据库新增了这条记录, 应用也还是拿不到值。

上面能解决的情况是 应用重复查询同一个不存在的值的情况。

如果应用每一次查询的不存在的值是不一样的呢？每次都缓存特殊字符串也没有作用。

解决 位图: 有序的数组, 只有 2 个值， 0： 代表数据不存在, 1: 代表存在

> 1. key 的长度是不固定的, 不同 key 的输入，可以得到固定长度的输出
> 2. 转换成下标的时候，希望在这个邮箱数组里面是分布均匀的。

解决 Hash 函数

问题 Hash 碰撞

不同的 key 经过计算后, 得到了同样的 hash 值, 在经过运算得到下标肯定是一样的，这种情况就是 hash 冲突或 hash 碰撞

解决方式
> 1. 扩大数组的长度, 也就是位图的容量, 函数是分布均匀的, 所以位图容量越大, 同一个位置发送 hash 发生碰撞的概率越低

但是越大的位图容量, 越大的内存消耗

> 2. 多个 不同的 hash 计算, 每次结果的位置都设置为 1 

填满位图的更多空间, 计算需要消耗时间



**布隆过滤器**

即使的多次 hash 计算，还是可能出现 hash 碰撞。三个 hash 函数，

对元素 a, 进行计算, 得到的 三次的位置都是为 1, 那么 a 这是会被判断为存在。但是这时候还是可能有误判性。Hash 碰撞是不可避免的

这种把本来不存在布隆过滤器中的元素误判为存在，这种情况称为 假阳性 (False Positive Probability, FPP)。

对元素 b, 进行计算, 得到的三次的位置为 1, 0, 1, 这是完全可以肯定 b 一定不存在。

布隆过滤器的特点
> 1. 如果布隆过滤器判断元素在集合中存在, 不一定存在
> 2. 如果布隆过滤器判断不存在，一定不存在
> 3. 如果元素实际存在, 布隆过滤器一定判断为存在
> 4. 如果元素实际不存在, 布隆过滤器可能判断为存在

基于第二个的特性， 可以解决缓存穿透的问题

例子 谷歌的 Guava 


项目启动时, 加载数据库中所有的数据库，

布隆在实例的使用中，先查询布隆，布隆说不存在, 那么一定不存在，如果说存在, 那么再走之前的流程


其他的使用场景， 爬虫，url 跑过了, 不需要爬了
邮箱服务器，发送垃圾邮件的账号叫做 spamer， 判断一个账号是不是为 spamer,


**缓存击穿**






## 分布式锁
> 1. 互斥 set nx
> 2. 死锁，超时
> 3. 持有锁的, 才能是否锁, 线程id
> 4. 可重入
> 5. 自动续期


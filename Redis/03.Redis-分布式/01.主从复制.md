# 1 Redis - 主从复制 (Replication)

## 1.1 为什么需要集群

* 性能  
Redis 本身的 QPS 已经很高了, 但是如果在一些并发量非常高的情况下, 性能还是会受到影响。这个时候可以借助更多的 Redis 服务来协助工作

* 扩展  
因为 Redis 所有的数据都放在内存中, 如果数据量大, 很容易受到硬件的限制。升级硬件收效和成本比太低, 需要有一种横向扩展的方法

* 可用性  
如果只有一个 Redis 服务, 一旦服务宕机，那么所有的客户端都无法访问, 会对业务造成很大的影响。另一个, 如果硬件发生故障, 而单机的数据无法恢复的话, 带来的影响也是灾难性的。

## 1.2  Redis 主从复制

将一台 Redis 服务器的数据, 复制到其他的 Redis 服务器。前者称为主节点 (master), 后者称为从节点 (slave)。  
数据的复制是单向的, 只能由主节点到从节点, 同时主节点以写为主 (可写也可以读), 从节点只能读不可写入。

### 1.2.1 主从复制的配置

假设
当前主节点为    192.168.0.1, 端口为 6379  
从节点 1 为     192.168.0.2, 端口为 6379  
从节点 2 为     192.168.0.3, 端口为 6379  

在 2 个从节点的 redis.conf 文件中追加 **slaveof 192.168.0.1 6379**
然后启动主节点, 在依次启动从节点, 这样一主两从的配置就完成了。

当然也可以不使用配置, 启动完成主节点好，在 2 个从节点启动的时候添加参数 **./redis-server --slaveof 192.168.0.1 6379**

从节点也可以使用 **slaveof no one** 脱离集群, 自身成为主节点。

最终可以通过 **info replication** 可以查看当前的集群信息

一主多从的特点:
> 1. 主节点挂了, 从节点依然还是从节点, 无法变为主节点
> 2. 主节点挂了, 重启后, 还是为主节点


### 1.2.2 主从复制流程

#### 1.2.2.1 连接阶段

**1. 保存主节点信息**

从节点服务器内部维护了两个字段, 即 masterhost 和 masterport 字段, 用于存储主节点的 ip 和 port 信息。

从节点启动时, 会将主节点的 ip 和 port 保存到下来。  
如果执行 slaveof 命令, 这是一个异步的命令, 会立即返回 OK, 然后后台将主节点的 ip 和 port 保存下来。


**2. 建立 socket 连接**

从节点内部有个定时任务 replicationCron (源码 replication.c), 每隔 1 秒钟检查是否有新的主节点要连接和复制, 如果发现, 就跟主节点建立 socket 网络连接, 如果连接成功了  

从节点: 为该 socket 建立一个专门处理复制工作的文件事件处理器, 负责后续的复制工作, 如接收 RDB 文件, 接收命令传播等  
主节点: 接收到从节点的 socket 连接后 (既 accept 之后), 为该 socket 创建相应的客户端状态, 并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行

**3. 发送 ping 命令**

从节点成为主节点的客户端之后, 会先发送 ping 命令进行首次请求, 目的是: 检查 socket 连接是否可用, 以及主节点当前是否能够处理请求。

从节点发送 ping 命令后, 可能出现 3 种情况:
> 1. 返回 pong: 说明 socket 连接正常, 且主节点当前可以处理请求, 复制过程继续。
> 2. 超时: 一定时间后从节点仍未收到主节点的回复, 说明 socket 连接不可用, 则从节点断开 socket 连接, 并重连
> 3. 返回 pong 以外的结果: 如果主节点返回其他结果, 如正在处理超时运行的脚本, 说明主节点当前无法处理命令, 则从节点断开 socket 连接, 并重连。

**4. 身份验证**  
如果从节点中设置了 masterauth 选项, 则从节点需要向主节点进行身份验证, 没有设置该选项, 则不需要验证。  
从节点进行身份验证是通过向主节点发送 auth 命令进行的, auth 命令的参数即为配置文件中的 masterauth 的值。

如果主节点设置密码的状态, 与从节点 masterauth 的状态一致 (一致是指都存在，且密码相同，或者都不存在), 则身份验证通过, 复制过程继续, 如果不一致, 则从节点断开 socket 连接, 并重连。

**5. 发送从节点端口信息**

身份验证之后, 从节点会向主节点发送其监听的端口号, 主节点将该信息保存到该从节点对应的客户端的 slave_listening_port 字段中。
该端口信息除了在主节点中执行 info Replication 时显示以外, 没有其他作用

#### 1.2.2.2 数据同步阶段

主从节点之间的连接建立以后, 便可以开始进行数据同步, 该阶段可以理解为从节点数据的初始化。  
具体执行的方式是: 从节点向主节点发送 psync 命令 (Redis 2.8 以前是 sync 命令), 开始同步。

数据同步阶段是主从复制最核心的阶段, 根据主从节点当前状态的不同, 可以分为**全量复制**和**部分复制**。这里涉及的内容比较多, 下面介绍。

#### 1.2.2.3 命令传播阶段

数据同步阶段完成后, 主从节点进入命令传播阶段。  
在这个阶段主节点将自己执行的写命令发送给从节点, 从节点接收命令并执行, 从而保证主从节点数据的一致性。

在命令传播阶段, 除了发送写命令, 主从节点还维持着心跳机制： **PING** 和 **REPLCONF ACK**。 
由于心跳机制的原理涉及部分复制, 因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。


**数据同步的延迟与不一致**  
命令传播是异步的过程, 即主节点发送写命令后并不会等待从节点的回复。 因此实际上主从节点之间很难保持实时的一致性, 延迟在所难免。数据不一致的程度, 与主从节点之间的网络状况, 主节点写命令的执行频率以及主节点中的 repl-disable-tcp-nodelay 配置等有关


**repl-disable-tcp-nodelay 配置作用**  
该配置作用于命令传播阶段, 控制主节点是否禁止与从节点的 TCP_NODELAY, 默认 no, 即不禁止 TCP_NODELAY。  
当设置为 yes 时, TCP 会对包进行合并从而减少带宽, 但是发送的频率会降低, 从节点数据延迟增加, 一致性变差。  
具体发送频率与 Linux 内核的配置有关, 默认配置为 40ms。当设置为 no 时, TCP 会立马将主节点的数据发送给从节点, 带宽增加但延迟变小。

一般来说, 只有当应用对 Redis 数据不一致的容忍度较高, 且主从节点之间网络状况不好时, 才会设置为 yes, 多数情况使用默认值 no。

### 1.2.2 数据同步阶段 - 数据复制模式

在 Redis 2.8 以前, 从节点向主节点发送 sync 命令请求同步数据, 此时的同步方式是全量复制。  
在 Redis 2.8 及以后, 从节点可以发送 psync 命令请求同步数据, 此时根据主从节点当前状态的不同, 同步方式可能是全量复制或部分复制。

> 1. 全量复制：用于初次复制或其他无法进行部分复制的情况, 将主节点中的所有数据都发送给从节点, 是一个非常重型的操作
> 2. 部分复制：用于网络中断等情况后的复制, 只将中断期间主节点执行的写命令发送给从节点, 与全量复制相比更加高效。需要注意的是, 如果网络中断时间过长, 导致主节点没有能够完整地保存中断期间执行的写命令, 则无法进行部分复制, 仍使用全量复制

#### 1.2.2.1 全量复制

Redis 通过 psync 命令进行全量复制的过程如下

1) 从节点判断无法进行部分复制, 向主节点发送全量复制的请求或从节点发送部分复制的请求, 但主节点判断无法进行部分复制 (具体的判断规则, 看部分复制部分)

2) 主节点收到全量复制的命令后, 执行 bgsave, 在后台生成 RDB 文件, 并使用一个缓冲区 (称为复制缓冲区) 记录从现在开始执行的所有写命令

3) 主节点的 bgsave 执行完成后, 将 RDB 文件发送给从节点 (如果超时了会重连, 可以调大 repl-timeout 的值)。从节点首先清除自己的旧数据, 然后载入接收的 RDB 文件, 将数据库状态更新至主节点执行 bgsave 时的数据库状态

4) 主节点将前述复制缓冲区中的所有写命令发送给从节点, 从节点执行这些写命令，将数据库状态更新至主节点的最新状态

5) 如果从节点开启了AOF, 则会触发 bgrewriteaof 的执行, 从而保证 AOF 文件更新至主节点的最新状态


从上面的步骤可以看出, 全量复制是一个很耗时的过程

> 1. 主节点通过 bgsave 命令 fork 子进程进行 RDB 持久化, 该过程是非常消耗 CPU, 内存(页表复制), 硬盘 IO 的
> 2. 主节点通过网络将 RDB 文件发送给从节点, 对主从节点的带宽都会带来很大的消耗
> 3. 从节点清空老数据, 载入新 RDB 文件的过程是阻塞的, 无法响应客户端的命令
> 4. 数据同步完成后, 从节点会执行 bgrewriteaof, 也会带来额外的消耗

#### 1.2.2.2 部分复制

部分复制的实现, 依赖于三个重要的概念

**1. 复制偏移量**  
主节点和从节点分别维护一个复制偏移量 (offset), 代表的是主节点向从节点传递的字节数。  
主节点每次向从节点传播 N 个字节数据时, 主节点的 offset 增加 N, 从节点每次收到主节点传来的 N 个字节数据时, 从节点的 offset 增加 N。

offset 用于判断主从节点的数据库状态是否一致: 如果二者 offset 相同, 则一致, 如果 offset 不同, 则不一致, 此时可以根据两个 offset 找出从节点缺少的那部分数据。  
例如, 如果主节点的 offset 是 1000, 而从节点的 offset 是 500, 那么部分复制就需要将 offset 为 501-1000 的数据传递给从节点。  
而 offset 为 501-1000 的数据存储的位置, 就是下面要介绍的复制积压缓冲区。

**2. 复制积压缓冲区**
复制积压缓冲区是由主节点维护的, 固定长度的, 先进先出 (FIFO) 队列, 默认大小 1MB。  
当主节点开始有从节点时创建, 其作用是备份主节点最近发送给从节点的数据 (无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区) 。

在命令传播阶段, 主节点除了将写命令发送给从节点, 还会发送一份给复制积压缓冲区, 作为写命令的备份。除了存储写命令, 复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量 (offset)。  
由于复制积压缓冲区定长且是先进先出, 所以它保存的是主节点最近执行的写命令, 时间较早的写命令会被挤出缓冲区。
由于该缓冲区长度固定且有限, 因此可以备份的写命令也有限, 当主从节点 offset 的差距过大超过缓冲区长度时, 将无法执行部分复制, 只能执行全量复制。  
反过来说, 为了提高网络中断时部分复制执行的概率, 可以根据需要增大复制积压缓冲区的大小 (可以通过 repl-backlog-size 配置)。

从节点将 offset 发送给主节点后, 主节点根据 offset 和缓冲区大小决定能否执行部分复制  
> 1. 如果 offset 偏移量之后的数据, 仍然都在复制积压缓冲区里, 则执行部分复制
> 2. 如果 offset 偏移量之后的数据已不在复制积压缓冲区中 (数据已被挤出), 则执行全量复制

**3. 服务器运行 ID (runid)**

每个 Redis 节点 (无论主从), 在启动时都会自动生成一个随机 ID (每次启动都不一样), 由 40 个随机的十六进制字符组成。   
runid 用来唯一识别一个 Redis 节点。通过 **info Server **命令, 可以查看节点的 runid。

主从节点初次复制时, 主节点将自己的 runid 发送给从节点, 从节点将这个 runid 保存起来。  
当断线重连时, 从节点会将这个 runid 发送给主节点, 主节点根据 runid 判断能否进行部分复制:  

> 1. 如果从节点保存的 runid 与主节点现在的 runid 相同, 说明主从节点之前同步过, 主节点会继续尝试使用部分复制 (到底能不能部分复制还要看 offset 和复制积压缓冲区的情况)
> 2. 如果从节点保存的 runid 与主节点现在的 runid 不同, 说明从节点在断线前同步的 Redis 节点并不是当前的主节点, 只能进行全量复制。

用于断线重连情况的兼容, 防止每次重连时都直接全量复制。


### 1.2.3 psync 命令的执行

![Alt 'RedisPsyncProcesses'](https://raw.githubusercontent.com/PictureRespository/Redis/main/picture/RedisPsyncProcesses.png)

如图

1) 首先, 从节点根据当前状态, 决定如何调用 psync 命令的参数  
* 如果从节点之前未执行过 slaveof 或最近执行了 slaveof no one, 则从节点发送命令为 **psync ? -1**, 向主节点请求全量复制  
* 如果从节点之前执行了 slaveof, 则发送命令为 **psync <runid> <offset>**, 其中 runid 为上次复制的主节点的 runid, offset 为上次复制截止时从节点保存的复制偏移量  

2) 其次, 主节点根据收到的 psync 命令, 及当前服务器状态, 决定执行全量复制还是部分复制  
* 如果主节点版本低于 Redis 2.8, 则返回 -ERR 回复, 此时从节点重新发送 sync 命令执行全量复制  
* 如果主节点版本够新, 且 runid 与从节点发送的 runid 相同, 且从节点发送的 offset 之后的数据在复制积压缓冲区中都存在, 则回复 CONTINUE, 表示将进行部分复制, 从节点等待主节点发送其缺少的数据即可  
* 如果主节点版本够新, 但是 runid 与从节点发送的 runid 不同, 或从节点发送的 offset 之后的数据已不在复制积压缓冲区中 (在队列中被挤出了), 则回复 **FULLRESYNC <runid> <offset>**, 表示要进行全量复制。  
其中 runid 表示主节点当前的 runid, offset 表示主节点当前的 offset, 从节点保存这两个值, 以备使用

### 1.2.3 心跳机制

**主节点向从节点发送 PING**
每隔指定的时间, 主节点会向从节点发送 PING 命令, 这个 PING 命令的作用, 主要是为了让从节点进行超时判断。  
PING 发送的频率由 **repl-ping-slave-period** 参数控制, 单位是秒, 默认值是 10s。


**从节点想住节点发送 REPLCONF ACK**
 
在命令传播阶段, 从节点会向主节点发送 REPLCONF ACK 命令, 频率是每秒 1 次, 命令格式为 **REPLCONF ACK {offset}**, 其中 offset 指从节点保存的复制偏移量。  

REPLCONF ACK 命令的作用包括
1) 实时监测主从节点网络状态: 该命令会被主节点用于复制超时的判断。  

在主节点中使用 **info Replication** 命令可以看到从节点的状态中的 lag 值, 代表的是主节点上次收到该 REPLCONF ACK 命令的时间间隔, 在正常情况下，该值应该是 0 或 1。 

2) 检测命令丢失: 从节点发送了自身的 offset, 主节点会与自己的 offset 对比, 如果从节点数据缺失 (如网络丢包), 主节点会推送缺失的数据 (这里也会利用复制积压缓冲区)。  

注意, offset 和复制积压缓冲区, 不仅可以用于部分复制, 也可以用于处理命令丢失等情形, 区别在于前者是在断线重连后进行的, 而后者是在主从节点没有断线的情况下进行的。

3）辅助保证从节点的数量和延迟: Redis 主节点中使用 min-slaves-to-write 和 min-slaves-max-lag 参数, 来保证主节点在不安全的情况下不会执行写命令。 

所谓不安全, 是指从节点数量太少, 或延迟过高。例如 min-slaves-to-write 和 min-slaves-max-lag 分别是 3 和 10, 含义是如果从节点数量小于 3 个, 或所有从节点的延迟值都大于 10 s, 则主节点拒绝执行写命令。 而这里从节点延迟值的获取, 就是通过主节点接收到 REPLCONF ACK 命令的时间来判断的, 即前面所说的 info Replication 中的 lag 值。

### 1.2.4 应用中的问题

#### 1.2.4.1 读写分离及其中的问题

**1. 延迟与不一致问题**

主从复制的命令传播是异步的，延迟与数据的不一致不可避免。  
优化措施: 优化主从节点之间的网络环境 (如同机房部署); 监控主从节点延迟 (通过 offset) 判断, 如果从节点延迟过大, 通知应用不再通过该从节点读取数据。使用集群同时扩展写负载和读负载等。

注:
在 Redis 从节点和主节点失去连接时, 也会造成大量的数据不一致。从节点提供了一个参数配置 **slave-serve-stale-data**, 它控制这种情况下从节点的表现, 默认值为 yes 表示从节点仍能够响应客户端的命令。  
如果为 no, 则从节点只能响应 info, slaveof 等少数命令。如果对数据一致性要求很高, 则应设置为 no。

**2. 数据过期问题**  

在单机版 Redis 中, 数据的过期策略为 **惰性策略** 和 **定期过期**。 在主从复制场景下, 为了主从节点的数据一致性, 从节点不会主动删除数据, 而是由主节点控制从节点中过期数据的删除。  
由于主节点的惰性删除和定期删除策略, 都不能保证主节点及时对过期数据执行删除操作。因此, 当客户端通过 Redis 从节点读取数据时, 很容易读取到已经过期的数据。

注:  
Redis 3.2 中, 从节点在读取数据时, 增加了对数据是否过期的判断: 如果该数据已过期, 则不返回给客户端

**3. 故障切换问题**

在一主一从或者一主多从的情况下, 如果主服务器挂了, 对外提供的服务就不可用了, 单点问题没有得到解决。   
应用针对读和写分别连接不同的 Redis 节点, 当主节点或从节点出现问题而发生更改时, 需要及时修改应用程序读写 Redis 数据的连接, 会影响到应用等。
Redis 服务端虽然可以手动把之前的从服务器切换成主服务器, 但是这是一个费时费力的操作, 还会造成一定时间的服务不可用。

**4. RDB 文件过大**
RDB 文件过大的情况下, 同步非常耗时, 在同步这个阶段, 从节点是无法提供服务的

#### 1.2.4.2 复制超时问题

主从节点复制超时是导致复制中断的最重要的原因之一。

**超时判断意义**  

1) 主节点判断连接超时   
会释放相应从节点的连接, 从而释放各种资源, 否则无效的从节点仍会占用主节点的各种资源 (输出缓冲区，带宽, 连接等)。  
此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全 (配合 min-slaves-to-write 参数)

2) 从节点判断连接超时  
可以及时重新建立连接，避免与主节点数据长期的不一致


**判断机制**

主从复制超时判断的核心, 在于 **repl-timeout** 参数, 该参数规定了超时时间的阈值 (默认 60s), 对于主节点和从节点同时有效

1) 主节点  
每秒 1 次调用复制定时函数 replicationCron(), 在其中判断当前时间距离上次收到各个从节点 REPLCONF ACK 的时间, 是否超过了 repl-timeout 值, 如果超过了则释放相应从节点的连接

2) 从节点  
> 1. 如果当前处于连接建立阶段, 且距离上次收到主节点的信息的时间已超过 repl-timeout, 则释放与主节点的连接
> 2. 如果当前处于数据同步阶段, 且收到主节点的 RDB 文件的时间超时, 则停止数据同步, 释放连接
> 3. 如果当前处于命令传播阶段, 且距离上次收到主节点的 PING 命令或数据的时间已超过 repl-timeout 值, 则释放与主节点的连接


**需要注意的坑**

1) 数据同步阶段  

在主从节点进行全量复制 bgsave 时, 主节点需要首先 fork 子进程将当前数据保存到 RDB 文件中, 然后再将 RDB 文件通过网络传输到从节点。  
如果 RDB 文件过大, 主节点在 fork 子进程 + 保存 RDB 文件时耗时过多, 可能会导致从节点长时间收不到数据而触发超时, 此时从节点会重连主节点, 然后再次全量复制, 再次超时, 再次重连。     
为了避免这种情况的发生, 除了注意 Redis 单机数据量不要过大, 另一方面就是适当增大 repl-timeout 值, 具体的大小可以根据 bgsave 耗时来调整


2) 命令传播阶段  
在该阶段主节点会向从节点发送 PING 命令, 频率由 repl-ping-slave-period 控制, 该参数应明显小于 repl-timeout 值 (后者至少是前者的几倍)。  
否则, 如果两个参数相等或接近, 网络抖动导致个别 PING 命令丢失, 此时恰巧主节点也没有向从节点发送数据, 则从节点很容易判断超时。


3) 慢查询导致的阻塞    
如果主节点或从节点执行了一些慢查询 (如 keys * 或者独爱大数据的 hgettall 等), 导致服务器阻塞。阻塞期间无法响应复制连接中对方节点的请求, 可能导致复制超时


#### 1.2.4.3 复制中断问题

主从节点超时是复制中断的原因之一, 除此之外, 还有其他情况可能导致复制中断, 其中最主要的是复制缓冲区溢出问题。

**复制缓冲区溢出**  
在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令
> 1. 主节点 bgsave 生成 RDB 文件
> 2. 主节点将 RDB 文件由主节点发往从节点
> 3. 从节点清空老数据并载入RDB文件中的数据

当主节点数据量较大, 或者主从节点之间网络延迟较大时, 可能导致该缓冲区的大小超过了限制, 此时主节点会断开与从节点之间的连接。  
这种情况可能引起 全量复制 -> 复制缓冲区溢出导致连接中断 -> 重连 -> 全量复制 -> 复制缓冲区溢出导致连接中断 …… 的循环

复制缓冲区的大小由 **client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}** 配置, 默认值为 **client-output-buffer-limit slave 256MB 64MB 60**,  
其含义是: 如果 buffer 大于 256MB, 或者连续 60s 大于 64MB, 则主节点会断开与该从节点的连接。该参数是可以通过 config set 命令动态配置的

**复制缓冲区**是客户端输出缓冲区的一种, 主节点会为每一个从节点分别分配复制缓冲区。   
**复制积压缓冲区**则是一个主节点只有一个，无论它有多少个从节点。


#### 1.2.4.4 各场景下复制的选择及优化技巧

**第一次建立复制**  

此时全量复制不可避免, 但仍有几点需要注意: 如果主节点的数据量较大, 应该尽量避开流量的高峰期, 避免造成阻塞。
如果有多个从节点需要建立对主节点的复制, 可以考虑将几个从节点错开, 避免主节点带宽占用过大。  
此外, 如果从节点过多, 也可以调整主从复制的拓扑结构, 由一主多从结构变为树状结构 (中间的节点既是其主节点的从节点，也是其从节点的主节点)。  
但使用树状结构应该谨慎: 虽然主节点的直接从节点减少, 降低了主节点的负担, 但是多层从节点的延迟增大, 数据一致性变差, 且结构复杂, 维护相当困难。

**主节点重启**

1) 主节点宕机  
主节点宕机重启后, runid 会发生变化, 因此不能进行部分复制, 只能全量复制。 

实际上在主节点宕机的情况下, 应进行故障转移处理, 将其中的一个从节点升级为主节点, 其他从节点从新的主节点进行复制, 且故障转移应尽量的自动化。

2) 安全重启: debug reload  
在一些场景下, 可能希望对主节点进行重启, 例如主节点内存碎片率过高, 或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点, 会使得 runid 发生变化, 可能导致不必要的全量复制。

为了解决这个问题, Redis 提供了 **debug reload** 的重启方式: 重启后, 主节点的 runid 和 offset 都不受影响, 避免了全量复制.

**从节点重启**

从节点宕机重启后, 其保存的主节点的 runid 会丢失, 因此即使再次执行 slaveof, 也无法进行部分复制

**网络中断**  

1) 网络问题时间极为短暂, 只造成了短暂的丢包, 主从节点都没有判定超时 (未触发repl-timeout), 此时只需要通过 REPLCONF ACK 来补充丢失的数据即可

2) 网络问题时间很长, 主从节点判断超时 (触发了 repl-timeout), 且丢失的数据过多, 超过了复制积压缓冲区所能存储的范围。 此时主从节点无法进行部分复制, 只能进行全量复制。  
为了尽可能避免这种情况的发生, 应该根据实际情况适当调整复制积压缓冲区的大小, 此外及时发现并修复网络中断, 也可以减少全量复制

3) 介于前述两种情况之间, 主从节点判断超时, 且丢失的数据仍然都在复制积压缓冲区中, 此时主从节点可以进行部分复制。

## 1.3 参考

[深入学习Redis（3）：主从复制](https://www.cnblogs.com/kismetv/p/9236731.html)
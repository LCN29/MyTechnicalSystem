# 2 AOF

AOF 全称: Append Only File, 是 Redis 提供了另一种数据保存模式,  Redis 默认不开启。  
AOF 采用日志的形式来记录每个写操作, 并追加到文件。开启后, 执行更改 Redis 数据的命令时, 就会把命令写入到 AOF 文件中。   
Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。

## 2.1 AOF 相关的配置

```sh
appendonly no                   # AOF 开关, 默认为关闭
appendfilename "appendonly.aof" # 保存的文件名
appendfsync everysec            # AOF 持久化策略 (硬盘缓存写入到硬盘) 
```

开启 AOF 后, 每天修改的命令都会存到 Redis 的一个缓存区。 缓存区的数据最终是需要写入到磁盘的, 而 Redis 是通过 **write** 函数, 将缓存中的数据写入到磁盘中。 
但是 **write** 函数实际是先将数据先保存到系统层级的缓存, 后续由系统自身将数据保存到磁盘, 系统默认为 30 秒保存一次。这样的话, 可能有风险, 如果系统直接宕机了
可能会丢失 30 秒左右的数据, 所以系统提供了一个 **fsync** 函数, 可以把系统层级的缓存立即写入到磁盘中, 但是这是一个阻塞且缓慢的操作, 会影响到执行的线程。


所以上面的配置的第 3 项就是控制这个 Redis 缓存到磁盘的行为
> 1. everysec: AOF 默认的持久化策略。每秒执行一次 fsync, 可能导致丢失 1s 数据, 这种策略兼顾了安全性和效率
> 2. no: 表示不执行 fsync, 由操作系统保证数据同步到磁盘, 速度最快, 但是不太安全
> 3. always: 表示每次写入到执行 fsync, 保证数据同步到磁盘, 效率很低

除了上面的 3 个基础配置, 还有几个关于 AOF 执行中的行为配置

```sh
# 默认为 100
# 当目前 AOF 文件大小超过上次重写的 AOF 文件的百分之多少进行重写 (重写的含义可以看下面的重写机制), 即当 AOF 文件增长到一定大小的时候, Redis 能够调用 bgrewriteaof 对日志文件进行重写
auto-aof-rewrite-percentag  100

# 默认为 64m
# 设置允许重写的最小 AOF 文件大小, 避免达到约定百分比但占用的容量仍然很小的情况就重写
auto-aof-rewrite-min-size  64mb

# 默认为 no
# 在 AOF 重写时, 是否不要执行 fsync, 将缓存写入到磁盘, 默认为 no。
# 如果对低延迟要求很高的应用, 这里可以设置为 yes, 否则设置为 no, 这样对持久化特性来说这是更安全的选择
# 设置为 yes 表示 rewrite 期间对新写操作不 fsync, 暂时存在内存中, 等 rewrite 完成后再写入
# 默认为 no, 建议改为 yes, 因为 Linux 的默认 fsync 策略为 30 秒, 所以可能丢失 30 秒数据
no-appendfsync-on-rewrite  no

# 默认为 yes
# 当 Redis 启动的时候, AOF 文件的数据会被重新载入内存
# 但是 AOF 文件可能在尾部是不完整的, 比如突然的断电宕机什么的, 可能导致 AOF 文件数据不完整
# 对于不完整的 AOF 文件如何处理
# 配置为 yes, 当截断的 AOF 文件被导入的时候, 会自动发布一个 log 给客户端, 然后继续加载文件中的数据
# 配置为 no, 用户必须手动 redis-check-aof 修复 AOF 文件才可以
aof-load-truncated yes
```

## 2.2 AOF 重写机制

由于 AOF 持久化是 Redis 不断将写命令记录到 AOF 文件中, 随着 Redis 不断的运行, AOF 文件将会越来越大, 占用服务器磁盘越来越大, 同时 AOF 恢复要求时间越长。  

为了解决这个问题, Redis 新增了重写机制, 当 AOF 文件的大小超过了所设定的阈值时, Redis 就会自动启动 AOF 文件的内容压缩, 只保留可以恢复数据的最小指令集。   
AOF 文件不是对原文件进行整理, 而是直接读取服务器现有的键值对, 然后用一条命令去代替之前记录这个键值对的多条命令, 生成一个新的文件替换原来的 AOF 文件。  

可以通过 **bgrewriteaof** 命令来手动触发 AOF 文件的重写, 也是通过子进程实现的。  
在子进程进行 AOF 重写时, 主线程需要保证
> 1. 处理客户端的请求
> 2. 将新增和更新命令追加到现有的 AOF 文件中
> 3. 将新增和更新命令追加到 AOF 重写缓存中

## 2.4 AOF 文件的优势和劣势

优势  
> 1. AOF 持久化的方法提供了多种的同步频率, 即使使用默认的同步频率每秒同步一次, Redis 最多也就丢失 1 秒的数据而已
> 2. AOF 日志文件以 append-only 模式写入, 所以没有任何磁盘寻址的开销, 写入性能非常高, 而且文件不容易受损, 即使文件尾部受损, 也能很容易恢复, 打开文件, 把后面损坏的数据删除即可

劣势  
> 1. 对于具有相同数据的的 Redis, AOF 文件通常会比 RDF 文件体积更大 (RDB 存的是数据快照) 
> 2. 虽然 AOF 提供了多种同步的频率, 默认情况下, 每秒同步一次的频率也具有较高的性能。在高并发的情况下, RDB 比 AOF 具好更好的性能保证

## 2.5 AOF 的过程

> 1. 所有的修改命令会追加到 Redis 的一个 AOF 缓存区
> 2. AOF 缓存区根据配置的策略向硬盘做同步操作
> 3. 随着 AOF 文件越来越大, 达到配置的条件, 对 AOF 文件进行重写, 达到压缩的目的

## 2.6 AOF 和 RDB  两种方案比较

如果可以忍受一小段时间内数据的丢失, 使用 RDB 是最好的, 定时生成 RDB 快照 (snapshot) 非常便于进行数据库备份, 并且 RDB 恢复数据集的速度也要 比 AOF 恢复的速度要快。 否则使用 AOF 重写。  
但是一般情况下建议不要单独使用某一种持久化机制, 而是应该两种一起用, 在这种情况下, 当 Redis 重启的时候会优先载入 AOF 文件来恢复原始的数据, 因为在通常情况下 AOF 文件保存的数据集要比 RDB 文件保存的数据集要完整。

在 Redis 4.0 带来了一个新的持久化选项 —— 混合持久化。将 RDB 文件的内容和增量的 AOF 日志文件存在一起。
这里的 AOF 日志不再是全量的日志, 而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志, 通常这部分 AOF 日志很小。

在 Redis 重启的时候, 可以先加载 RDB 的内容, 然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放, 重启效率因此大幅得到提升。

到此, AOF 的理论知识就没了, 下面是从源码进行分析。

## 2.7 AOF 文件结构

比如向 Redis 中写入一个 key 为 redis-key, value 为 redis-value 的字符串键值对后, 这对键值对在 AOF 文件的保存如下

```
*3\r\n$3\r\nset\r\n$9\r\nredis-key\r\n$11\r\nredis-value\r\n
```
以 `*数字` 的格式开始, 表示后面的命令的参数个数, 然后通过 `$数字` 表示后面参数的长度, 然后各个分隔之间通过 `\r\n` 进行分隔。  
Redis 中有多个数据库, 写入的数据是保存在哪个数据库的确定是会把 **select 数据库的编号** 这条命令也写入到文件中。

可以看到这种文本格式具有很高的可读性, 同时可以直接进行修改。

将 key 和 value 转换为上面的文件格式的实现是由 2 个函数实现的: catAppendOnlyGenericCommand 和 catAppendOnlyExpireAtCommand, 前者处理的是没有过期时间的键值对, 而后者处理的是设置过期时间的几个命令。

### 2.7.1 catAppendOnlyGenericCommand 

```C
/**
 * @param dst 当前未写入到文件的命令文本, 新的命令会追加到这个的后面
 * @param argc 命令参数的个数
 * @param argv 命令参数
 */
sds catAppendOnlyGenericCommand(sds dst, int argc, robj **argv) {

    char buf[32];
    int len, j;
    robj *o;

    // 命令开始的前缀为 *
    buf[0] = '*';
    // 计算出长度
    len = 1+ll2string(buf+1,sizeof(buf)-1,argc);
    // 追加 \r\n
    buf[len++] = '\r';
    buf[len++] = '\n';

    // 拼接到dst的后面
    dst = sdscatlen(dst,buf,len);

    // 拼接参数列表
    for (j = 0; j < argc; j++) {
        // 转为字符串类型
        o = getDecodedObject(argv[j]);
        buf[0] = '$';
        len = 1+ll2string(buf+1,sizeof(buf)-1,sdslen(o->ptr));
        buf[len++] = '\r';
        buf[len++] = '\n';
        dst = sdscatlen(dst,buf,len);
        dst = sdscatlen(dst,o->ptr,sdslen(o->ptr));
        dst = sdscatlen(dst,"\r\n",2);
        decrRefCount(o);
    }
    return dst;
}

/**
 * 如果入参的对象是 raw 或者 embstr 编码, 引用次数 + 1
 * 如果为 int 编码, 根据这个整数创建出一个字符串, 同时返回这个字符串
 * 其他类型不会处理
 */
robj *getDecodedObject(robj *o) {
    robj *dec;

    // 判断一个对象的编码是否为 OBJ_ENCODING_EMBSTR 或者 OBJ_ENCODING_RAW
    if (sdsEncodedObject(o)) {
        // 对象的引用次数还没达到最大值时, 进行引用次数 + 1
        incrRefCount(o);
        return o;
    }
    // 是字符串类型同时编码为 OBJ_ENCODING_INT
    if (o->type == OBJ_STRING && o->encoding == OBJ_ENCODING_INT) {

        char buf[32];
        // 整形转为 char 数组
        ll2string(buf,32,(long)o->ptr);
        // 转为字符串
        dec = createStringObject(buf,strlen(buf));
        return dec;
    } else {
        serverPanic("Unknown encoding type");
    }
}
```

### 2.7.2 catAppendOnlyExpireAtCommand

```C
/**
 * 处理哪些可以设置超时时间的键值对
 * @param buf 当前未写入到文件的命令文本, 新的命令会追加到这个的后面, 同时将命令修改为 pexpireat 的格式
 * @param cmd 执行的命令
 * @param key redis 的 key 值
 * @param second 过期的时间, 单位秒
 */
sds catAppendOnlyExpireAtCommand(sds buf, struct redisCommand *cmd, robj *key, robj *seconds) {

    long long when;
    robj *argv[3];

    // 转为字符串类型, 以便使用 strtoll 函数
    seconds = getDecodedObject(seconds);
    // 根据指定的进制将入参的 char 数组转为一个整数
    when = strtoll(seconds->ptr,NULL,10);

    // 当前执行的命令为 expire, setex expireat 将参数的秒转换成毫秒
    if (cmd->proc == expireCommand || cmd->proc == setexCommand || cmd->proc == expireatCommand) {
        when *= 1000;
    }

    // 将 expire, setex expireat 命令的参数，从相对时间设置为绝对时间
    if (cmd->proc == expireCommand || cmd->proc == pexpireCommand || cmd->proc == setexCommand || cmd->proc == psetexCommand) {
        when += mstime();
    }

    // 减少 second 的引用次数
    decrRefCount(seconds);

    // 拼接为 pexpireat key 超时时的时间戳
    argv[0] = createStringObject("PEXPIREAT",9);
    argv[1] = key;
    argv[2] = createStringObjectFromLongLong(when);

    buf = catAppendOnlyGenericCommand(buf, 3, argv);
    decrRefCount(argv[0]);
    decrRefCount(argv[2]);
    // 返回buf
    return buf;
}
```


## 1.5 代码实现

### 1.5.1 AOF - 触发入口

在上面有说过 AOF 的过程, 修改性质的命令会先写入到 Redis 的一个 AOF 缓存区。

首先这个缓存区的定义如下:

```C
struct redisServer {

    // 很简单就是一个字符串, 后面的命令追加到这个字符串的后面
    sds aof_buf; 

    // 重写缓存列表, 当前正在进行重写时, 会先把命令写入到这个链表, 待重写完成后, 在写入文件
    list *aof_rewrite_buf_blocks; 
}
```

重写缓存列表的节点定义如下

```C
typedef struct aofrwblock {

    // 下面的缓存数组已经使用的空间和剩余的空间
    unsigned long used, free;

    // AOF_RW_BUF_BLOCK_SIZE = 1024*1024*10
    // 用来缓存需要写入到文件的命令文本内容, 当数组所有空间使用完了, 会新建一个新的缓存节点
    char buf[AOF_RW_BUF_BLOCK_SIZE];

} aofrwblock;

```

AOF 的保存入口则在 call 函数中, 每条命令的执行函数都是通过 call 函数触发的

```C
void call(client *c, int flags) {

    // 省略

    c->cmd->proc(c);

    // 省略

    if (flags & CMD_CALL_PROPAGATE && (c->flags & CLIENT_PREVENT_PROP) != CLIENT_PREVENT_PROP) {
        
        // 省略

        if (propagate_flags != PROPAGATE_NONE && !(c->cmd->flags & CMD_MODULE))
            // 调用 propagate 进行命令的保存
            propagate(c->cmd,c->db->id,c->argv,c->argc,propagate_flags);
    }
}

void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc, int flags) {

    // AOF 保存
    if (server.aof_state != AOF_OFF && flags & PROPAGATE_AOF)
        feedAppendOnlyFile(cmd,dbid,argv,argc);
    
    // 主从节点复制    
    if (flags & PROPAGATE_REPL)
        replicationFeedSlaves(server.slaves,dbid,argv,argc);
}
```

上面就是 AOF 的执行入口, 而真正的 AOF 的过程的话就是 feedAppendOnlyFile 函数了

### 1.5.2 AOF - 命令写入缓冲区

```C
void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) {

    sds buf = sdsempty();
    robj *tmpargv[3];

    // 写入的数据库不是配置的, 手动加入一段, select 对应的数据库;
    if (dictid != server.aof_selected_db) {
        char seldb[64];

        snprintf(seldb,sizeof(seldb),"%d",dictid);
        buf = sdscatprintf(buf,"*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n", (unsigned long)strlen(seldb),seldb);
        server.aof_selected_db = dictid;
    }

    // expire/ pexpire / expireat 这三个命令
    if (cmd->proc == expireCommand || cmd->proc == pexpireCommand || cmd->proc == expireatCommand) {
        
        // 转为过期对应的文本
        buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);

    } else if (cmd->proc == setexCommand || cmd->proc == psetexCommand) {
        
        // setnx psetex 2 个命令拆分为 set 和 expireat 2 个命令
        tmpargv[0] = createStringObject("SET",3);
        tmpargv[1] = argv[1];
        tmpargv[2] = argv[3];

        // 将 SET 命令按协议格式追加到buf中
        buf = catAppendOnlyGenericCommand(buf,3,tmpargv);
        decrRefCount(tmpargv[0]);

        // 转为过期对应的文本
        buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);
    }  else if (cmd->proc == setCommand && argc > 3) {

        // set 命令同时参数大于 3 个 也就是带有超时时间了

        int i;
        robj *exarg = NULL, *pxarg = NULL;
        
        // 同样是, 先写入 set 命令
        buf = catAppendOnlyGenericCommand(buf,3,argv);

        // 计算后面的超时时间
        for (i = 3; i < argc; i ++) {
            if (!strcasecmp(argv[i]->ptr, "ex")) exarg = argv[i+1];
            if (!strcasecmp(argv[i]->ptr, "px")) pxarg = argv[i+1];
        }
        serverAssert(!(exarg && pxarg));

        // 根据配置的超时时间, 设置文本
        if (exarg)
            buf = catAppendOnlyExpireAtCommand(buf,server.expireCommand,argv[1], exarg);
        if (pxarg)
            buf = catAppendOnlyExpireAtCommand(buf,server.pexpireCommand,argv[1], pxarg);
    } else {
        
        // 其他的命令直接追加
        buf = catAppendOnlyGenericCommand(buf,argc,argv);
    }

    // 如果正在进行AOF，则将命令追加到AOF的缓存中，在重新进入事件循环之前，这些命令会被冲洗到磁盘上，并向client回复
    if (server.aof_state == AOF_ON)
        server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));

    // 如果后台正在进行重写，那么将命令追加到重写缓存区中，以便我们记录重写的AOF文件于当前数据库的差异
    if (server.aof_child_pid != -1)
        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));    
}

void aofRewriteBufferAppend(unsigned char *s, unsigned long len) {

    listNode *ln = listLast(server.aof_rewrite_buf_blocks);
    aofrwblock *block = ln ? ln->value : NULL;

    while(len) {

        // 重写缓存列表已经有数据了
        if (block) {
            
            // 当前列表的最后一个节点需要分配多少的长度出来
            // 剩余的空间 < 需要的空间 ? 剩余多少分配多少 : 存储内容需要的长度
            unsigned long thislen = (block->free < len) ? block->free : len;
            if (thislen) {
                // 当前的节点空间还有剩余的
                memcpy(block->buf+block->used, s, thislen);
                block->used += thislen;
                block->free -= thislen;
                s += thislen;
                // 计算出还需要多少空间
                len -= thislen;
            }
        }

        if (len) {
            // 还需要空间

            int numblocks;
            // 分配以新的缓存节点, 同时放到列表的尾部
            block = zmalloc(sizeof(*block));
            block->free = AOF_RW_BUF_BLOCK_SIZE;
            block->used = 0;
            listAddNodeTail(server.aof_rewrite_buf_blocks,block);

            // 获取当前的重写缓存列表的节点长度
            numblocks = listLength(server.aof_rewrite_buf_blocks);

            // 加 1 后是 10 的倍数
            if (((numblocks+1) % 10) == 0) {
                // 记录日志
                int level = ((numblocks+1) % 100) == 0 ? LL_WARNING : LL_NOTICE;
                serverLog(level,"Background AOF buffer size: %lu MB", aofRewriteBufferSize()/(1024*1024));
            }

            // 回到循环的头部, 再来一次循环
        }

    }

    // 注册一个文件事件, 用来通知子进程, 重写缓存列表还有数据需要处理
    // 只需要注册一个就可以了
    if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) {
        aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child, AE_WRITABLE, aofChildWriteDiffData, NULL);
    }
}
```

### 1.5.3 AOF - 缓冲区写入文件触发入口

将缓存区中的数据写入到文件的函数为 **flushAppendOnlyFile**, 而在 Redis 中会触发这个函数的有好 5 个地方
> 1. 通过命令动态的关闭 AOF 功能时, 会进行一次保存, 即动态的将 appendonly yes 设置为 appendonly no
> 2. Redis 服务器正确关闭之前
> 3. 在 ae 死循环中每次执行事件时, 如果有配置 beforesleep 函数, 会先执行配置的 beforesleep 函数, 再执行事件调用, 而在 Redis 配置的 beforesleep 中就会调用一次
> 4. Redis 的定时器函数 serverCron  (默认为 100 毫秒执行一次), 会判断上次执行的 flushAppendOnlyFile 没进行执行, 而是延迟执行了, 是会在调一次 (这个延迟的行为, 在 flushAppendOnlyFile 中有分析)
> 5. 最后一个就是定时器函数 serverCron, 每秒判断一次上次 aof 写入状态, 失败就执行一次

后面 2 种都是在 serverCron 中, 代码如下

```C
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {

    // 省略

    // 上次的写文件需要延迟处理
    if (server.aof_flush_postponed_start) 
        flushAppendOnlyFile(0);

    run_with_period(1000) {

        // 上次的写文件失败了
        if (server.aof_last_write_status == C_ERR)
            flushAppendOnlyFile(0);
    }    

    // 省略

}
```


### 1.5.4 AOF - AOF - 缓冲区写入文件

```C

/**
 * aof 缓存区数据写入文件
 * 当持久策略被设置为 everysec, 实际上会由后台线程进行处理, 那么当前这次刷新写入时, 后台可能有线程还在写入, 这时的操作应该是进行延迟写入
 * 
 * @param force 1：表示无视后台的 fsync, 直接写入, 0: 表示可以延迟
 */
void flushAppendOnlyFile(int force) {

    ssize_t nwritten;
    int sync_in_progress = 0;
    mstime_t latency;

    // 缓存区没有数据
    if (sdslen(server.aof_buf) == 0) {

        // 即使在缓存区数据为空的情况下, 也需要检查一次是否需要执行 fsync 操作
        // 因为在以前在 everysec 模式下, fsync 仅在 aof 缓冲区不为空时调用
        // 如果在一秒钟调用一次的 fsync 之前, 用户停止了写命令 (stop write commands), 将会导致缓存中的数据无法及时刷新
        // 这种情况的分析, 个人的猜测在下面

        // 1. 配置的持久化策略为 everysec 每秒执行一次 fsync 
        // 2. 已经同步到磁盘的内容大小 ！= 当前 aof 文件的内容大小
        // 3. 当前的时间 > 上次 fsync 的时间
        // 4. 当前没有 BIO 线程在进行 fsync 同步

        // 4 个条件都符合, 尝试进行 fsync, 否则直接返回
        if (server.aof_fsync == AOF_FSYNC_EVERYSEC && server.aof_fsync_offset != server.aof_current_size 
            && server.unixtime > server.aof_last_fsync && !(sync_in_progress = aofFsyncInProgress())) {
            goto try_fsync;
        } else {
            return;
        }
    }

    // 持久策略为每秒 fsync 一次
    if (server.aof_fsync == AOF_FSYNC_EVERYSEC)
        // true: 表示当前有 BIO 线程在执行 fsync 
        sync_in_progress = aofFsyncInProgress();


    // 持久策略为每秒 fsync 一次, 同时不需要强制写入文件
    if (server.aof_fsync == AOF_FSYNC_EVERYSEC && !force) {    

        // 当前有 BIO 线程在 执行 fsync
        if (sync_in_progress) { 
            
            // 0 表示当前没有需要延迟 fsync
            if (server.aof_flush_postponed_start == 0) {

                // 把 aof_flush_postponed_start 设置为当前时间, 那么在定时器 serverCron 中就能在执行一次
                server.aof_flush_postponed_start = server.unixtime;
                return;
            
            // 如果之前有延迟 fsync, 当前时间和上一次设置的延迟时间小于 2 秒
            } else if (server.unixtime - server.aof_flush_postponed_start < 2) {
                // 直接返回
                return;
            } 

            // 延迟 fsync 的次数 + 1
            // 到了这一步表示后台有 BIO 线程在 fsync, 同时上次延迟距离当前时间超过 2 秒了
            server.aof_delayed_fsync++;
            // 记录日志
            serverLog(LL_NOTICE,"Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.");
        }
    }

    // 下面的 latency 开头的函数基本都是延迟统计相关的, 不影响具体的逻辑, 具体的逻辑可以看下面的 Redis 的延迟统计
    latencyStartMonitor(latency);

    // 步骤 BB

    // 调用 write 函数将缓存区中的数据写入到文件 (系统级缓存)
    nwritten = aofWrite(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));
    latencyEndMonitor(latency);

    if (sync_in_progress) {
        latencyAddSampleIfNeeded("aof-write-pending-fsync",latency);
    } else if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) {
        latencyAddSampleIfNeeded("aof-write-active-child",latency);
    } else {
        latencyAddSampleIfNeeded("aof-write-alone",latency);
    }
    latencyAddSampleIfNeeded("aof-write",latency);

    // 将缓存区中的数据 write 到系统后, 可以把延迟开始设置为 0
    server.aof_flush_postponed_start = 0;

    
    // 写入到系统的数据长度不等于当前缓存区的长度, 进入异常处理
    if (nwritten != (ssize_t)sdslen(server.aof_buf)) {

        static time_t last_write_error_log = 0;
        int can_log = 0;

        // 上次写错误日志的时间距离现在 30 秒了
        if ((server.unixtime - last_write_error_log) > AOF_WRITE_LOG_ERROR_RATE) {
            can_log = 1;
            last_write_error_log = server.unixtime;
        }

        // -1, 第一次就写入失败了
        if (nwritten == -1) {
            // 写入失败
            if (can_log) {
                serverLog(LL_WARNING,"Error writing to the AOF file: %s", strerror(errno));
                
                // 保存错误到 redisServer 的 aof_last_write_errno
                server.aof_last_write_errno = errno;
            }
        } else {
            // 大于 -1 但是不等于 缓存区的大小, 写入成功了一部分, 
            if (can_log) {
                // 记录日志
            }

            // 将 aof 的文件大小修改为 aof_current_size 的大小, 返回值 0 成功, -1 失败
            // 也就是恢复回写入前的文件内容
            if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {
                // 记录日志
            } else {
                // 设置为 -1, 表示 AOF 中没有写入成功的部分数据
                nwritten = -1;
            }
            server.aof_last_write_errno = ENOSPC;
        }

        // 同步策略为 always
        if (server.aof_fsync == AOF_FSYNC_ALWAYS) {
            // 这种情况无法处理了, 已经告知客户端写入成功了, 但是当前写入失败了, 直接退出程序。
            serverLog(LL_WARNING,"Can't recover from AOF write error when the AOF fsync policy is 'always'. Exiting...");
            exit(1);

        } else {
            // 设置上一次写入状态为异常
            server.aof_last_write_status = C_ERR;

            if (nwritten > 0) {
                // 更新当前 aof 文件的大小 = 当前的大小 + 写入部分的大小, 同时将缓存区中这部分大小的数据移除
                // 表示这部分写入成功了, 剩余部分下次调用继续
                server.aof_current_size += nwritten;
                sdsrange(server.aof_buf,nwritten,-1);
            }

            return;
        }

    } else {
        // 写入成功

        if (server.aof_last_write_status == C_ERR) {
            // 新最近一次写的状态为 C_OK
            server.aof_last_write_status = C_OK;
        }
    }

    // 更新当前 aof 文件的大小
    server.aof_current_size += nwritten;

    // 如果这个缓存足够小，小于 4K，那么重用这个缓存，否则释放 AOF 缓存, 然后重新分配一个
    if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) < 4000) {
        sdsclear(server.aof_buf);
    } else {
        sdsfree(server.aof_buf);
        server.aof_buf = sdsempty();
    }


try_fsync:

    // no-appendfsync-on-rewrite (真正重写, 不执行 fsync) 被设置为 yes
    // 同时执行 后台保存 RDB  或者 后台保存 AOF, 直接返回
    if (server.aof_no_fsync_on_rewrite && (server.aof_child_pid != -1 || server.rdb_child_pid != -1))
            return;

    // 持久策略为 always 
    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {

        latencyStartMonitor(latency);

        // 宏定义, 在 Linux 中执行 fdatasync, 其他执行 fsync
        redis_fsync(server.aof_fd); 

        latencyEndMonitor(latency);
        latencyAddSampleIfNeeded("aof-fsync-always",latency);

        // 更新 aof_fsync_offset 为当前的页的大小
        server.aof_fsync_offset = server.aof_current_size;
        // 上次 fsync 为当前的时间
        server.aof_last_fsync = server.unixtime;

    } else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC && server.unixtime > server.aof_last_fsync)) {
        // 持久策略为 everysec 同时当前的时间大于上次 fsync 的时间

        // 步骤 AA
        // 当前没有 BIO 线程在后台执行 fsync 
        if (!sync_in_progress) {
            // 开启一个后台线程,  执行 fsync 操作, 实际就是一个线程在死循环执行 redis_fsync 函数
            aof_background_fsync(server.aof_fd);
            // 更新 aof_fsync_offset 为当前的页的大小
            server.aof_fsync_offset = server.aof_current_size;
        }
        server.aof_last_fsync = server.unixtime;
    }
}



// 返回 true, 如果当前有一个 BIO 线程已经在进行 AOF fsync 操作
int aofFsyncInProgress(void) {
    return bioPendingJobsOfType(BIO_AOF_FSYNC) != 0;
}

// 开启一个线程， 执行 fsync 操作
void aof_background_fsync(int fd) {
    bioCreateBackgroundJob(BIO_AOF_FSYNC,(void*)(long)fd,NULL,NULL);
}

// 调用 
ssize_t aofWrite(int fd, const char *buf, size_t len) {

    ssize_t nwritten = 0, totwritten = 0;

    // 调用 write 函数将 server.aof_buf 中的数据写入到系统级缓存中
    while(len) {
        nwritten = write(fd, buf, len);

        if (nwritten < 0) {
            if (errno == EINTR) {
                continue;
            }
            return totwritten ? totwritten : -1;
        }

        len -= nwritten;
        buf += nwritten;
        totwritten += nwritten;
    }

    // 写入的内容大小
    return totwritten;
}
```

在上面的代码中, 在 aof 缓存区没有数据的情况下, 还会进行条件的判断后, 尝试进行 fsync 的操作, 需要进行这种情况的情景, 个人猜测如下  
> 1. 第一次走入这个方法, sync_in_progress 为 false, 走到下面的步骤 AA, 开启了一个后台 BIO 线程进行 fsync, 假设当前的 aof_fsync_offset = aof_current_size = AA
> 2. 第二次走入到这个方法, sync_in_progress 为 true, 走到步骤 BB 时, 后台的 BIO 线程已经完成任务, 结束了, 所以这时候 sync_in_progress 理论应该为 false 了, 但是此时还是为 false
> 3. 第二次同样走到了下面的步骤 AA, 这是 aof_current_size 已经是追加到了最新的大小了, 设为 BB, 因为 sync_in_progress 为 true, aof_fsync_offset 还是 AA, 最新的数据已经 write 到系统级缓存了, 但是没有 fsync
> 4. 如果这时候用户没有在向 Redis 中进行更改命令, aof 缓存区就会一直为空, 无论走几次到这个方法, 都不会走到下面的逻辑, 这时候就存在 aof 文件中的数据和真正的数据有偏差
> 5. 所以在 aof 缓存区为空的情况下, 还要进行多一次判断, 进行 fsync


上面就是一个将 aof 缓存区中的数据写入到系统的过程, 一个正常的流程如下：

> 1. 如果当前是每秒 fsync, 入参为不强制写入, 同时有 BIO 线程在后台处理 fsync 了, redisServer 的延迟执行时间 aof_flush_postponed_start 为 0, 则将其设置为当前时间, 等待下次执行, 结束
> 3. 调用 write 把 aof 缓存区的数据写入到系统级缓存中
> 4. 获取写入到系统级缓存的数据长度
> 5. 写入到系统级缓存的数据长度不等于 aof 缓存区的数据长度, 进行异常处理, 结束
> 6. 长度一样, 更新 redisServer 的最新 aof 写入状态  aof_last_write_status 为成功状态
> 7. 更新当前 aof 文件的大小 aof_current_size 为 aof_current_size + 最新写入的数据长度
> 8. 清空 aof 缓存的数据
> 9. 如果配置的持久策略为 always, 执行 fsync 
> 10. 如果配置的持久策略为 everysec, 当前的时间大于上次 fsync 的时间, 同时没有 BIO 线程在后台 fsync 中, 开启一个后台线程执行 fsync, 更新当前的 fsync 写入量的 aof_fsync_offset 为当前的 aof 文件大小
> 11. 更新最新的 aof fsync 时间为当前时间


### Redis 的延迟统计

统计延迟信息的配置
```C

#define CONFIG_DEFAULT_LATENCY_MONITOR_THRESHOLD 0

struct redisServer {

    // 延迟监视的阈值, 默认值为 0, 如果配置为大于 0 的值, 表示开启延迟监控, 同时超过了这个时间就进行延迟记录
    long long latency_monitor_threshold;

    // 字典, 也就是延迟记录的保存地方, 保存的格式是 延迟记录的事件名 和 latencyTimeSeries (一个数组)
    dict *latency_events;
}
```

统计延迟样本对象的定义

```C
struct latencyTimeSeries {

    // 用于记录的下一个延迟样本的位置, 超过了数组的长度, 会重新被赋值为 0 
    int idx;

    // 最大的延时
    uint32_t max;

    // 最近的延时记录样本数组
    struct latencySample samples[LATENCY_TS_LEN];
}

struct latencySample {

    // 延时样本创建的时间
    int32_t time; 

    // 延迟样本的延迟时间, 单位毫秒
    uint32_t latency;
}
```

统计延迟样本的函数定义

```C
// 下面的函数做了小改动, 逻辑一样的

// 获取延迟事件的时间
void latencyStartMonitor(var) { 
    var = server.latency_monitor_threshold ? mstime : 0;
}

void latencyEndMonitor(var) {
    if (server.latency_monitor_threshold) {
        var = mstime() - var;
    }
}

/**
 * 判断是否需要记录延迟时间 
 * @param event 事件名
 * @param var 延迟事件的耗时时间
 */
void latencyAddSampleIfNeeded(event,var) {
    if (server.latency_monitor_threshold &&  (var) >= server.latency_monitor_threshold)
        latencyAddSample((event),(var));
}

/**
 * 添加延迟事件到 redisServer 的 latency_events 字典
 */ 
void latencyAddSample(char *event, mstime_t latency) {

    // 找出 event 对应的延时事件记录结构体
    struct latencyTimeSeries *ts = dictFetchValue(server.latency_events,event);

    time_t now = time(NULL);
    int prev;

    // 没有对应事件的 latencyTimeSeries, 添加一个
    if (ts == NULL) {
        ts = zmalloc(sizeof(*ts));
        ts->idx = 0;
        ts->max = 0;
        memset(ts->samples,0,sizeof(ts->samples));
        dictAdd(server.latency_events,zstrdup(event),ts);
    }

    // 获取存储的位置
    prev = (ts->idx + LATENCY_TS_LEN - 1) % LATENCY_TS_LEN;

    // 数组对应位置的样本的创建时间等于当前时间
    if (ts->samples[prev].time == now) {
        // 当前的延迟时间大于样本里面的延迟时间, 更新为当前时间
        if (latency > ts->samples[prev].latency)
            ts->samples[prev].latency = latency;
        return;
    }

    // 修改对应位置的样本的时间信息
    ts->samples[ts->idx].time = time(NULL);
    ts->samples[ts->idx].latency = latency;

    // 如果大于当前所有样本的时间, 更新最大延迟时间为当前的延迟时间
    if (latency > ts->max) 
        ts->max = latency;

    ts->idx++;
    // 超过了上限, 重新设置为 0 
    if (ts->idx == LATENCY_TS_LEN) 
        ts->idx = 0;    

}
```

上面就是延迟事件的创建和保存, 至于在哪里使用的, 如何汇总分析, AOF 这里没有涉及, 就跳过了, 如果需要继续研究可以查看 **latency.h** 和 **latency.c** 这 2 个文件


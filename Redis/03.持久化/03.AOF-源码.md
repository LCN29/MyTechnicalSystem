# 3 AOF - 源码实现

## 3.1 AOF - 命令写入缓冲区

### 3.1.1 触发入口

开启了 AOF 后, 对于修改性质的命令会先写入到 Redis 的一个 AOF 缓存区, 后续再把这个缓存区的数据写入到文件中。

首先这个缓存区的定义如下:

```C
struct redisServer {

    // 很简单就是一个字符串, 后面的命令追加到这个字符串的后面
    sds aof_buf; 

    // 重写缓存列表, 当前正在进行重写时, 会先把命令写入到这个链表, 待重写完成后, 在写入文件
    list *aof_rewrite_buf_blocks; 
}
```

重写缓存列表的节点定义如下

```C
typedef struct aofrwblock {

    // 下面的缓存数组已经使用的空间和剩余的空间
    unsigned long used, free;

    // AOF_RW_BUF_BLOCK_SIZE = 1024*1024*10
    // 用来缓存需要写入到文件的命令文本内容, 当数组所有空间使用完了, 会新建一个新的缓存节点
    char buf[AOF_RW_BUF_BLOCK_SIZE];

} aofrwblock;

```

AOF 的保存入口则在 call 函数中, 每条命令的执行函数都是通过 call 函数触发的

```C
void call(client *c, int flags) {

    // 省略

    // 执行命令
    c->cmd->proc(c);

    // 省略

    if (flags & CMD_CALL_PROPAGATE && (c->flags & CLIENT_PREVENT_PROP) != CLIENT_PREVENT_PROP) {
        
        // 省略

         int propagate_flags = PROPAGATE_NONE;

        /* Check if the command operated changes in the data set. If so
         * set for replication / AOF propagation. */

        // 修改了数据, 需要 aof 和 repl 传播 
        if (dirty) 
            propagate_flags |= (PROPAGATE_AOF|PROPAGATE_REPL);


        // 客户端需要强制同步传播
        if (c->flags & CLIENT_FORCE_REPL) 
            propagate_flags |= PROPAGATE_REPL;

        // 客户端需要强制 AOF 传播
        if (c->flags & CLIENT_FORCE_AOF) 
            propagate_flags |= PROPAGATE_AOF;

        // 如果命令实现了  preventCommandPropagation() 或者类似的, 没有调用 call() 等, 阻止传播
        if (c->flags & CLIENT_PREVENT_REPL_PROP || !(flags & CMD_CALL_PROPAGATE_REPL))
                propagate_flags &= ~PROPAGATE_REPL;

        if (c->flags & CLIENT_PREVENT_AOF_PROP || !(flags & CMD_CALL_PROPAGATE_AOF))
                propagate_flags &= ~PROPAGATE_AOF;

        if (propagate_flags != PROPAGATE_NONE && !(c->cmd->flags & CMD_MODULE))
            // 调用 propagate 进行命令的保存
            propagate(c->cmd,c->db->id,c->argv,c->argc,propagate_flags);
    }
}

void propagate(struct redisCommand *cmd, int dbid, robj **argv, int argc, int flags) {

    // AOF 保存
    if (server.aof_state != AOF_OFF && flags & PROPAGATE_AOF)
        feedAppendOnlyFile(cmd,dbid,argv,argc);
    
    // 主从节点复制    
    if (flags & PROPAGATE_REPL)
        replicationFeedSlaves(server.slaves,dbid,argv,argc);
}
```

上面就是 AOF 的执行入口, 而真正的 AOF 的过程的话就是 feedAppendOnlyFile 函数了

### 3.1.2 实现逻辑

```C
void feedAppendOnlyFile(struct redisCommand *cmd, int dictid, robj **argv, int argc) {

    sds buf = sdsempty();
    robj *tmpargv[3];

    // 写入的数据库不是配置的, 手动加入一段, select 对应的数据库;
    if (dictid != server.aof_selected_db) {
        char seldb[64];

        snprintf(seldb,sizeof(seldb),"%d",dictid);
        buf = sdscatprintf(buf,"*2\r\n$6\r\nSELECT\r\n$%lu\r\n%s\r\n", (unsigned long)strlen(seldb),seldb);
        server.aof_selected_db = dictid;
    }

    // expire/ pexpire / expireat 这三个命令
    if (cmd->proc == expireCommand || cmd->proc == pexpireCommand || cmd->proc == expireatCommand) {
        
        // 转为过期对应的文本
        buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);

    } else if (cmd->proc == setexCommand || cmd->proc == psetexCommand) {
        
        // setnx psetex 2 个命令拆分为 set 和 expireat 2 个命令
        tmpargv[0] = createStringObject("SET",3);
        tmpargv[1] = argv[1];
        tmpargv[2] = argv[3];

        // 将 SET 命令按协议格式追加到buf中
        buf = catAppendOnlyGenericCommand(buf,3,tmpargv);
        decrRefCount(tmpargv[0]);

        // 转为过期对应的文本
        buf = catAppendOnlyExpireAtCommand(buf,cmd,argv[1],argv[2]);
    }  else if (cmd->proc == setCommand && argc > 3) {

        // set 命令同时参数大于 3 个 也就是带有超时时间了

        int i;
        robj *exarg = NULL, *pxarg = NULL;
        
        // 同样是, 先写入 set 命令
        buf = catAppendOnlyGenericCommand(buf,3,argv);

        // 计算后面的超时时间
        for (i = 3; i < argc; i ++) {
            if (!strcasecmp(argv[i]->ptr, "ex")) exarg = argv[i+1];
            if (!strcasecmp(argv[i]->ptr, "px")) pxarg = argv[i+1];
        }
        serverAssert(!(exarg && pxarg));

        // 根据配置的超时时间, 设置文本
        if (exarg)
            buf = catAppendOnlyExpireAtCommand(buf,server.expireCommand,argv[1], exarg);
        if (pxarg)
            buf = catAppendOnlyExpireAtCommand(buf,server.pexpireCommand,argv[1], pxarg);
    } else {
        
        // 其他的命令直接追加
        buf = catAppendOnlyGenericCommand(buf,argc,argv);
    }

    // 如果可以进行 AOF，则将命令追加到 AOF 的缓存中，在重新进入事件循环之前，这些命令会被冲洗到磁盘上，并向client回复
    if (server.aof_state == AOF_ON)
        server.aof_buf = sdscatlen(server.aof_buf,buf,sdslen(buf));

    // 如果后台正在进行重写，那么将命令追加到重写缓存区中，以便我们记录重写的AOF文件于当前数据库的差异
    if (server.aof_child_pid != -1)
        aofRewriteBufferAppend((unsigned char*)buf,sdslen(buf));  
}

void aofRewriteBufferAppend(unsigned char *s, unsigned long len) {

    listNode *ln = listLast(server.aof_rewrite_buf_blocks);
    aofrwblock *block = ln ? ln->value : NULL;

    while(len) {

        // 重写缓存列表已经有数据了
        if (block) {
            
            // 当前列表的最后一个节点需要分配多少的长度出来
            // 剩余的空间 < 需要的空间 ? 剩余多少分配多少 : 存储内容需要的长度
            unsigned long thislen = (block->free < len) ? block->free : len;
            if (thislen) {
                // 当前的节点空间还有剩余的
                memcpy(block->buf+block->used, s, thislen);
                block->used += thislen;
                block->free -= thislen;
                s += thislen;
                // 计算出还需要多少空间
                len -= thislen;
            }
        }

        if (len) {
            // 还需要空间

            int numblocks;
            // 分配以新的缓存节点, 同时放到列表的尾部
            block = zmalloc(sizeof(*block));
            block->free = AOF_RW_BUF_BLOCK_SIZE;
            block->used = 0;
            listAddNodeTail(server.aof_rewrite_buf_blocks,block);

            // 获取当前的重写缓存列表的节点长度
            numblocks = listLength(server.aof_rewrite_buf_blocks);

            // 加 1 后是 10 的倍数
            if (((numblocks+1) % 10) == 0) {
                // 记录日志
                int level = ((numblocks+1) % 100) == 0 ? LL_WARNING : LL_NOTICE;
                serverLog(level,"Background AOF buffer size: %lu MB", aofRewriteBufferSize()/(1024*1024));
            }

            // 回到循环的头部, 再来一次循环
        }

    }

    // 注册一个文件事件, 用来将缓存区的数据写入到 aof_pipe_write_data_to_child 中, 然后在 Pipe 的作用下, 可以同步到 aof_pipe_read_data_from_parent
    // 只需要注册一个就可以了
    if (aeGetFileEvents(server.el,server.aof_pipe_write_data_to_child) == 0) {
        aeCreateFileEvent(server.el, server.aof_pipe_write_data_to_child, AE_WRITABLE, aofChildWriteDiffData, NULL);
    }
}

// 把当前的 AOF 缓存区同步到 aof_pipe_write_data_to_child, 在 Pipe 的作用下间接同步到 aof_pipe_read_data_from_parent
void aofChildWriteDiffData(aeEventLoop *el, int fd, void *privdata, int mask) {

    listNode *ln;
    aofrwblock *block;
    ssize_t nwritten;
    UNUSED(el);
    UNUSED(fd);
    UNUSED(privdata);
    UNUSED(mask);

    while(1) {
        
        // 获取头节点
        ln = listFirst(server.aof_rewrite_buf_blocks);
        block = ln ? ln->value : NULL;

        // 停止同步或者没有 AOF 缓存区时, 删除这个事件
        // 后续如果停止同步的标识还是 true, 又有缓存区数据, 在 aofRewriteBufferAppend 会重新新建一个这个事件
        if (server.aof_stop_sending_diff || !block) {
            // 删除这个事件
            aeDeleteFileEvent(server.el,server.aof_pipe_write_data_to_child, AE_WRITABLE);
            return;
        }

        if (block->used > 0) {
            // 把 block 的数据写入到 aof_pipe_write_data_to_child
            nwritten = write(server.aof_pipe_write_data_to_child, block->buf, block->used);
            if (nwritten <= 0) return;
            memmove(block->buf,block->buf+nwritten,block->used-nwritten);
            block->used -= nwritten;
            block->free += nwritten;
        }
        if (block->used == 0) 
            listDelNode(server.aof_rewrite_buf_blocks,ln);
    }
}
```

## 3.2 AOF - 缓冲区写入文件

### 3.2.1 触发入口

将缓存区中的数据写入到文件的函数为 **flushAppendOnlyFile**, 而在 Redis 中会触发这个函数的有好 5 个地方
> 1. 通过命令动态的关闭 AOF 功能时, 会进行一次保存, 即动态的将 appendonly yes 设置为 appendonly no
> 2. Redis 服务器正常关闭之前
> 3. 在 ae 死循环中每次执行事件时, 如果有配置 beforesleep 函数, 会先执行配置的 beforesleep 函数, 再执行事件调用, 而在 Redis 配置的 beforesleep 中就会调用一次, 这个是主要的入口
> 4. Redis 的定时器函数 serverCron  (默认为 100 毫秒执行一次), 会判断上次执行的 flushAppendOnlyFile 没进行执行, 而是延迟执行了, 是会在调一次 (这个延迟的行为, 在 flushAppendOnlyFile 中有分析)
> 5. 最后一个就是定时器函数 serverCron, 每秒判断一次上次 aof 写入状态, 失败就执行一次

后面 2 种都是在 serverCron 中, 代码如下

```C
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {

    // 省略

    // 上次的写文件需要延迟处理
    if (server.aof_flush_postponed_start) 
        flushAppendOnlyFile(0);

    run_with_period(1000) {

        // 上次的写文件失败了
        if (server.aof_last_write_status == C_ERR)
            flushAppendOnlyFile(0);
    }    

    // 省略

}
```   

### 3.2.2 实现逻辑

```C

/**
 * aof 缓存区数据写入文件
 * 当持久策略被设置为 everysec, 实际上会由后台线程进行处理, 那么当前这次刷新写入时, 后台可能有线程还在写入, 这时的操作应该是进行延迟写入
 * 
 * @param force 1：表示无视后台的 fsync, 直接写入, 0: 表示可以延迟
 */
void flushAppendOnlyFile(int force) {

    ssize_t nwritten;
    int sync_in_progress = 0;
    mstime_t latency;

    // 缓存区没有数据
    if (sdslen(server.aof_buf) == 0) {
            
        // 即使在缓存区数据为空的情况下, 也需要检查一次是否需要执行 fsync 操作
        // 因为在以前在 everysec 模式下, fsync 仅在 aof 缓冲区不为空时调用
        // 如果在一秒钟调用一次的 fsync 之前, 用户停止了写命令 (stop write commands), 将会导致缓存中的数据无法及时刷新
        // 这种情况的分析, 个人的猜测在下面

        // 1. 配置的持久化策略为 everysec 每秒执行一次 fsync 
        // 2. 已经同步到磁盘的内容大小 ！= 当前 aof 文件的内容大小
        // 3. 当前的时间 > 上次 fsync 的时间
        // 4. 当前没有请求 fsync 的任务在线程池中

        // 4 个条件都符合, 尝试进行 fsync, 否则直接返回
        if (server.aof_fsync == AOF_FSYNC_EVERYSEC && server.aof_fsync_offset != server.aof_current_size 
            && server.unixtime > server.aof_last_fsync && !(sync_in_progress = aofFsyncInProgress())) {
            goto try_fsync;
        } else {
            return;
        }

    }

    
    // 持久策略为每秒 fsync 一次
    if (server.aof_fsync == AOF_FSYNC_EVERYSEC)
        // true: 表示当前有 BIO 线程在执行 fsync 
        sync_in_progress = aofFsyncInProgress();


    // 持久策略为每秒 fsync 一次, 同时不需要强制写入文件
    if (server.aof_fsync == AOF_FSYNC_EVERYSEC && !force) {       

        // 当前有 BIO 线程在 执行 fsync
        if (sync_in_progress) { 
            
            // 0 表示当前没有需要延迟刷新
            if (server.aof_flush_postponed_start == 0) {

                // 把 aof_flush_postponed_start 设置为当前时间, 那么在定时器 serverCron 中就能在执行一次
                server.aof_flush_postponed_start = server.unixtime;
                return;
            
            // 如果之前有延迟 fsync, 当前时间和上一次设置的延迟时间小于 2 秒
            } else if (server.unixtime - server.aof_flush_postponed_start < 2) {
                // 直接返回
                return;
            } 

            // 上面的情况分析
            // 1. sync_in_progress: 表示线程池中有 fsync 的任务未进行或者进行中
            // 2. aof_flush_postponed_start 表示上一次已经把 aof 缓存区中的数据 write 了 (write 成功后会把这个属性设置为 0)
            // 1, 2 两个条件加上去, 同时可以不强制写入, 那么这次 flush 可以先延迟
            // 3. 当前的时间距离上次延迟执行的时间还没大于 2 秒, 可以继续等
            // 所以第一次成功 flush 后, 第二次 flush 需要在 2 秒后才会进行, 而不是 everysec 说的 1 秒

            // 延迟 fsync 的次数 + 1
            // 到了这一步表示线程池中有请求 fsync 的任务, 同时上次延迟距离当前时间超过 2 秒了
            server.aof_delayed_fsync++;
            // 记录日志
            serverLog(LL_NOTICE,"Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.");
        }

    }

    // 下面的 latency 开头的函数基本都是延迟统计相关的, 不影响具体的逻辑, 具体的逻辑可以看下面的 Redis 的延迟统计
    latencyStartMonitor(latency);

    // 步骤 BB

    // 调用 write 函数将缓存区中的数据写入到文件 (系统级缓存)
    nwritten = aofWrite(server.aof_fd,server.aof_buf,sdslen(server.aof_buf));
    latencyEndMonitor(latency);

    if (sync_in_progress) {
        latencyAddSampleIfNeeded("aof-write-pending-fsync",latency);
    } else if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) {
        latencyAddSampleIfNeeded("aof-write-active-child",latency);
    } else {
        latencyAddSampleIfNeeded("aof-write-alone",latency);
    }
    latencyAddSampleIfNeeded("aof-write",latency);

    // 将缓存区中的数据 write 到系统后, 可以把延迟开始设置为 0
    server.aof_flush_postponed_start = 0;

    // 写入到系统的数据长度不等于当前缓存区的长度, 进入异常处理
    if (nwritten != (ssize_t)sdslen(server.aof_buf)) {
        
        static time_t last_write_error_log = 0;
        int can_log = 0;

        // 上次写错误日志的时间距离现在 30 秒了
        if ((server.unixtime - last_write_error_log) > AOF_WRITE_LOG_ERROR_RATE) {
            can_log = 1;
            last_write_error_log = server.unixtime;
        }

        // -1, 第一次就写入失败了
        if (nwritten == -1) {
            // 写入失败
            if (can_log) {
                serverLog(LL_WARNING,"Error writing to the AOF file: %s", strerror(errno));
                
                // 保存错误到 redisServer 的 aof_last_write_errno
                server.aof_last_write_errno = errno;
            }
        } else {
            // 大于 -1 但是不等于 缓存区的大小, 写入成功了一部分, 
            if (can_log) {
                // 记录日志
            }

            // 将 aof 的文件大小修改为 aof_current_size 的大小, 返回值 0 成功, -1 失败
            // 也就是恢复回写入前的文件内容
            if (ftruncate(server.aof_fd, server.aof_current_size) == -1) {
                // 记录日志
            } else {
                // 设置为 -1, 表示 AOF 中没有写入成功的部分数据
                nwritten = -1;
            }
            server.aof_last_write_errno = ENOSPC;
        }

        // 同步策略为 always
        if (server.aof_fsync == AOF_FSYNC_ALWAYS) {
            // 这种情况无法处理了, 已经告知客户端写入成功了, 但是当前写入失败了, 直接退出程序。
            serverLog(LL_WARNING,"Can't recover from AOF write error when the AOF fsync policy is 'always'. Exiting...");
            exit(1);

        } else {
            // 设置上一次写入状态为异常
            server.aof_last_write_status = C_ERR;

            if (nwritten > 0) {
                // 更新当前 aof 文件的大小 = 当前的大小 + 写入部分的大小, 同时将缓存区中这部分大小的数据移除
                // 表示这部分写入成功了, 剩余部分下次调用继续
                server.aof_current_size += nwritten;
                sdsrange(server.aof_buf,nwritten,-1);
            }

            return;
        }

    } else {
        // 写入成功

        if (server.aof_last_write_status == C_ERR) {
            // 新最近一次写的状态为 C_OK
            server.aof_last_write_status = C_OK;
        }
    }

    // 更新当前 aof 文件的大小
    server.aof_current_size += nwritten;

    // 如果这个缓存足够小，小于 4K，那么重用这个缓存，否则释放 AOF 缓存, 然后重新分配一个
    if ((sdslen(server.aof_buf)+sdsavail(server.aof_buf)) < 4000) {
        sdsclear(server.aof_buf);
    } else {
        sdsfree(server.aof_buf);
        server.aof_buf = sdsempty();
    }

try_fsync:

    // no-appendfsync-on-rewrite (正在重写, 不执行 fsync) 被设置为 yes
    // 正在执行 后台保存 RDB  或者 后台保存 AOF, 直接返回
    if (server.aof_no_fsync_on_rewrite && (server.aof_child_pid != -1 || server.rdb_child_pid != -1))
            return;

    // 持久策略为 always 
    if (server.aof_fsync == AOF_FSYNC_ALWAYS) {

        latencyStartMonitor(latency);

        // 宏定义, 在 Linux 中执行 fdatasync, 其他执行 fsync
        redis_fsync(server.aof_fd); 

        latencyEndMonitor(latency);
        latencyAddSampleIfNeeded("aof-fsync-always",latency);

        // 更新 aof_fsync_offset 为当前的页的大小
        server.aof_fsync_offset = server.aof_current_size;
        // 上次 fsync 为当前的时间
        server.aof_last_fsync = server.unixtime;

    } else if ((server.aof_fsync == AOF_FSYNC_EVERYSEC && server.unixtime > server.aof_last_fsync)) {
        // 持久策略为 everysec 同时当前的时间大于上次 fsync 的时间

        // 步骤 AA
        // 当前没有请求 fsync 的任务在线程池中
        if (!sync_in_progress) {
            // 提交一个任务, 最终就是一个后台线程执行一次 redis_fsync 函数
            aof_background_fsync(server.aof_fd);
            // 更新 aof_fsync_offset 为当前的页的大小
            server.aof_fsync_offset = server.aof_current_size;
        }
        server.aof_last_fsync = server.unixtime;
    }
}

// 返回 true, 如果当前已经有一个请求 fsync 的任务了, 返回 true
int aofFsyncInProgress(void) {
    return bioPendingJobsOfType(BIO_AOF_FSYNC) != 0;
}

// Redis 的 BIO 更像是一个线程池, 下面的方法是提交一个任务到对应任务链表
// 同时会尝试唤醒线程池对应的线程去执行任务, 具体的实现可以看一下 bio.c 这个文件
void aof_background_fsync(int fd) {
    bioCreateBackgroundJob(BIO_AOF_FSYNC,(void*)(long)fd,NULL,NULL);
}

// 调用 
ssize_t aofWrite(int fd, const char *buf, size_t len) {

    ssize_t nwritten = 0, totwritten = 0;

    // 调用 write 函数将 server.aof_buf 中的数据写入到系统级缓存中
    while(len) {
        nwritten = write(fd, buf, len);

        if (nwritten < 0) {
            if (errno == EINTR) {
                continue;
            }
            return totwritten ? totwritten : -1;
        }

        len -= nwritten;
        buf += nwritten;
        totwritten += nwritten;
    }

    // 写入的内容大小
    return totwritten;
}
```

在上面的代码中, 在 aof 缓存区没有数据的情况下, 还会进行条件的判断后, 尝试进行 fsync 的操作, 需要进行这种情况的情景, 个人猜测如下  
> 1. 第一次走入这个方法, sync_in_progress 为 false, 走到下面的步骤 AA, 开启了一个后台 BIO 线程进行 fsync, 假设当前的 aof_fsync_offset = aof_current_size = AA
> 2. 第二次走入到这个方法, sync_in_progress 为 true, 走到步骤 BB 时, 后台的 BIO 线程已经完成任务, 结束了, 所以这时候 sync_in_progress 理论应该为 false 了, 但是此时还是为 false
> 3. 第二次同样走到了下面的步骤 AA, 这是 aof_current_size 已经是追加到了最新的大小了, 设为 BB, 因为 sync_in_progress 为 true, aof_fsync_offset 还是 AA, 最新的数据已经 write 到系统级缓存了, 但是没有 fsync
> 4. 如果这时候用户没有在向 Redis 中进行更改命令, aof 缓存区就会一直为空, 无论走几次到这个方法, 都不会走到下面的逻辑, 这时候就存在 aof 文件中的数据和真正的数据有偏差
> 5. 所以在 aof 缓存区为空的情况下, 还要进行多一次判断, 进行 fsync


上面就是一个将 aof 缓存区中的数据写入到系统的过程, 一个正常的流程如下：

> 1. 如果当前是每秒 fsync, 入参为不强制写入, 同时有 BIO 线程在后台处理 fsync 了, redisServer 的延迟执行时间 aof_flush_postponed_start 为 0, 则将其设置为当前时间, 等待下次执行, 结束
> 3. 调用 write 把 aof 缓存区的数据写入到系统级缓存中
> 4. 获取写入到系统级缓存的数据长度
> 5. 写入到系统级缓存的数据长度不等于 aof 缓存区的数据长度, 进行异常处理, 结束
> 6. 长度一样, 更新 redisServer 的最新 aof 写入状态  aof_last_write_status 为成功状态
> 7. 更新当前 aof 文件的大小 aof_current_size 为 aof_current_size + 最新写入的数据长度
> 8. 清空 aof 缓存的数据
> 9. 如果配置的持久策略为 always, 执行 fsync 
> 10. 如果配置的持久策略为 everysec, 当前的时间大于上次 fsync 的时间, 同时 fsync 请求的任务在线程池, 提交一个到线程池, 更新当前的 fsync 写入量的 aof_fsync_offset 为当前的 aof 文件大小
> 11. 更新最新的 aof fsync 时间为当前时间


## 3.3 AOF - 重写机制

### 3.3.1 触发入口

在 Redis 触发重写机制的方式有 2 个
> 1. 通过 bgrewriteaof 命令
> 2. 定时器满足条件触发

命令方式的话, 最终执行到的函数为 **bgrewriteaofCommand**, 里面的逻辑如下
> 1. 如果已经在执行重写中了, 返回错误提示
> 2. 如果当前正在执行 RDB 保存时, 只会先将 redisServer 中的 aof_rewrite_scheduled 属性设置为 true, 返回提示后, 结束, 后面通过定时器在出发执行
> 3. 调用 rewriteAppendOnlyFileBackground 执行重写

而定时器的触发代码如下

```C
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {

    // 代码省略

    // 后台没有进程在 RDB 和 AOF, 同时通过 bgrewriteaof 命令设置了定时刷新 aof 
    if (server.rdb_child_pid == -1 && server.aof_child_pid == -1 && server.aof_rewrite_scheduled) {
        rewriteAppendOnlyFileBackground();
    }

    // 后台有进程在 RDB 或者 AOF
    if (server.rdb_child_pid != -1 || server.aof_child_pid != -1 || ldbPendingChildren()) {
        // 代码省略
    } else {
        // 代码省略

        // 1. 开启了 aof 功能
        // 2. 后台没有进程在 RDB 和 AOF
        // 3. 配置了目前 AOF 文件大小超过上次重写的 AOF 文件的百分比
        // 4. 当前的 AOF 文件大小超过了配置的需要触发重写的最小大小
        if (server.aof_state == AOF_ON && server.rdb_child_pid == -1 && server.aof_child_pid == -1 &&
            server.aof_rewrite_perc && server.aof_current_size > server.aof_rewrite_min_size) {
            
            // 计算当前的文件增长的比例
            long long base = server.aof_rewrite_base_size ? server.aof_rewrite_base_size : 1;
            long long growth = (server.aof_current_size*100/base) - 100;  

            // 超过了就调用 rewriteAppendOnlyFileBackground 进行重写
            if (growth >= server.aof_rewrite_perc) {
                rewriteAppendOnlyFileBackground();
            }  
        }
    }

    // 代码省略
}
```

上面就是 AOF 重写触发的入口了, 而 AOF 重写的逻辑就是 **rewriteAppendOnlyFileBackground** 函数。

### 3.3.2 实现逻辑

```C
int rewriteAppendOnlyFileBackground(void) {

    pid_t childpid;
    long long start;

    if (server.aof_child_pid != -1 || server.rdb_child_pid != -1) 
        return C_ERR;

    // 创建通道, 用于父子进程之间通信
    if (aofCreatePipes() != C_OK) 
        return C_ERR;  

    // 开启通道
    openChildInfoPipe();
    start = ustime();  

    if ((childpid = fork()) == 0) {     
        // 子进程 

        // 清除子进程不需要的资源
        closeClildUnusedResourceAfterFork();
        // 设置标题
        redisSetProcTitle("redis-aof-rewrite");
        // 创建临时文件
        snprintf(tmpfile,256,"temp-rewriteaof-bg-%d.aof", (int) getpid());

        // 执行 rewriteAppendOnlyFile 函数进行 aof 
        if (rewriteAppendOnlyFile(tmpfile) == C_OK) {

            // 计算当前进程使用了多少额外的内存
            size_t private_dirty = zmalloc_get_private_dirty(-1);

            if (private_dirty) {
                serverLog(LL_NOTICE, "AOF rewrite: %zu MB of memory used by copy-on-write", private_dirty/(1024*1024));
            }

            server.child_info_data.cow_size = private_dirty;
            // 将子进程的信息发送给父进程, 也就是拷贝到 server.child_info_pipe[2] 中
            sendChildInfo(CHILD_INFO_TYPE_AOF);
            exitFromChild(0);
        } else {
            exitFromChild(1);
        }

    } else {
        // 父进程

        // 设置 fork 消耗的时间
        server.stat_fork_time = ustime()-start;
        // 计算 fork 的速率，GB/每秒
        server.stat_fork_rate = (double) zmalloc_used_memory() * 1000000 / server.stat_fork_time / (1024*1024*1024);
        // 延迟统计
        latencyAddSampleIfNeeded("fork",server.stat_fork_time/1000);
        
        if (childpid == -1) {
            // fork 失败 关闭通道
            closeChildInfoPipe();
            serverLog(LL_WARNING, "Can't rewrite append only file in background: fork: %s", strerror(errno));
            aofClosePipes();
            return C_ERR;
        }

        serverLog(LL_NOTICE,"Background append only file rewriting started by pid %d",childpid);
        server.aof_rewrite_scheduled = 0;
        server.aof_rewrite_time_start = time(NULL);
        server.aof_child_pid = childpid;

        // 和 RDB 类型的, 更新全局的 dict.dict_can_resize 进行字典扩容的控制, 控制存储数据的 dict 扩容
        updateDictResizePolicy();
        server.aof_selected_db = -1;

        // 清空 redisServer 的 repl_scriptcache_dict 字典和 repl_scriptcache_fifo 这个列表
        // 和主从复制相关
        replicationScriptCacheFlush();
        return C_OK;
    }
}
```

**子进程执行的 rewriteAppendOnlyFile 函数就是 AOF 重写真正过程**

```C

// 这里的入参 filename 格式为 temp-rewriteaof-bg-进程ID, 而不是真正的 aof 文件名
int rewriteAppendOnlyFile(char *filename) {

    rio aof;
    FILE *fp;
    char tmpfile[256];
    char byte;

    // 重新更加进程ID 获取一个文件名 temp-rewriteaof-进程ID.aof 的文件, 数据先写入到这个文件, 后面在重命名为入参的 filename
    snprintf(tmpfile,256,"temp-rewriteaof-%d.aof", (int) getpid());
    fp = fopen(tmpfile,"w");
    if (!fp) {
        serverLog(LL_WARNING, "Opening the temp file for AOF rewrite in rewriteAppendOnlyFile(): %s", strerror(errno));
        return C_ERR;
    }

    // 清空 aof_child_diff 的数据
    server.aof_child_diff = sdsempty();
    // 初始 rio 流
    rioInitWithFile(&aof,fp);

    // 设置文件自动同步, 当写入的字节数达到了 REDIS_AUTOSYNC_BYTES 的倍数, 就执行一次 fsync,
    if (server.aof_rewrite_incremental_fsync)
        // REDIS_AUTOSYNC_BYTES = 1024*1024*32
        rioSetAutoSync(&aof,REDIS_AUTOSYNC_BYTES);

    // Redis 4.0 的特性, aof 和 rdb 混用, 先将当前的数据以 rdb 的格式存储下来, 添加的这段时间, 在缓存区的再以 aof 的方式存储
    if (server.aof_use_rdb_preamble) {
        int error;
        if (rdbSaveRio(&aof,&error,RDB_SAVE_AOF_PREAMBLE,NULL) == C_ERR) {
            errno = error;
            goto werr;
        }
    } else {
        // 正常的写入
        if (rewriteAppendOnlyFileRio(&aof) == C_ERR) goto werr;
    }   

    // 当前的数据库的数据都写入完成
    // 执行 fflush 函数 
    if (fflush(fp) == EOF) goto werr;

    // 执行 fsync 函数
    if (fsync(fileno(fp)) == -1) goto werr;

    int nodata = 0;
    mstime_t start = mstime();

    // 当前时间和重写的开始时间差在 1 秒内, 尝试从父级中读取数据
    // 当前的时间和重写的开始时间差大于 1 秒或者连续 20 次读取到空数据就结束
    while(mstime()-start < 1000 && nodata < 20) {

        if (aeWait(server.aof_pipe_read_data_from_parent, AE_READABLE, 1) <= 0) {
            nodata++;
            continue;
        }
        nodata = 0; 
        // 从重写缓存区读数据到 aof_child_diff
        aofReadDiffFromParent();
    }

    // 写入一个 ！ 到 aof_pipe_write_ack_to_parent, 通过通道间接同步到父级的 aof_pipe_read_ack_from_child
    // 请求父进程停止发送差异数据, 也就是重写缓存区
    if (write(server.aof_pipe_write_ack_to_parent,"!",1) != 1) goto werr;

    // 将从父级读取 ack 的 aof_pipe_read_ack_from_parent 设置为非阻塞的
    if (anetNonBlock(NULL,server.aof_pipe_read_ack_from_parent) != ANET_OK) goto werr;

    // 在 5000ms 之内，从 aof_pipe_read_ack_from_parent 读取 1 个字节的数据保存在 byte 中, 同时判断 byte 是否为 '!'
    if (syncRead(server.aof_pipe_read_ack_from_parent,&byte,1,5000) != 1 || byte != '!') goto werr;

    serverLog(LL_NOTICE,"Parent agreed to stop sending diffs. Finalizing AOF...");

    // 再次从父级中读取差异数据
    aofReadDiffFromParent();

    serverLog(LL_NOTICE, "Concatenating %.2f MB of AOF diff received from parent.", (double) sdslen(server.aof_child_diff) / (1024*1024));

    // 写入文件
    if (rioWrite(&aof,server.aof_child_diff,sdslen(server.aof_child_diff)) == 0) goto werr;

    if (fflush(fp) == EOF) goto werr;
    if (fsync(fileno(fp)) == -1) goto werr;
    if (fclose(fp) == EOF) goto werr;

    // 重命名文件名
    if (rename(tmpfile,filename) == -1) {
        serverLog(LL_WARNING,"Error moving temp append only file on the final destination: %s", strerror(errno));
        unlink(tmpfile);
        return C_ERR;
    }
    serverLog(LL_NOTICE,"SYNC append only file rewrite performed");
    return C_OK;

werr:
    serverLog(LL_WARNING,"Write error writing append only file on disk: %s", strerror(errno));
    fclose(fp);
    unlink(tmpfile);
    return C_ERR;    
}
```


**AOF 文件写入执行过程**

```C
/**
 * 将 Redis 数据库中的数据都写入到文件
 * 原理就是变量数据库中的数据, 然后将每个 key 和 key 对应的 value 写入到文件中
 * 同时为较小文件的大小, 会使用批量相关的命令来替代单个命令
 * 比如向 list 类型的结构添加数据, 可以通过 lset 一个一个元素的添加, 也可以通过 RPUSH 一次添加多个
 * 所以 Redis AOF 文件能缩小的原因就是这个
 * 
 * 同时内部为了安全性, 单个批量命令内部的元素会控制不超过 AOF_REWRITE_ITEMS_PER_CMD 64 个
 */
int rewriteAppendOnlyFileRio(rio *aof) {

    dictIterator *di = NULL;
    dictEntry *de;
    size_t processed = 0;
    int j;

    for (j = 0; j < server.dbnum; j++) {

        char selectcmd[] = "*2\r\n$6\r\nSELECT\r\n";
        redisDb *db = server.db+j;
        dict *d = db->dict;

        // 对应的数据库没有数据, 跳过
        if (dictSize(d) == 0) 
            continue;

        // 字典迭代器
        di = dictGetSafeIterator(d);

        // 向文件中写入 *2\r\n$6\r\nSELECT\r\n数据库的编号的长度\r\n数据库的编号, 也就是 select 数据库
        if (rioWrite(aof,selectcmd,sizeof(selectcmd)-1) == 0) goto werr;
        if (rioWriteBulkLongLong(aof,j) == 0) goto werr;

        while((de = dictNext(di)) != NULL) {    

            sds keystr;
            robj key, *o;
            long long expiretime;

            keystr = dictGetKey(de);
            o = dictGetVal(de);
            // 将字符串的 key 转为 redisObject 对象, 编码 encoding 默认为 OBJ_ENCODING_RAW, 引用次数 refcount 为 1
            initStaticStringObject(key,keystr);

            expiretime = getExpire(db,&key);

            if (o->type == OBJ_STRING) {

                char cmd[]="*3\r\n$3\r\nSET\r\n";
                // 写入上面的文本
                if (rioWrite(aof,cmd,sizeof(cmd)-1) == 0) goto werr;
                // 写入 key 
                if (rioWriteBulkObject(aof,&key) == 0) goto werr;
                // 写入 value
                if (rioWriteBulkObject(aof,o) == 0) goto werr;

            } else if (o->type == OBJ_LIST) {
                if (rewriteListObject(aof,&key,o) == 0) goto werr;
            } else if (o->type == OBJ_SET) {
                // 下面的几个写入和 list 类型跳过
                if (rewriteSetObject(aof,&key,o) == 0) goto werr;
            } else if (o->type == OBJ_ZSET) {
                if (rewriteSortedSetObject(aof,&key,o) == 0) goto werr;
            } else if (o->type == OBJ_HASH) {
                if (rewriteHashObject(aof,&key,o) == 0) goto werr;
            } else if (o->type == OBJ_STREAM) {
                if (rewriteStreamObject(aof,&key,o) == 0) goto werr;
            } else if (o->type == OBJ_MODULE) {
                if (rewriteModuleObject(aof,&key,o) == 0) goto werr;
            } else {
                serverPanic("Unknown object type");
            }

            // 如果 key 设置了过期时间, 写入过期时间
            if (expiretime != -1) {
                char cmd[]="*3\r\n$9\r\nPEXPIREAT\r\n";
                if (rioWrite(aof,cmd,sizeof(cmd)-1) == 0) goto werr;
                if (rioWriteBulkObject(aof,&key) == 0) goto werr;
                if (rioWriteBulkLongLong(aof,expiretime) == 0) goto werr;
            }

            // AOF_READ_DIFF_INTERVAL_BYTES = 1024*10
            // 重写文件每写入 10 M,  就通过通道从父级中读取差异
            if (aof->processed_bytes > processed + AOF_READ_DIFF_INTERVAL_BYTES) {
                // 更新已写的字节数
                processed = aof->processed_bytes;
                aofReadDiffFromParent();
            }
        }
    }
    return C_OK;

werr:
    if (di)
        dictReleaseIterator(di);
    return C_ERR;

}

// list 类型的数据写入
int rewriteListObject(rio *r, robj *key, robj *o) {

    long long count = 0, items = listTypeLength(o);

    if (o->encoding == OBJ_ENCODING_QUICKLIST) {

        quicklist *list = o->ptr;
        quicklistIter *li = quicklistGetIterator(list, AL_START_HEAD);
        quicklistEntry entry;

        while (quicklistNext(li,&entry)) {
            if (count == 0) {
                
                // 获取当前  rpush 的元素个数, 最大为 AOF_REWRITE_ITEMS_PER_CMD 64 个
                int cmd_items = (items > AOF_REWRITE_ITEMS_PER_CMD) ?  AOF_REWRITE_ITEMS_PER_CMD : items;

                // 写入参数个数 *参数个数
                if (rioWriteBulkCount(r,'*',2+cmd_items) == 0) return 0;
                // 写入 rpush 命令
                if (rioWriteBulkString(r,"RPUSH",5) == 0) return 0;
                // 写入 key 值
                if (rioWriteBulkObject(r,key) == 0) return 0;
            }

            // 依次写入元素
            if (entry.value) {
                if (rioWriteBulkString(r,(char*)entry.value,entry.sz) == 0) return 0;
            } else {
                if (rioWriteBulkLongLong(r,entry.longval) == 0) return 0;
            }

            // 写入一次 count + 1 次, 当 count == 上限的 64 个, 重新值为 0
            // 从而可以重新写入一个 rpush
            if (++count == AOF_REWRITE_ITEMS_PER_CMD) count = 0;
            items--;
        }

        quicklistReleaseIterator(li);

    } else {
        serverPanic("Unknown list encoding");
    }
    return 1;
}

// 将 aof_pipe_read_data_from_parent 中的数据读取到 buf 中
ssize_t aofReadDiffFromParent(void) {

    char buf[65536];
    ssize_t nread, total = 0;

    // 将 aof_pipe_read_data_from_parent 中的数据读取到 buf 中
    while ((nread = read(server.aof_pipe_read_data_from_parent,buf,sizeof(buf))) > 0) {
        // 把 buf 的数据拼接到 aof_child_diff 中
        server.aof_child_diff = sdscatlen(server.aof_child_diff,buf,nread);
        total += nread;
    }
    return total;
}
```

整个 AOF 重写的因为涉及到了子进程, 所以复杂度就上去了, 整理如下:

主进程
> 1. 定时器判断满足重写条件或者执行了 bgrewriteaof 命令, 触发 AOF 重写
> 2. 主进程创建出 6 个文件描述符, 用来创建 3 个通道, 分别用于: 父进程将数据写给子进程, 子进程通知父进程 ack, 父进程通知子进程 ack, 同时创建一个 关于这个 aof_pipe_read_ack_from_child 描述符的时间, 用来处理收到子进程的 ack 请求 
> 3. 创建完通道后, 设置 aof_stop_sending_diff 为 0, 也就是 false, 表示可以将重写缓存区的数据继续推送给子进程
> 4. 父进程 fork 出一个子进程, 然后进行一些统计相同的配置后, 进行处理其他的命令 (此处是子进程的开始地方)
> 5. 父进程处理到修改性质的命令时, 依旧是会进行把当前命令的变更写的已有的 AOF 文件中, 同时判断到当前在进行 AOF 重新, 会把当前命令对应的文本保存到重写缓存列表中 aof_rewrite_buf_blocks
> 6. 判断当前的 ae 循环中是否有 aof_pipe_write_data_to_child 这个文件描述符 (这个就是上面 6 个文件描述符之一) 对应的文件, 没有则创建 1 个文件, 执行的逻辑为 aofChildWriteDiffData
> 7. 因为有事件存在, 每次 ae 循环时, 都会执行到 aofChildWriteDiffData 函数, 逻辑就是将重写缓存列表中 aof_rewrite_buf_blocks 中的数据全部写到 aof_pipe_write_data_to_child 中, 同时在 aof_stop_sending_diff 为 true 或者 aof_rewrite_buf_blocks 中的数据转移完成时, 删除这个事件, 写入到 aof_pipe_write_data_to_child 的数据在通道的作用下, 会自动同步到子进程的 aof_pipe_read_data_from_parent 中

上面就是主进程的逻辑, 下面的子进程的逻辑

子进程
> 1. 因为子进程是通过 fork 操作创建出来的, 所以子进程和父进程是完全一样的, 也就是当前子进程拥有着和父进程一样的字典, 存放着所有键值对的数据, 同时不受父进程的影响, 也就是快照
> 2. 临时创建出一个 temp-rewriteaof-bg-进程ID.aof 文件, 用来保存当前的数据
> 3. 判断 server.aof_use_rdb_preamble 是否为 true, 也就是是否开启了 RDB 和 AOF 混用的功能, 开启了, 就先将当前的数据字典的数据以 RDB 的方式进行保存, 否则就是根据数据字典执行命令重写
> 4. 命令重写的逻辑: 用批量相关的命令来替代单个命令, 同时在执行的过程中不断的将 aof_pipe_read_data_from_parent 中的数据读取到自身的 aof_child_diff 中
> 5. 数据字典中的数据都处理完成后, 子进程向 aof_pipe_write_ack_to_parent 写入一个 !, 在通道的同步下, 同步到父进程的 aof_pipe_read_ack_from_child 中 (父级收到了, 先将 aof_stop_sending_diff 设置为 true, 向 aof_pipe_write_ack_to_child 写入了一个 ！, 同样在管道的同步下, 最终到了子进程的 aof_pipe_read_ack_from_parent, 最后删除这个 aof_pipe_read_ack_from_child 描述符的事件)
> 6. 向 aof_pipe_write_ack_to_parent 写入 ! 后, 等待 5000ms, 从 aof_pipe_read_ack_from_parent 中读取数据, 超时读取, 读取到的不是 !, 异常处理, 结束
> 7. 从 aof_pipe_read_ack_from_parent 读取到了 ！, 表示读取到了父级的确认 ack, 最后一次从 aof_pipe_read_data_from_parent 读取数据到 aof_child_diff, 确保在文件描述符中没有父进程写向子进程的数据了
> 8. 把 aof_child_diff 中的数据追加到临时的 AOF 文件中
> 9. 通过 rename 函数将临时文件重命名为配置的入参的文件名 (AOF 重写入参的文件名为: emp-rewriteaof-bg-进程ID.aof,  rename 函数会先将同名的文件, 文件夹删除)


从上面的过程中看起来, 好像完美了, 但是别忘了这里涉及到了并发, 在父子进程互相 ack 确认时, 父进程收到 ack 时, 只是把 aof_stop_sending_diff 设置为 true, 也就是确保重写缓存列表的数据不会在写给子进程。   
而子进程收到 ack, 只是把当前所有的重写缓存列表的数据写入到文件中, 然后将最新的文件替换为新的 AOF 文件。如果在子进程写入的过程中, 还有新的命令进来, 这些新的命令怎么处理的呢?   
正常的处理逻辑也很简单, 子进程结束后, 父级继续把当前重新缓存列表的数据追加到 AOF 文件即可, 最后 rename 文件为配置的 AOF 文件名即可。


**AOF 子进程重写结束后的逻辑**

首先入口, 还是在定时器 serveCron 中, 定时的检查子进程的状态是否为结束了, 是的话, 执行结束逻辑

```C
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {

    // 省略

    // 检查是否有 RDB 子进程或者 AOF 重写子进程结束了
    if (server.rdb_child_pid != -1 || server.aof_child_pid != -1 || ldbPendingChildren()){

        int statloc;
        pid_t pid;

        // wait3 可以获取所有的进程是否有一个进程退出状态的, 有的话, 进行彻底的销毁，同时返回其进程 id
        if ((pid = wait3(&statloc,WNOHANG,NULL)) != 0) {

            int exitcode = WEXITSTATUS(statloc);
            int bysignal = 0;

            if (WIFSIGNALED(statloc)) 
                bysignal = WTERMSIG(statloc);

            if (pid == -1) {
                // 异常情况, 打印日志
                serverLog(LL_WARNING,"wait3() returned an error: %s. rdb_child_pid = %d, aof_child_pid = %d", strerror(errno), (int) server.rdb_child_pid, (int) server.aof_child_pid);
            } else if (pid == server.rdb_child_pid) {
                // rdb 进程逻辑省略
            } else if (pid == server.aof_child_pid) {
                // 执行最终的清除逻辑
                backgroundRewriteDoneHandler(exitcode,bysignal);
                if (!bysignal && exitcode == 0) 
                    // 获取子进程发送给父进程的信息
                    receiveChildInfo();
            } else {
                // 其他的情况
                if (!ldbRemoveChild(pid)) {
                    serverLog(LL_WARNING, "Warning, detected child with unmatched pid: %ld", (long)pid);
                }
            }  

            // 重新设置字典的可以扩容标识为 true
            updateDictResizePolicy();
            closeChildInfoPipe();

        }

    } else {
        // 判断是否需要进行 RDB 或者 AOF 重写

        // 省略

    }

    // 省略
}
```

**AOF 重写结束后, 父级执行的逻辑**

```C
void backgroundRewriteDoneHandler(int exitcode, int bysignal) {
    
    // exitcode == 0 表示子进程是执行完逻辑后, 主动退出的
    if (!bysignal && exitcode == 0) {

        int newfd, oldfd;
        char tmpfile[256];
        long long now = ustime();
        mstime_t latency;

        serverLog(LL_NOTICE, "Background AOF rewrite terminated with success");

        latencyStartMonitor(latency);
        
        // 再次通过子进程的进程 ID 获取到 AOF 重写的临时文件名 temp-rewriteaof-bg-进程ID.aof
        snprintf(tmpfile,256,"temp-rewriteaof-bg-%d.aof",(int)server.aof_child_pid);

        newfd = open(tmpfile,O_WRONLY|O_APPEND);
        if (newfd == -1) {
            serverLog(LL_WARNING, "Unable to open the temporary AOF produced by the child: %s", strerror(errno));
            goto cleanup;
        }

        // 把最后剩余的信息从 aof_rewrite_buf_blocks 写入到指定的文件
        if (aofRewriteBufferWrite(newfd) == -1) {
            serverLog(LL_WARNING, "Error trying to flush the parent diff to the rewritten AOF: %s", strerror(errno));
            close(newfd);
            goto cleanup;
        }

        latencyEndMonitor(latency);
        latencyAddSampleIfNeeded("aof-rewrite-diff-write",latency);

        serverLog(LL_NOTICE,"Residual parent diff successfully flushed to the rewritten AOF (%.2f MB)", (double) aofRewriteBufferSize() / (1024*1024));

        // aof_fd 为当前的 AOF 文件的文件描述符, 等于 - 1, 应该是 AOF 功能禁用了
        // 这时为了下面的流程能走下去, 从配置文件中获取到配置的文件名, 尝试打开禁用前的文件
        if (server.aof_fd == -1) {
            oldfd = open(server.aof_filename,O_RDONLY|O_NONBLOCK);
        } else {
            oldfd = -1;
        }

        latencyStartMonitor(latency);
        // 将临时文件重命名为配置的文件名
        if (rename(tmpfile,server.aof_filename) == -1) {
            serverLog(LL_WARNING, "Error trying to rename the temporary AOF file %s into %s: %s", tmpfile, server.aof_filename, strerror(errno));
            close(newfd);
            if (oldfd != -1) close(oldfd);
            goto cleanup;
        }
        latencyEndMonitor(latency);
        latencyAddSampleIfNeeded("aof-rename",latency);

        if (server.aof_fd == -1) {
            close(newfd);
        } else {
            oldfd = server.aof_fd;
            server.aof_fd = newfd;

            // 根据同步策略进行 fsync
            if (server.aof_fsync == AOF_FSYNC_ALWAYS)
                redis_fsync(newfd);
            else if (server.aof_fsync == AOF_FSYNC_EVERYSEC)
                aof_background_fsync(newfd);
            server.aof_selected_db = -1; 
            // 更新当前 AOF 文件的大小
            aofUpdateCurrentSize();
            server.aof_rewrite_base_size = server.aof_current_size;
            server.aof_fsync_offset = server.aof_current_size;   

            sdsfree(server.aof_buf);
            server.aof_buf = sdsempty(); 
        }

        server.aof_lastbgrewrite_status = C_OK;

        serverLog(LL_NOTICE, "Background AOF rewrite finished successfully");

        if (server.aof_state == AOF_WAIT_REWRITE)
            server.aof_state = AOF_ON;

        // 关闭打开的文件
        if (oldfd != -1) 
            bioCreateBackgroundJob(BIO_CLOSE_FILE,(void*)(long)oldfd,NULL,NULL);    

        serverLog(LL_VERBOSE,"Background AOF rewrite signal handler took %lldus", ustime()-now);    
    }  else if (!bysignal && exitcode != 0) {

        server.aof_lastbgrewrite_status = C_ERR;

        serverLog(LL_WARNING, "Background AOF rewrite terminated with error");
    } else {

        if (bysignal != SIGUSR1)
            server.aof_lastbgrewrite_status = C_ERR;

        serverLog(LL_WARNING, "Background AOF rewrite terminated by signal %d", bysignal);
    }

cleanup:
    // 清除工作
    aofClosePipes();
    aofRewriteBufferReset();
    aofRemoveTempFile(server.aof_child_pid);
    server.aof_child_pid = -1;
    server.aof_rewrite_time_last = time(NULL)-server.aof_rewrite_time_start;
    server.aof_rewrite_time_start = -1;
    if (server.aof_state == AOF_WAIT_REWRITE)
        server.aof_rewrite_scheduled = 1;

}

ssize_t aofRewriteBufferWrite(int fd) {
    listNode *ln;
    listIter li;
    ssize_t count = 0;

    listRewind(server.aof_rewrite_buf_blocks,&li);
    while((ln = listNext(&li))) {
        aofrwblock *block = listNodeValue(ln);
        ssize_t nwritten;

        if (block->used) {
            nwritten = write(fd,block->buf,block->used);
            if (nwritten != (ssize_t)block->used) {
                if (nwritten == 0) errno = EIO;
                return -1;
            }
            count += nwritten;
        }
    }
    return count;
}
```

到了这一步, 整个 AOF 的重写过程才真正的结束了。


## 3.4 参考

[Redis源码剖析和注释（十八）--- Redis AOF持久化机制](https://blog.csdn.net/men_wen/article/details/71375513)
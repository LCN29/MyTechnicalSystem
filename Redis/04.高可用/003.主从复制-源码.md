# 3 主从复制 - 源码

因为主从复制的过程很复杂, 同时集中在 **replication.c** 这个文件中, 所以为了篇幅, 单独的把功能中涉及的大部分代码都集中到了另一篇文章。
这篇文章中, 这篇主要涉及主从复制的大体代码逻辑, 如果需要了解整体的过程, 可以配合 [03.主从复制-replication源码分析](https://www.baidu.com/) 这篇文章。

## 3.1 主从节点建立连接

Redis 主从节点建立连接的 3 种方式, 本质都是从节点执行 **slaveof** 命令, 和父节点建立初步的关联关系。   
这个命令执行的方法为 **replicaofCommand**。(高版本的 Redis 可以通过 replicaof 达到 slaveof 的效果)

```C
void replicaofCommand(client *c) {

    // 开启了集群功能, 直接返回, 集群模式不允许执行 slaveof 
    if (server.cluster_enabled) {
        addReplyError(c,"REPLICAOF not allowed in cluster mode.");
        return;
    }

    // 第一参数为 no, 第二个参数为 one
    // slaveof no one, 可以让从节点和主节点断开连接, 停止主从复制 
    if (!strcasecmp(c->argv[1]->ptr,"no") && !strcasecmp(c->argv[2]->ptr,"one")) {

        // 如果保存了主节点 IP, 当前节点为某个节点的从节点
        if (server.masterhost) {
            
            // 取消复制操作, 同时设置当前节点为主节点
            // 1. 置空 server.masterhost 
            // 2. 将第一组 replid 和 offset 赋值到第二组, 重试生成一个 replid
            // 3. 置空 server.cached_server
            // 4. 如果在传输 RDB 文件中或者处于握手阶段, 进行取消, 同时取消和主节点的连接
            // 5. 如果有从节点, 释放所有的从节点客户端, 也就是断开从节点的连接
            // 6. 当前节点的状态变为 REPL_STATE_NONE (普通状态, 无主从复制状态)
            replicationUnsetMaster();

            // 获取 client 的每种信息, 并以 sds 形式返回, 并打印到日志中
            sds client = catClientInfoString(sdsempty(),c);
            serverLog(LL_NOTICE,"MASTER MODE enabled (user request from '%s')", client);
            sdsfree(client);
        }

    } else {

        // 当前的客户端的标识为从节点标识
        // 本身是一个从节点了, 无法在执行 salveof ip 端口
        if (c->flags & CLIENT_SLAVE) {

            addReplyError(c, "Command is not valid when client is a replica.");
            return;
        }

        // 从入参中获取端口
        if ((getLongFromObjectOrReply(c, c->argv[2], &port, NULL) != C_OK))
            return;

        // 已经有主节点了, 同时主节点的的 host 和 ip 和入参的相同
        if (server.masterhost && !strcasecmp(server.masterhost,c->argv[1]->ptr) && server.masterport == port) {    

            serverLog(LL_NOTICE,"REPLICAOF would result into synchronization with the master we are already connected with. No operation performed.");
            addReplySds(c,sdsnew("+OK Already connected to specified master\r\n"));
            return;
        }

        // 1. 保存主节点的 IP 和 端口到 server.masterhost 和 server.masterport
        // 2. 解除所有阻塞状态的客户端
        // 3. 释放所有的从节点信息
        // 4. 取消主从复制的握手操作
        // 5. 上次有主节点了, 为 server.cached_server 赋值一个默认生成的 client
        // 6. 设置当前的节点的状态为 REPL_STATE_CONNECT (待连接上主节点)
        replicationSetMaster(c->argv[1]->ptr, port);

        // 生成当前客户端的信息的字符串
        sds client = catClientInfoString(sdsempty(),c);
        serverLog(LL_NOTICE,"REPLICAOF %s:%d enabled (user request from '%s')", server.masterhost, server.masterport, client);
        sdsfree(client);    
    }

    addReply(c,shared.ok);
}
```

当前第一步主要的逻辑就是将当前的主节点的 IP 和 Post 保存起来, 同时经过这一步, 当前实例的复制状态设置为 REPL_STATE_CONNECT。
执行完上的逻辑后, salveof (replicaof) 就结束的, 但是整个的主从复制还没有开始, 可以得出 salveof 是一个异步的命令。 接下来的步骤则是由定时函数 serverCron 定时的调用。

## 3.2 主从网络连接建立

在第一步中, 只是将主节点的信息保存到从节点中就结束了, 之间还是没有建立起相关的网络连接的, 第二步就是完成这个网络连接的操作。
而这个网络连接建立的触发是通过定时函数执行的

```C
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {

    // 省略

    // 定时 1 秒执行一次
    run_with_period(1000) replicationCron();

    // 省略
}
```

replicationCron 里面涉及到了大量的逻辑, 基本整个复制运行阶段的状态判断等都是在里面判断的, 这里只截取了涉及到当前步骤相关的逻辑。
在第一步操作完成后, 可以知道从节点当前的状态为 **REPL_STATE_CONNECT**。

```C
void replicationCron(void) {

    // 省略

    // 当前的状态为 REPL_STATE_CONNECT (开启了主从复制, 但是还没连接上主节点), 顺利执行了 salveof 后, 从节点的默认状态
    if (server.repl_state == REPL_STATE_CONNECT) {

        // 尝试连接主节点, 连接成功后, 从节点的状态会变为 REPL_STATE_CONNECTING (正在连接主节点)

        // 1. 通过保存的 IP 和 Port 和主节点建立一个 TCP 连接
        // 2. 向事件轮询添加对应的 Socket 通道的读写事件
        // 3. 更新当前节点的状态为 REPL_STATE_CONNECTING (正在连接主节点)
        if (connectWithMaster() == C_OK) {
            serverLog(LL_NOTICE, "MASTER <-> REPLICA sync started");
        }
    }

    // 省略
}
```


第二步的逻辑很简单, 和主节点建立起了 Socket 连接, 同时将当前节点的状态更新为 REPL_STATE_CONNECTING

## 3.3 发送 PING 命令

在第二步的步骤中, 通过保存的主节点 IP 和端口建立起连接后, 会向事件轮询中注册一个 AE_READABLE|AE_WRITABLE 的事件, 
在底层的 epollo 中就是同时注册了一个 EPOLLIN | EPOLLOUT 事件, 这样会触发一次 EPOLLOUT 事件, 也就是触发一次  AE_WRITABLE 事件,
也就是在下次事件轮询中会执行到其注册的函数 syncWithMaster 函数, 所以第三步的入口就是这个函数了。

同样的这个方法涉及到了大量的主从通信复制相关的逻辑, 整个逻辑很复杂, 所以也截取了相关的代码

```C
// 入参中的 fd 就是和主节点建立的 Socket 连接的文件描述符
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    int sockerr = 0;
    socklen_t errlen = sizeof(sockerr);
    
    UNUSED(el);
    UNUSED(privdata);
    UNUSED(mask);

    // 状态为 REPL_STATE_NONE, 关闭对应的文件描述符
    if (server.repl_state == REPL_STATE_NONE) {
        close(fd);
        return;
    }

    // 检查当前的 Socket 通道的状态
    if (getsockopt(fd, SOL_SOCKET, SO_ERROR, &sockerr, &errlen) == -1)
        // 获取异常信息
        sockerr = errno;

    // 有异常信息
    if (sockerr) {
        serverLog(LL_WARNING,"Error condition on socket for SYNC: %s", strerror(sockerr));
        goto error;
    }

    // 从节点和父节点建立了 Socket 后的第一个状态为 REPL_STATE_CONNECTING
    if (server.repl_state == REPL_STATE_CONNECTING) {

        serverLog(LL_NOTICE,"Non blocking connect for SYNC fired the event.");
        
        // 删除当前这个 Socket 的可写事件, 不关心写事件
        aeDeleteFileEvent(server.el,fd,AE_WRITABLE);

        // 状态修改为 REPL_STATE_RECEIVE_PONG (发送 pong, 等待 ping 回答)
        server.repl_state = REPL_STATE_RECEIVE_PONG;
        
        // 发送同步命令, 也就是 ping 到主节点, SYNC_CMD_WRITE = 1
        err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"PING",NULL);
        if (err) 
            goto write_error;
        return;
    }
}
```

从节点向主节点发送了一个 Ping 的命令, 这时候主节点收到了从节点的 Ping 命令后, 处理正常后, 会响应一个 Pong 的命令。

**主节点**执行的 Ping 命令的逻辑如下

```C
void pingCommand(client *c) {

    // ping 命令的参数只能是 1 个或者 0 个
    if (c->argc > 2) {
        addReplyErrorFormat(c,"wrong number of arguments for '%s' command", c->cmd->name);
        return;
    }

    // 对应的客户端处于 Pub/Sub 模式
    if (c->flags & CLIENT_PUBSUB) {
        addReply(c,shared.mbulkhdr[2]);
        addReplyBulkCBuffer(c,"pong",4);
        if (c->argc == 1)
            addReplyBulkCBuffer(c,"",0);
        else
            addReplyBulk(c,c->argv[1]);
    } else {

        // 其他模式
        // 参数是 1 个, 响应一个 pong
        if (c->argc == 1)
            addReply(c,shared.pong);
        else
            // 响应入参的第 2 个参数
            addReplyBulk(c,c->argv[1]);
    }
}
```

**从节点** 收到了主节点发送过来的 Pone 响应命令, 同时在上面第 2 步就建立了对应的可读事件, 这时事件轮询循环中找到了可读事件, 又执行到 **syncWithMaster** 函数

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略
    
    // 当前从节点处于 REPL_STATE_RECEIVE_PONG 状态 (发送 ping, 等待 pong  应答)
    if (server.repl_state == REPL_STATE_RECEIVE_PONG) {

        // 读取主节点响应的信息
        err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);

        // 异常情况
        if (err[0] != '+' && strncmp(err,"-NOAUTH",7) != 0 && strncmp(err,"-ERR operation not permitted",28) != 0) {
            serverLog(LL_WARNING,"Error reply to PING from master: '%s'",err);
            sdsfree(err);
            goto error;
        } else {
            // 响应的是 Pong, 响应了 Ping 请求, 能继续处理
            serverLog(LL_NOTICE, "Master replied to PING, replication can continue...");
        }

        sdsfree(err);
        // 状态切换到 REPL_STATE_SEND_AUTH, 等待认证结果应答
        server.repl_state = REPL_STATE_SEND_AUTH;
    }
}
```

## 3.4 认证权限

在从节点发送 Ping, 主节点响应 Pong , 从节点收到 Pong 响应后, 进入处理时 (syncWithMaster 函数), 
状态修改为 **REPL_STATE_SEND_AUTH** 后, 方法继续执行下去, 立即进入认证权限的过程。

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // 当前从节点处于 REPL_STATE_RECEIVE_PONG 状态 (发送 ping, 等待 pong  应答)
    if (server.repl_state == REPL_STATE_RECEIVE_PONG) {

        // 省略

        // 状态切换到 REPL_STATE_SEND_AUTH, 等待认证结果应答
        server.repl_state = REPL_STATE_SEND_AUTH;
    }

    // 进入认证, 如果需要的话
    if (server.repl_state == REPL_STATE_SEND_AUTH) {

        // 配置了主节点的密码
        if (server.masterauth) {

            // 发送认证请求和密码到主节点
            err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"AUTH",server.masterauth,NULL);
            if (err) 
                goto write_error;

            // 状态切换为 REPL_STATE_RECEIVE_AUTH (等待认证结果响应)
            server.repl_state = REPL_STATE_RECEIVE_AUTH;
            return;
        } else {
            // 不需要认证, 状态之间切换为 REPL_STATE_SEND_PORT 准备发送端口
            server.repl_state = REPL_STATE_SEND_PORT;
        }
    }
}
```

**从节点**根据是否配置了主节点认证密码, 走不同的逻辑
> 1. 配置了认证密码, 发送 auth 密码, 同时带上密码到主节点, 同时状态变为 REPL_STATE_RECEIVE_AUTH (等待主节点响应认证结果应答)
> 2. 没有配置认证密码, 直接将状态变为 REPL_STATE_SEND_PORT (准备发送从节点的监听的端口)


**主节点**收到从节点的认证请求 auth, 就会进入到权限认证的过程,  执行的逻辑如下:

```C
void authCommand(client *c) {

    // 主节点不需要密码认证
    if (!server.requirepass) {
        addReplyError(c,"Client sent AUTH, but no password is set");
    } else if (!time_independent_strcmp(c->argv[1]->ptr, server.requirepass)) {
        // 密码认证成功  
        c->authenticated = 1;
        addReply(c,shared.ok);
    } else {
        // 密码认证失败  
        c->authenticated = 0;
        addReplyError(c,"invalid password");
    }
}
```

**主节点**收到从节点的 auth 命令后
> 1. 本身没有设置密码, 直接返回错误
> 2. 收到的密码和自身配置的密码一样, 返回成功
> 3. 收到的密码和自身配置的密码不一样, 返回错误

同 **Ping Pong** 的处理逻辑一样, 这时**从节点**读取到主节点的响应, 事件轮询触发 **syncWithMaster** 函数

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 当前从节点处于 REPL_STATE_RECEIVE_PONG 状态 (发送 ping, 等待 pong  应答)
    if (server.repl_state == REPL_STATE_RECEIVE_PONG) {
        // 省略

         // 状态切换为 REPL_STATE_RECEIVE_AUTH (等待认证结果响应)
        server.repl_state = REPL_STATE_RECEIVE_AUTH;
        return;
    }

    // 接收到请求认证的响应
    if (server.repl_state == REPL_STATE_RECEIVE_AUTH) {

        // 读取响应信息
        err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);
        
        // 认证失败
        if (err[0] == '-') {
            serverLog(LL_WARNING,"Unable to AUTH to MASTER: %s",err);
            sdsfree(err);
            goto error;
        }

        // 认证成功
        sdsfree(err);
        // 状态变为 REPL_STATE_SEND_PORT (准备发送从节点的监听的端口)
        server.repl_state = REPL_STATE_SEND_PORT;
    }
}
```

## 3.5 发送端口号

在不需要权限认证或者从节点收到主节点的权限认证成功后, 此时从节点的状态为 **REPL_STATE_SEND_PORT**, 顺着上一步的处理逻辑中, 继续处理

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // 收到权限认证的响应
    if (server.repl_state == REPL_STATE_RECEIVE_AUTH) {

        // 配置了主节点的密码
        if (server.masterauth) {
            // 省略
        } else {
            // 不需要认证, 状态之间切换为 REPL_STATE_SEND_PORT 准备发送端口
            server.repl_state = REPL_STATE_SEND_PORT;
        }
    }
    
    // 接收到请求认证的响应
    if (server.repl_state == REPL_STATE_RECEIVE_AUTH) {
        // 省略
        // 状态变为 REPL_STATE_SEND_PORT (准备发送从节点的监听的端口)
        server.repl_state = REPL_STATE_SEND_PORT;
    }

    // 进入发送端口阶段
    if (server.repl_state == REPL_STATE_SEND_PORT) {

        // 如果有配置一个专门复制的端口的话, 使用配置的端口, 没有使用当前服务器的端口
        sds port = sdsfromlonglong(server.slave_announce_port ? server.slave_announce_port : server.port);

        // 发送端口信息给主节点 命令: replconf listening-port 端口
        err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"REPLCONF", "listening-port",port, NULL);
        sdsfree(port);
        if (err) 
            goto write_error;
        sdsfree(err);
        // 切换状态为 REPL_STATE_RECEIVE_PORT ()
        server.repl_state = REPL_STATE_RECEIVE_PORT;
        return;
    }
}
```

**主节点**收到从节点的发送端口请求 REPLCONF, 执行的逻辑如下

```C
void replconfCommand(client *c) {

    int j;

    // 参数需要是 2 的倍数
    if ((c->argc % 2) == 0) {
        addReply(c,shared.syntaxerr);
        return;
    }

    for (j = 1; j < c->argc; j+=2) {

        // 每个循环使用 2 个参数

        // replconf listening-port port
        if (!strcasecmp(c->argv[j]->ptr,"listening-port")) {

            long port;

            // 获取下一个项, 也就是端口号
            if ((getLongFromObjectOrReply(c,c->argv[j+1], &port,NULL) != C_OK))
                return;

            // 保存到对应的客户端的 slave_listening_port     
            c->slave_listening_port = port;
        } else if (!strcasecmp(c->argv[j]->ptr,"ip-address")) {
            // 省略
        } else if (!strcasecmp(c->argv[j]->ptr,"capa")) {
            // 省略
        } else if (!strcasecmp(c->argv[j]->ptr,"ack")) {
            // 省略
        }  else if (!strcasecmp(c->argv[j]->ptr,"getack")) {
            // 省略
        } else {
            // 响应错误
            addReplyErrorFormat(c,"Unrecognized REPLCONF option: %s", (char*)c->argv[j]->ptr);
            return;
        }
    }

    // 响应 OK 
    addReply(c,shared.ok);
}
```

可以看到主节点收到从节点发送过来的端口, 会保存到从节点客户端 client 的 slave_listening_port 字段。

收到主节点的响应后, 从节点同样是事件轮询触发 **syncWithMaster** 函数

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // 进入发送端口阶段
    if (server.repl_state == REPL_STATE_SEND_PORT) {

        // 省略

        // 切换状态为 REPL_STATE_RECEIVE_PORT ()
        server.repl_state = REPL_STATE_RECEIVE_PORT;
        return;
    }

    // REPL_STATE_RECEIVE_PORT 等待主节点响应发送 IP 请求的响应
    if (server.repl_state == REPL_STATE_RECEIVE_PORT) {

        err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);
        if (err[0] == '-') {
            serverLog(LL_NOTICE,"(Non critical) Master does not understand REPLCONF listening-port: %s", err);
        }
        sdsfree(err);
        // 状态变为 REPL_STATE_SEND_IP, 准备发送 IP 到主节点
        server.repl_state = REPL_STATE_SEND_IP;
    }

}
```

## 3.6 发送 IP 地址

收到主节点对 **REPLCONF listening-port 端口** 的响应后, 从节点会将状态修改为 **REPL_STATE_SEND_IP**, 然后顺着逻辑走下去

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // REPL_STATE_RECEIVE_PORT 等待主节点响应发送 IP 请求的响应
    if (server.repl_state == REPL_STATE_RECEIVE_PORT) {
        // 省略

        // 状态变为 REPL_STATE_SEND_IP, 准备发送 IP 到主节点
        server.repl_state = REPL_STATE_SEND_IP;
    }

    // 没有配置宣布的 IP, slave_announce_ip 为空, 直接跳过发送 IP 的阶段
    if (server.repl_state == REPL_STATE_SEND_IP && server.slave_announce_ip == NULL) {
        // 进入下一个节点 准备发送从节点的发送能力
        server.repl_state = REPL_STATE_SEND_CAPA;
    }

    if (server.repl_state == REPL_STATE_SEND_IP) {

        // 发送 REPLCONF ip-address ip
        err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"REPLCONF", "ip-address",server.slave_announce_ip, NULL);
        if (err) 
            goto write_error;
        sdsfree(err);

        // 状态变为 REPL_STATE_RECEIVE_IP (等待主节点响应收到从节点的 IP 地址)
        server.repl_state = REPL_STATE_RECEIVE_IP;
        return;
    }
}

```

从节点进入发送 IP 地址阶段时, 除了状态需要为 REPL_STATE_SEND_IP (准备发送 IP 地址阶段), 还必须有指定 slave_announce_ip, 从节点的 IP (对应配置文件的 slave-announce-ip),  
2 个条件都满足的情况下, 才会真正的进入发送 IP 地址, 否则直接进入下一阶段。

**主节点**收到从节点的发送的 **REPLCONF ip-address IP** 请求, 执行的逻辑如下

```C
void replconfCommand(client *c) {

    int j;

    // 参数需要是 2 的倍数
    if ((c->argc % 2) == 0) {
        addReply(c,shared.syntaxerr);
        return;
    }

    
    for (j = 1; j < c->argc; j+=2) {
        // 每个循环使用 2 个参数

         if (!strcasecmp(c->argv[j]->ptr,"listening-port")) {
            // 省略
        } else if (!strcasecmp(c->argv[j]->ptr,"ip-address")) {

            // replconf ip-address ip

            // 获取对应的从节点发送的 IP 
            sds ip = c->argv[j+1]->ptr;

            // IP 的长度判断
            if (sdslen(ip) < sizeof(c->slave_ip)) {
                // 保存到客户端的 client 的 slave_ip 属性
                memcpy(c->slave_ip,ip,sdslen(ip)+1);
            } else {
                // 错误提示
                addReplyErrorFormat(c,"REPLCONF ip-address provided by replica instance is too long: %zd bytes", sdslen(ip));
                return;
            }

        } else if (!strcasecmp(c->argv[j]->ptr,"capa")) {
            // 省略
        } else if (!strcasecmp(c->argv[j]->ptr,"ack")) {
            // 省略
        }  else if (!strcasecmp(c->argv[j]->ptr,"getack")) {
            // 省略
        } else {
            // 响应错误
            addReplyErrorFormat(c,"Unrecognized REPLCONF option: %s", (char*)c->argv[j]->ptr);
            return;
        }

    }

    // 响应 OK 
    addReply(c,shared.ok);
}
```

主节点收到从节点发送的 IP 地址, 会将其保存到从节点的客户端 client 的 slave_ip 字段。

**从节点**收到主节点的响应后, 同样是由事件轮询触发 **syncWithMaster** 函数

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // 收到主节点对发送 IP 请求的响应
    if (server.repl_state == REPL_STATE_RECEIVE_IP) {

        err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);

        if (err[0] == '-') {
            serverLog(LL_NOTICE,"(Non critical) Master does not understand REPLCONF ip-address: %s", err);
        }
        sdsfree(err);

        // 状态变为等待发送发送能力状态
        server.repl_state = REPL_STATE_SEND_CAPA;
    }
}
```

## 3.7 发送同步能力 (数据同步的方式)

收到主节点响应的 IP 请求, 从节点的状态切换为了 REPL_STATE_SEND_CAPA, 
如果从节点没有配置  slave-announce-ip, 也就不会有发送 IP 相关的操作, 也会直接过度到 REPL_STATE_SEND_CAPA,

状态切换到 REPL_STATE_SEND_CAPA 后, 会继续下面的逻辑, 同样在 **syncWithMaster** 函数

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // 没有配置宣布的 IP, slave_announce_ip 为空, 直接跳过发送 IP 的阶段
    if (server.repl_state == REPL_STATE_SEND_IP && server.slave_announce_ip == NULL) {
        // 进入下一个节点 准备发送从节点的发送能力
        server.repl_state = REPL_STATE_SEND_CAPA;
    }

    // 省略

    // 收到主节点对发送 IP 请求的响应
    if (server.repl_state == REPL_STATE_RECEIVE_IP) {

        // 状态变为等待发送发送能力状态
        server.repl_state = REPL_STATE_SEND_CAPA;
    }


    if (server.repl_state == REPL_STATE_SEND_CAPA) {

        // 发送从节点支持的发送能力到主节点 
        // REPLCONF capa eof capa psync2
        err = sendSynchronousCommand(SYNC_CMD_WRITE,fd,"REPLCONF", "capa","eof","capa","psync2",NULL);
        if (err) goto write_error;
        sdsfree(err);
        // 状态修改为 REPL_STATE_RECEIVE_CAPA, 等待主节点响应发送能力的应答
        server.repl_state = REPL_STATE_RECEIVE_CAPA;
        return;
    }
}
```

从节点发送过去的支持的 2 种发送能力
> 1. eof: 全量复制, 能够解析出 RDB 文件的 EOF 流格式
> 2. psync2: 部分复制, 利用复制积压缓冲区等实现部分同步


**主节点**收到从节点的发送能力请求 REPLCONF, 执行的逻辑如下

```C
void replconfCommand(client *c) {

    int j;

    // 参数需要是 2 的倍数
    if ((c->argc % 2) == 0) {
        addReply(c,shared.syntaxerr);
        return;
    }

    for (j = 1; j < c->argc; j+=2) {

        // 每个循环使用 2 个参数

        if (!strcasecmp(c->argv[j]->ptr,"listening-port")) {
            // 省略
        } else if (!strcasecmp(c->argv[j]->ptr,"ip-address")) {
            // 省略
        } else if (!strcasecmp(c->argv[j]->ptr,"capa")) {

            if (!strcasecmp(c->argv[j+1]->ptr,"eof"))
                // SLAVE_CAPA_EOF = 1
                c->slave_capa |= SLAVE_CAPA_EOF;
            else if (!strcasecmp(c->argv[j+1]->ptr,"psync2"))
                // SLAVE_CAPA_PSYNC2 = 2 
                c->slave_capa |= SLAVE_CAPA_PSYNC2;

            // 如果不支持的能力, 不做处理
        } else if (!strcasecmp(c->argv[j]->ptr,"ack")) {
            // 省略
        }  else if (!strcasecmp(c->argv[j]->ptr,"getack")) {
            // 省略
        } else {
            // 响应错误
            addReplyErrorFormat(c,"Unrecognized REPLCONF option: %s", (char*)c->argv[j]->ptr);
            return;
        }
    }
    
    // 响应 OK 
    addReply(c,shared.ok);
}
```

**从节点**收到主节点的响应后, 从节点同样是事件轮询触发 **syncWithMaster** 函数

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {
    
    // 省略

    // 读取主节点发送过来的信息
    if (server.repl_state == REPL_STATE_RECEIVE_CAPA) {
        err = sendSynchronousCommand(SYNC_CMD_READ,fd,NULL);

        if (err[0] == '-') {
            serverLog(LL_NOTICE,"(Non critical) Master does not understand REPLCONF capa: %s", err);
        }
        sdsfree(err);

        // 向主节点发送 psync 命令, 请求全量复制
        server.repl_state = REPL_STATE_SEND_PSYNC;
    }

    // 省略
}
```

## 3.8 发送 PSYNC 命令

**从节点**收到了主节点对其同步能力的响应后, 这是会发送一个 psync 的命令给主节点, 这个请求就是同步复制的真正开始了

```C
void syncWithMaster(aeEventLoop *el, int fd, void *privdata, int mask) {

    // 省略

    // 读取主节点发送过来的信息
    if (server.repl_state == REPL_STATE_RECEIVE_CAPA) {

        // 省略

        // 向主节点发送 psync 命令, 请求全量复制
        server.repl_state = REPL_STATE_SEND_PSYNC;
    }

    // 发送 psync 命令
    if (server.repl_state == REPL_STATE_SEND_PSYNC) {

        // 入参的 0 表示写消息给主节点, 1 表示从主节点读取数据
        // 入参 0 的逻辑, 根据当前是否缓存了主节点, 既 cached_master 是否为空, 来发送 psync 命令, 为空, 发送全量同步请求, 不为空, 发送部分同步请求
        if (slaveTryPartialResynchronization(fd,0) == PSYNC_WRITE_ERROR) {
            err = sdsnew("Write error sending the PSYNC command.");
            goto write_error;
        }

        // 切换状态为 REPL_STATE_RECEIVE_PSYNC (等待 psync 应答)
        server.repl_state = REPL_STATE_RECEIVE_PSYNC;
        return;
    }
}
```

slaveTryPartialResynchronization 函数可以根据入参进行写消息给主节点和读取主节点消息, 因为上面只涉及到写的操作，下面梳理的是写部分的逻辑
> 1. 声明了 2 个变量 psync_replid 和 psync_offset, 前面的用来存储节点的 replid, 后者存储的是同步复制积压缓冲区的同步到的位置
> 2. 首先根据自身保存的 server.cached_master 为空, 得出 2 个变量的值
> 3. 如果 server.cached_master 不为空, psync_replid 等于 cached_master.replid, psync_offset 等于 cached_master.reploff + 1
> 4. 如果 server.cached_master 为空, psync_replid 等于 ?, psync_offset 等于 -1
> 5. server.cached_master 不为空, 表示从节点上次是有主节点的, 当前可能是重启等情况, 导致从节点重新走了一次复制的流程, 可以尝试进行部分复制, 不进行全量复制
> 6. 向主节点发送 psync <psync_replid> <psync_offset>, 也就是 psync ? -1 或者 psync replid offset, 后者主节点收到后会直接判定为全量复制, 后者主节点会判断是否可进行部分复制

上面就是 slaveTryPartialResynchronization 写操作的逻辑

**主节点**收到从节点的发送过来的同步请求命令 psync, 执行的逻辑如下

```C
void syncCommand(client *c) {

    // 客户端不是从节点, 直接返回
    if (c->flags & CLIENT_SLAVE) 
        return;

    // 当前节点是另一个节点的从节点, 同时节点的状态不是 REPL_STATE_CONNECTED (已经连接状态), 直接返回
    if (server.masterhost && server.repl_state != REPL_STATE_CONNECTED) {
        addReplySds(c,sdsnew("-NOMASTERLINK Can't SYNC while not connected with my master\r\n"));
        return;
    }   

    // 判断 client c 的 bufpos != 0 || reply 有数据
    // 也就是判断当前节点有数据准备发送给从节点, 是的话, 直接返回
    if (clientHasPendingReplies(c)) {
        addReplyError(c,"SYNC and PSYNC are invalid with pending output");
        return;
    }

    // 打日志
    serverLog(LL_NOTICE,"Replica %s asks for synchronization",replicationGetSlaveName(c)); 

    // 执行的命令为 psync
    if (!strcasecmp(c->argv[0]->ptr,"psync")) {

        // 主节点尝试进行部分同步复制, 
        // 部分复制成功了 stat_sync_partial_ok 部分同步成功次数 + 1, 然后直接结束
        if (masterTryPartialResynchronization(c) == C_OK) {
            server.stat_sync_partial_ok++;
            return;
        }

        char *master_replid = c->argv[1]->ptr;
        
        // 从节点指定了 replid, 但是现在部分复制失败了
        if (master_replid[0] != '?') 
            // 部分同步复制失败次数 + 1
            server.stat_sync_partial_err++;
    } else {
        // 执行的命令不是 psync, 也就是 sync 命令
        c->flags |= CLIENT_PRE_PSYNC;
    }

    // 全量复制

    // 全量复制次数 + 1
    server.stat_sync_full++;
    // 修改从节点的状态为等待 bgsave 的开始
    c->replstate = SLAVE_STATE_WAIT_BGSAVE_START;

    // 关闭了 TCP_NODELAY 功能
    if (server.repl_disable_tcp_nodelay)
        // 启用 nagle 算法
        anetDisableTcpNoDelay(NULL, c->fd);

    c->repldbfd = -1;
    // 客户端设置从节点标识
    c->flags |= CLIENT_SLAVE;
    // 把当前的客户端添加到从节点列表
    listAddNodeTail(server.slaves,c);       

    // 如果有需要, 创建复制积压缓冲区
    // 从节点只有 1 个, 复制积压缓冲区为空
    if (listLength(server.slaves) == 1 && server.repl_backlog == NULL) {

        // 生成 replid, 存放到 server.replid 中
        changeReplicationId();
        // 清除 replid2 和 second_replid_offset
        clearReplicationId2();
        // 创建复制积压缓冲区
        createReplicationBacklog();
    }

    if (server.rdb_child_pid != -1 && server.rdb_child_type == RDB_CHILD_TYPE_DISK) {
        // 正在执行 RDB, 同时类型是写入磁盘, 也就是普通的 RDB 

        client *slave;
        listNode *ln;
        listIter li;

        listRewind(server.slaves,&li);

        // 遍历所有的从节点, 找到第一个节点的状态为 SLAVE_STATE_WAIT_BGSAVE_END (等待 bgsave 的结束, 即等待 RDB 文件的创建结束)
        while((ln = listNext(&li))) {
            slave = ln->value;
            if (slave->replstate == SLAVE_STATE_WAIT_BGSAVE_END) 
                break;
        }

        // 有找到对应的节点, 当前客户端的节点的复制能力和找到的节点的复制能力一样
        if (ln && ((c->slave_capa & slave->slave_capa) == slave->slave_capa)) {
            
            // 把找到的节点的输出缓存复制到当前的客户端
            // 将 slave 的 buf 拷贝到 c 的 buf
            // 将 slave 的 reply_bytes 拷贝到 c 的 reply_bytes
            // 将 slave 的 bufpos 设置等于 c 的 bufpos
            copyClientOutputBuffer(c,slave);

            // 更新从节点客户端的偏移量, 状态和发送全量复制消息给从节点
            // 这个命令会发送 FULLRESYNC master_run_id offset\r\n 的响应给从节点, 可以看做是对 psync 命令的响应
            replicationSetupSlaveForFullResync(c,slave->psync_initial_offset);
            serverLog(LL_NOTICE,"Waiting for end of BGSAVE for SYNC");

        } else {
            // 找不到 或者找到的节点和当前的客户端的能力不一样, 只能等待下次的 bgsave 
            serverLog(LL_NOTICE,"Can't attach the replica to the current BGSAVE. Waiting for next BGSAVE for SYNC");
        }

    } else if (server.rdb_child_pid != -1 && server.rdb_child_type == RDB_CHILD_TYPE_SOCKET) {

        // 正在执行 RDB, 同时类型是写入 Socket, 也就是复制同步的 RDB
        // 提示等待下次同步
        serverLog(LL_NOTICE,"Current BGSAVE has socket target. Waiting for next BGSAVE for SYNC");
    } else { 

        // 没有在执行 RDB 
        // 复制类型为无盘同步 同时 当前的客户端执行 EOF 的同步方式, 也就是 RDB 文件流

        if (server.repl_diskless_sync && (c->slave_capa & SLAVE_CAPA_EOF)) {

            // 支持延迟无盘同步, 打印日志后结束
            // 后续在定时器执行的 replicationCron 函数时, 会创建出子进程进行同步
            // 延迟一段时间, 可以等待几个从节点, 后面同步处理

            if (server.repl_diskless_sync_delay)
                serverLog(LL_NOTICE,"Delay next BGSAVE for diskless SYNC");
        } else {

            // 没有子进程正在执行 BGSAVE, 且没有进行写 AOF 文件, 则开始为复制执行 BGSAVE, 并且是将 RDB 文件写到磁盘上
            if (server.aof_child_pid == -1) {
                // 内部和 RDB 的操作类型, 分为主子进程, 子进程进行 RDB 的生成, fork 出子进程后,
                // 主进程也会通过 replicationSetupSlaveForFullResync 函数进行 psync 的应答
                startBgsaveForReplication(c->slave_capa);
            } else {
                // 延迟执行 
                serverLog(LL_NOTICE, "No BGSAVE in progress, but an AOF rewrite is active. BGSAVE for replication delayed");
            }
        }
    }
    return;
}
```



## 
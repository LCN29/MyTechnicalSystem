# 3 ConcurrentHashMap (JDK-1.8版本)

## 3.1 ConcurrentHashMap 简介
 
Map 一种存储键值对 (key-value) 的数据结构, 可以通过 key 快速地定位到需要的 value, 在 Java 中是一个使用频率很高的一个数据结构。一般情况下, 我们都是可以直接使用它的实现类 HashMap 就能满足需求了。  
但是 HashMap 在多线程情况, 并不是一个线程安全的类。解决的方式的话  
> 1. 使用在 Java 体系中古老的 Hashtable 作为替代, 该类基本上所有的方法都采用 synchronized 进行线程安全的控制, 虽然保证了线程安全, 但是牺牲了很大的性能。 在高并发的情况下, 每次只有一个线程能够获取对象监视器锁, 这样的并发性能的确不令人满意。  
> 2. 通过 Collections 的 synchronizedMap(Map<K,V> m) 方法返回一个线程安全的 Map。但是这个的效果实际上和 Hashtable 的一样, 依然是采用 synchronized 独占式锁进行线程安全的并发控制的, 所以这种方案的性能也是令人不太满意的。

那么有没有一种既保证了线程安全性, 性能也不错的 Map 呢? ConcurrentHashMap 就是我们的选择了, 内部利用了**锁分段**的思想提高了并发度。当然的, 随着 JDK 的升级, ConcurrentHashMap 的实现也有了不同的方式。  
大体了分为 2 个版本: 1.6 版本的 和 1.8 版本。

ConcurrentHashMap 在 JDK 1.6 的版本网上资料很多, 有兴趣的可以去看看。 JDK 1.6 版本关键要素: 
> 1. segment 继承了 ReentrantLock 充当锁的角色, 为每一个 segment 提供了线程安全的保障
> 2. segment 维护了哈希散列表的若干个桶, 每个桶由 HashEntry 构成的链表

而到了 JDK 1.8 的 ConcurrentHashMap 就有了很大的变化, 光是代码量就足足增加了很多。1.8 版本舍弃了 segment, 并且大量使用了 synchronized, 以及 CAS 无锁操作以保证 ConcurrentHashMap 操作的线程安全性。  
至于为什么不用 ReentrantLock 而是 Synchronzied 呢? 实际上, synchronzied 在 JDK 1.6 做了很多的优化, 包括偏向锁, 轻量级锁, 重量级锁, 可以依次向上升级锁状态。  
因此, 使用 synchronized 相较于 ReentrantLock 的性能会持平甚至在某些情况更优, 具体的性能测试可以去网上查阅一些资料。另外, 底层数据结构改变为采用数组 + 链表 + 红黑树的数据形式。  

## 3.2 ConcurrentHashMap 的关键属性, 类和 CAS 方法

在了解 ConcurrentHashMap 的具体方法实现前, 我们需要系统的来看一下几个关键的地方, 从这几个地方, 从大体上了解 ConcurrentHashMap 的一些特性。

### 3.2.1 常量设置 (这些设置基本和 HashMap 的类似)

> 1. ConcurrentHashMap 内部是使用一个数组存放数据的,  这个数组的长度必须是 2 的 n 次方, 默认的容量是 16, 最大是 1 << 30, 既 2 的 30 次方
> 2. 默认负载因子为 0.75, 当数组的的存数据的项 >= 数组的长度 * 负载因子, 就会进行数组长度扩容
> 3. 数组的每一项, 在 JDK 1.8 中, 可以是链表, 也可以是红黑树。
> 4. 当数组的长度大于等于 64, 数组的某一项的长度大于等于 8, 会转为红黑树, 小于等于 6, 会重新转为链表
> 5. key 和 value 都不允许为 null (HashMap 允许一个 key 为 null 和 不限制的 value 为 null)
> 6. 在 ConcurrentHash 中数组中的每个节点的 hash 都有特殊作用

ConcurrentHash 中数组中的节点的 hash 值不同的含义
> 1. **>= 0**, 表明这个节点为 Node, 既链表节点
> 2. **-1**, 表明这个节点为 ForwardingNode, 说明这个位置正在数据迁移, 即这个位置的数据正在迁到新的数组的指定位置中
> 3. **-2**, 表明这个节点为 TreeBin, 树节点 TreeNode 的进一步封装
> 4. **-3**, 表明这个节点为 ReservationNode, 通过 JDK 1.8 新增的几个方法给 ConcurrentHashMap 设值时, 会先对应位置的节点变为 ReservationNode, 在做处理

比如 Map 提供了 computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction) 的方法, 这个方法的作用，就是向 Map 获取 key 对应的值不存在时，将后面的 lambda 表达式的返回值设置到 Map 中，然后返回。 
这样就能保证从 Map 不会获取到 null 值。

```java

Map<Integer, String> test = new ConcurrentHashMap<>();
test.put(1, "1");

String s = test.computeIfAbsent(2, k -> k + "123");

// 输出： 2123
System.out.println(s);

// 输出：null
System.out.println(test.get(10));

```

computeIfAbsent 定义在 Map 接口中声明的方法, 同时基于 JDK 1.8 的特性, 用 default 关键字进行了修饰, 提供了默认的实现。  
Map 提供的这些 default 方法，可以发现都是线程不安全的，所以 ConcurrentHashMap 对他们进行了重写, 在这些方法中，需要对向已有的数组里面的添加新值，那么就会向把对应位置的那一项, 设置为 ReservationNode 节点。  
用于通知其他的线程，这个位置的数据在修改中。

### 3.2.2 关键属性

```java
public class ConcurrentHashMap<K,V> {

    // 装载 Node 的数组，作为 ConcurrentHashMap 的数据容器，采用懒加载的方式，直到第一次插入数据的时候才会进行初始化操作，数组的大小总是为 2 的幂次方
    transient volatile Node<K,V>[] table;

    // 扩容时使用，平时为 null，只有在扩容的时候才为非 null, 扩容时先把数据放在这个对象，扩容完成后，才把 table 指向这个对象
    transient volatile Node<K,V>[] nextTable;

    // 在没有发生争用时的元素个数的统计, 即当前的元素个数
    transient volatile long baseCount;

    // 数组大小控制
    // 这个属性非常重要, 取值不同有不同的情况

    // 1. 当 sizeCtl > 0 时
    // 在 ConcurrentHashMap 未初始时, sizeCtl 表示的是初始时，数组 table 的长度
    // 初始化后表示扩容的阈值, 默认为当前数组的长度 * 0.75

    // 2. 当 sizeCtl = 0 时
    // 在声明 ConcurrentHashMap, 没有指定容量大小, 这时 sizeCtl 为 0，也就是表明 数组 table 的长度去默认值：16

    // 3. 当 sizeCtl = -1 时
    // 表明当前 table 正在初始中

    // 4. 当 sizeCtl < -1 时
    // sizeCtl 的数据类型为 int, 占 32 位。
    // 那么 sizeCtl 的高 16 位存放的是扩容时标识符(具体的解释可以看后面，现在知道有这个设定就行了), 低 16 位存放的是参与扩容的线程数目 (CocurrentHashMap 在扩容的时候，有别的线程发现正在扩容中, 会一起参与进来，一起扩容)
    transient volatile int sizeCtl;

    // 扩容索引值, 表示已经分配给扩容线程的 table 数组索引位置, 主要用来协调多个线程间迁移任务的并发安全
    transient volatile int transferIndex;

}
```

### 3.2.3 关键内部类

```java
public class ConcurrentHashMap<K,V> {

    static class Node<K,V> implements Map.Entry<K,V> {
        
        final int hash;
        final K key;

        // 很多属性都是用 volatile 进行修饰的，也就是为了保证内存可见性
        volatile V val;
        volatile Node<K,V> next;
        ......
    }

    static final class TreeNode<K,V> extends Node<K,V> {

        TreeNode<K,V> parent;  // red-black tree links
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    // needed to unlink next upon deletion
        boolean red;
        ......
    }

    static final class TreeBin<K,V> extends Node<K,V> {
        
        // 这个类并不负责包装用户的 key、value 信息，而是包装的很多 TreeNode 节点。 
        // 实际的 ConcurrentHashMap "数组" 中，存放的是 TreeBin 对象，而不是 TreeNode 对象
        TreeNode<K,V> root;
        volatile TreeNode<K,V> first;
        volatile Thread waiter;
        volatile int lockState;

        // values for lockState
        static final int WRITER = 1; // 持有写锁时的标志
        static final int WAITER = 2; // 等待写锁的标志
        static final int READER = 4; // 读锁的增加值
        ......
    }

    static final class ForwardingNode<K,V> extends Node<K,V> {
        // 在扩容时才会出现的特殊节点, 作为一个标记节点放在桶的首位, 
        // 其 key, value, next 全部为 null, hash 为 MOVED (-1), 并拥有 nextTable 指针指向新的 table 数组

        final Node<K,V>[] nextTable;

        ForwardingNode(Node<K,V>[] tab) {
            // hash, key, value, next
            super(MOVED, null, null, null);
            this.nextTable = tab;
        }
    }

}
```


### 3.2.4 一些高频的 CAS 方法

```java
public class ConcurrentHashMap<K,V> {

    /**
     * 该方法用来获取 tab 数组中索引为 i 的 Node 元素
     */
    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
        return (Node<K,V>)U.getObjectAcquire(tab, ((long)i << ASHIFT) + ABASE);
    }

    /**
     * 利用 cas 操作将 tab 数组中索引为 i 的元素从 c 替换为 v
     */
    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {
        return U.compareAndSetObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
    }

    /**
     * 将 tab 数组中索引为 i 的元素设置为 v
     */
    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
        U.putObjectRelease(tab, ((long)i << ASHIFT) + ABASE, v);
    }
}
```


## 3.3 ConcurrentHashMap 的源码实现

### 3.3.1 实例构造器方法

```java

public class ConcurrentHashMap<K,V> {

    // 1. 构造一个空的 map，即 table 数组还未初始化，初始化放在第一次插入数据时，默认大小为 16
    public ConcurrentHashMap()

    // 2. 给定 map 的大小
    public ConcurrentHashMap(int initialCapacity)

    // 3. 给定一个 map
    public ConcurrentHashMap(Map<? extends K, ? extends V> m)

    // 4. 给定 map 的大小以及负载因子
    public ConcurrentHashMap(int initialCapacity, float loadFactor)

    // 5. 给定 map 大小，加载因子以及最少多少个桶(数组的最小长度)
    public ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel)

}
```

ConcurrentHashMap 一共给我们提供了 5 种构造器方法，具体使用请看注释，我们来看看第 2 种构造器，传入指定大小时的情况 (其他的构造方式都是类似的)，该构造器源码为：

```java
public class ConcurrentHashMap<K,V> {

    // 存储数据的数组的最大容量 
    private static final int MAXIMUM_CAPACITY = 1 << 30;

    public ConcurrentHashMap(int initialCapacity) {

        //1. 小于 0 直接抛异常
        if (initialCapacity < 0)
            throw new IllegalArgumentException();

        //2. 判断指定的容量是否超过了允许的最大值，超过了话则取最大值，否则再对该值进一步处理, 使其为 2 的 n 次方

        // 在 initialCapacity 的值大于等于 MAXIMUM_CAPACITY / 2 的情况下， 直接取最大值 MAXIMUM_CAPACITY， 否则重试计算出第一个大于 initialCapacity 的 2 的 n 次方的数

        // initialCapacity >>> 1 相当于除以2 取整, 经过这样处理可以得到第一个大于 initialCapacity 的 2 的 n 次方的数
        int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?  MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));    

        //3. 赋值给 sizeCtl，这时候 sizeCtl 作用是存放初始时数组的容量
        this.sizeCtl = cap;
    }

    // 经过这个方法的处理后, 可以得到第一个大于等于 c 的 2 的 n 次方的数
    private static final int tableSizeFor(int c) {
        int n = c - 1;
        n |= n >>> 1;
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        // MAXIMUM_CAPACITY == 1 << 30
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
    }

}

```

这段代码的逻辑请看注释，很容易理解。  
如果小于 0 就直接抛出异常，如果指定值大于了所允许的最大值的话就取最大值。  
否则，在对指定值做进一步处理。最后将计算出来的容量 cap 赋值给 sizeCtl, 关于 sizeCtl 的说明请看上面的说明，**当调用构造器方法之后，sizeCtl 的大小就代表了 ConcurrentHashMap 的大小，即 table 数组长度**。

在指定容量的处理方法 **tableSizeFor** 中, 根据入参的值计算出第一个大于当前入参的 2 的 n 次方数, 这个值就是 ConcurrentHashMap 中数组进行声明时的容量了。  
比如，当指定大小为 18 时，经过这个方法处理， 会得到一个 32 的值。

需要注意的是，**调用构造器方法的时候并未构造出 table 数组（可以理解为 ConcurrentHashMap 的数据容器），只是算出 table 数组的长度，当第一次向 ConcurrentHashMap 插入数据的时候才真正的完成初始化创建 table 数组的工作**。


### 3.3.2 ConcurrentHashMap 中数组的初始方法 initTable() 

在上面的指定容量的构造函数中, 可以看到, 只是对入参的容量参数进行了处理, 然后赋值给 sizeCtl, 就结束了。 而真正存储数据的 table 数组还是为空的。  
这是一种懒加载的方式, 而只要第一次向里面放数据时, 就会进行数组的初始化，initTable 就是初始化的方法。

```java
public class ConcurrentHashMap<K,V> {

    private final Node<K,V>[] initTable() {

        Node<K,V>[] tab; 
        int sc;

        // table 为空 或者长度为 0, 进入循环, 否则进入后面的逻辑
        while ((tab = table) == null || tab.length == 0) {

            // 当前的 sizeCtl 小于 0，表示 ConcurrentHashMap 正在扩容中
            if ((sc = sizeCtl) < 0)
                // 让当前线程让出行时间段，使正在运行中的线程重新变成就绪状态，后面重新竞争 CPU 的调度权
                // 确保当前只有一个线程在初始化
                Thread.yield();

            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                // 通过 CAS 将 sizeCtl 设置为 -1, 成功了，进行初始化
                // 在初始时，会先将 sizeCtl CAS 为 -1， 也就是其他的线程进入到 while 里面，也会在上面的判断时，判断为 true 然后让出执行权

                try {
                    // 再次判断 table 为 null 或者长度为 0 
                    if ((tab = table) == null || tab.length == 0) {
                        
                        // 如果指定的容量小于 0，使用默认值 16，进行声明, 否则就用指定的大小进行声明
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;

                        // 初始数组
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;

                        // 计算数组中可用的大小：实际大小 n * 0.75（加载因子）
                        // n >>> 2 相等于 n /2 /2 = n/4 = 0.25
                        // sc = n - 0.25 * n = 0.75 * n
                        sc = n - (n >>> 2);

                    }

                } finally {
                    // 这时候 sizeCtl 存放的是阈值，不是数组的长度，也不是 -1 了
                    // 如果上面异常了, 可以把 sc 重新赋值过来, 也就是还是维护的是数组的长度
                    sizeCtl = sc;
                }
            }    
        }
    }
}
```

代码的逻辑请见注释，有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，会在数组初始时做了一个判断 sizeCtl < 0 的判断，  
若当前已经有一个线程正在初始化即 sizeCtl 值变为 -1，这个时候其他线程在 if 判断为 true 从而调用 Thread.yield() 让出 CPU 时间片。    
正在进行初始化的线程会调用 U.compareAndSwapInt 方法将 sizeCtl 改为 -1 即正在初始化的状态。

构造方法 +  initTable 基本就构成了 ConcurrentHashMap 的初始的全部逻辑了

###  3.3.3 ConcurrentHashMap 新增数据 - put() 方法

```java
public class ConcurrentHashMap<K,V> {

    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    static final int spread(int h) {
        // ConcurrentHashMap 中 hash 值的计算方法
        // h 异或 (h 无符号右移 16 位) 后，再与上 HASH_BITS
        // HASH_BITS = 0x7fffffff = 2147483647, 二进制表示为  01111111 11111111 11111111 11111111
        return (h ^ (h >>> 16)) & HASH_BITS;
    }

    final V putVal(K key, V value, boolean onlyIfAbsent) {

        // 注意：这里和 HashMap 的区别，HashMap 允许一个 key 为 0 和 多个 value 为 null
        // ConcurrentHashMap 则 key 和 value 都不允许, 直接抛出异常
        if (key == null || value == null) 
            throw new NullPointerException();

        // 通过计算得出 key 对应的 hash 值
        int hash = spread(key.hashCode());   

        

    }


}

```

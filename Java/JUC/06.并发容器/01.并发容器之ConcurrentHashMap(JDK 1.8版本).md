# 15. 并发容器之ConcurrentHashMap(JDK 1.8版本)

## 1. ConcurrentHashmap 简介

Map 一种存储键值对 (key-value) 的数据结构，可以通过 key 快速地定位到需要的 value, 在 Java 中是一个使用频率很高的一个数据结构。一般情况下，我们都是可以直接使用它的实现类 HashMap 就能满足需求了。但是 HashMap 在多线程情况, 并不是一个线程安全的类。  
(1) 通常可以使用在 Java 体系中古老的 Hashtable 作为替代，该类基本上所有的方法都采用 synchronized 进行线程安全的控制， 虽然保证了线程安全, 但是牺牲了很大的性能, 在高并发的情况下，每次只有一个线程能够获取对象监视器锁，这样的并发性能的确不令人满意。  
(2) 也可以通过 Collections 的 synchronizedMap(Map<K,V> m) 方法返回一个线程安全的 Map。但是这个的效果实际上和 Hashtable 的一样, 依然是采用 synchronized 独占式锁进行线程安全的并发控制的, 所以这种方案的性能也是令人不太满意的。

那么有没有一种既保证了线程安全性，性能也不错的 Map 呢？ConcurrentHashMap 就是我们的选择了，内部利用了**锁分段**的思想提高了并发度。当然的，随着 JDK 的升级, ConcurrentHashMap 的实现也有了不同的方式。大体了分为 2 个版本：1.6 版本的 和 1.8 版本。

ConcurrentHashMap 在 JDK1.6 的版本网上资料很多，有兴趣的可以去看看。 JDK 1.6 版本关键要素：

>1. segment 继承了 ReentrantLock 充当锁的角色，为每一个 segment 提供了线程安全的保障
>2. segment 维护了哈希散列表的若干个桶，每个桶由 HashEntry 构成的链表

而到了 JDK 1.8 的 ConcurrentHashMap 就有了很大的变化，光是代码量就足足增加了很多。1.8 版本舍弃了 segment，并且大量使用了 synchronized，以及 CAS 无锁操作以保证 ConcurrentHashMap 操作的线程安全性。至于为什么不用 ReentrantLock 而是 Synchronzied 呢？实际上，synchronzied 在 JDK 1.6 做了很多的优化，包括偏向锁，轻量级锁，重量级锁，可以依次向上升级锁状态，但不能降级。因此，使用 synchronized 相较于 ReentrantLock 的性能会持平甚至在某些情况更优，具体的性能测试可以去网上查阅一些资料。另外，底层数据结构改变为采用数组 + 链表 + 红黑树的数据形式。

## 2. 关键属性及类

在了解 ConcurrentHashMap 的具体方法实现前，我们需要系统的来看一下几个关键的地方，从这几个地方，从大体上了解 ConcurrentHashMap 的一些特性。

### 2.1 常量设置(这些设置基本和 HashMap 的类似)

>1. ConcurrentHashMap 内部是使用一个数组存放数据的,  这个数组的长度必须是 2 的 n 次方，默认的容量是 16，最大是 1 << 30, 既 2 的 30 次方
>2. 默认负载因子为 0.75, 当数组的的存数据的项 >= 数组的长度 * 负载因子，就会进行数组长度扩容
>3. 数组的每一项，在 JDK 1.8 中, 可以是链表，也可以是红黑树。
>4. 当数组的长度大于等于 64，数组的某一项的长度大于等于 8，会转为红黑树，小于等于 6，会重新转为链表
>5. key 和 value 都不允许为 null (HashMap 允许一个 key 为 null 和 不限制的 value 为 null)
>6. 在 ConcurrentHash 中数组中的每个节点的 hash 都有特殊作用
>>
>>1. **>= 0**, 表明这个节点为 Node, 既链表节点
>>2. **-1**, 表明这个节点为 ForwardingNode，说明这个位置正在数据迁移，即这个位置的数据正在迁到新的数组的指定位置中
>>3. **-2**, 表明这个节点为 TreeBin, 树节点 TreeNode 的进一步封装
>>4. **-3**, 表明这个节点为 ReservationNode, 通过 JDK 1.8 新增的几个方法给 ConcurrentHashMap 设置时, 会先对应位置的节点变为 ReservationNode。

比如 Map 提供了 computeIfAbsent(K key, Function<? super K, ? extends V> mappingFunction) 的方法, 这个方法的作用，就是向 Map 获取 key 对应的值不存在时，将后面的 lambda 表达式的返回值设置到 Map 中，然后返回。这样就能保证从 Map 不会获取到 null 值。

```java
Map<Integer, String> test = new ConcurrentHashMap<>();
test.put(1, "1");
String s = test.computeIfAbsent(2, k -> k + "123");
// 输出： 2123
System.out.println(s);
// 输出：2123
System.out.println(test.get(10));
```

Map 提供的这些 default 方法，可以发现都是线程不安全的，所以 ConcurrentHashMap 对他们进行了重写, 在这些方法中，需要对向已有的数组里面的添加新值，那么就会向把对应位置的那一项, 设置为 ReservationNode 节点。用于通知其他的线程，这个位置的数据在修改中

### 2.2 关键属性

```java
transient volatile Node<K,V>[] table;
```

装载 Node 的数组，作为 ConcurrentHashMap 的数据容器，采用懒加载的方式，直到第一次插入数据的时候才会进行初始化操作，数组的大小总是为 2 的幂次方

```java
transient volatile Node<K,V>[] nextTable;
```

扩容时使用，平时为 null，只有在扩容的时候才为非 null, 扩容时先把数据放在这个对象，扩容完成后，才把 table 指向这个对象

```java
transient volatile long baseCount;
```

在没有发生争用时的元素个数的统计

```java
transient volatile int sizeCtl;
```

这个属性非常重要, 取值不同有不同的情况
(1) **当 sizeCtl > 0 时**

>1. 在 ConcurrentHashMap 未初始时, sizeCtl 表示的是初始时，数组 table 的长度
>2. 初始化后表示扩容的阈值, 默认为当前数组的长度 * 0.75

(2) **当 sizeCtl = 0 时**
我们在声明 ConcurrentHashMap, 没有指定容量大小, 这时 sizeCtl 为 0，也就是表明 数组 table 的长度去默认值：16

(3) **当 sizeCtl = -1 时**
表明当前 table 正在初始中

(4) **当 sizeCtl < -1 时**
sizeCtl 为的数据类型为 int, 占 32 位。sizeCtl 的高 16 位存放的是扩容时标识符(具体的解释可以看后面，现在知道有这个设定就行了), 低 16 位存放的是 参与扩容的线程数目(CocurrentHashMap 在扩容的时候，有别的线程发现正在扩容中, 会一起参与进来，一起扩容)

>1. 在 addCount 和 helpTransfer 的方法代码中, 如果需要帮助扩容, 则会 CAS 替换为 sizeCtl + 1 (参与扩容的线程数目加 1)
>2. 在完成当前扩容内容, 且没有再分配的区域时, 线程会退出扩容, 此时会 CAS 替换为 sizeCtl - 1 (参与扩容的线程数目 - 1)

```java
transient volatile int transferIndex;
```

扩容索引值, 表示已经分配给扩容线程的 table 数组索引位置, 主要用来协调多个线程间迁移任务的并发安全

### 2.3 关键内部类

1. **Node**  
Node 类实现了 Map.Entry 接口，主要存放 key-value 对，并且具有 next 域, 可以理解为就是链表中的一项

    ```java
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        volatile V val;
        volatile Node<K,V> next;
        ......
    }
    ```

    可以看出很多属性都是用 volatile 进行修饰的，也就是为了保证内存可见性

2. **TreeNode**  
树节点，继承于承载数据的 Node 类。但是在 ConcurrentHashMap 对树节点的操作是使用 TreeBin 这个类的，也就是 TreeBin 会将 TreeNode 进行再一次封装。

    ```java
    static final class TreeNode<K,V> extends Node<K,V> {
        TreeNode<K,V> parent;  // red-black tree links
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    // needed to unlink next upon deletion
        boolean red;
        ......
    }
    ```

3. **TreeBin**  
这个类并不负责包装用户的 key、value 信息，而是包装的很多 TreeNode 节点。实际的 ConcurrentHashMap "数组" 中，存放的是 TreeBin 对象，而不是 TreeNode 对象

    ```java
    static final class TreeBin<K,V> extends Node<K,V> {
        TreeNode<K,V> root;
        volatile TreeNode<K,V> first;
        volatile Thread waiter;
        volatile int lockState;
        // values for lockState
        static final int WRITER = 1; // 持有写锁时的标志
        static final int WAITER = 2; // 等待写锁的标志
        static final int READER = 4; // 读锁的增加值
        ......
    }
    ```

4. **ForwardingNode**  
在扩容时才会出现的特殊节点, 作为一个标记节点放在桶的首位, 其 key, value, next 全部为 null, hash 为 MOVED(-1), 并拥有 nextTable 指针指向新的 table 数组

    ```java
    static final class ForwardingNode<K,V> extends Node<K,V> {
        final Node<K,V>[] nextTable;
        ForwardingNode(Node<K,V>[] tab) {
            // hash, key, value, next
            super(MOVED, null, null, null);
            this.nextTable = tab;
        }
    .....
    }
    ```

### 一些高频的 CAS 方法

1. **tabAt**  
该方法用来获取 table 数组中索引为 i 的 Node 元素

    ```Java
    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
        return (Node<K,V>)U.getObjectAcquire(tab, ((long)i << ASHIFT) + ABASE);
    }
    ```

2. **casTabAt**  
利用 CAS 操作替换 table 数组中索引为 i 的元素

    ```java
    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i, Node<K,V> c, Node<K,V> v) {
        return U.compareAndSetObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
    }
    ```

3. **setTabAt**  
该方法用来设置 table 数组中索引为 i 的元素

    ```java
    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
        U.putObjectRelease(tab, ((long)i << ASHIFT) + ABASE, v);
    }
    ```

## 3. ConcurrentHashMap 中的常用方法

### 3.1 实例构造器方法

```java

// 1. 构造一个空的 map，即 table 数组还未初始化，初始化放在第一次插入数据时，默认大小为 16
ConcurrentHashMap()

// 2. 给定 map 的大小
ConcurrentHashMap(int initialCapacity)

// 3. 给定一个 map
ConcurrentHashMap(Map<? extends K, ? extends V> m)


// 4. 给定 map 的大小以及负载因子
ConcurrentHashMap(int initialCapacity, float loadFactor)


// 5. 给定 map 大小，加载因子以及最少多少个桶(数组的最小长度)
ConcurrentHashMap(int initialCapacity,float loadFactor, int concurrencyLevel)
```

ConcurrentHashMap 一共给我们提供了 5 种构造器方法，具体使用请看注释，我们来看看第 2 种构造器，传入指定大小时的情况，该构造器源码为：

```java
public ConcurrentHashMap(int initialCapacity) {

    //1. 小于 0 直接抛异常
    if (initialCapacity < 0)
        throw new IllegalArgumentException();

    //2. 判断是否超过了允许的最大值，超过了话则取最大值，否则再对该值进一步处理
    // 在 initialCapacity 的值 大于 0 的情况下， initialCapacity >>> 1 相当于 除以2 取整, 经过这样处理 可以得到第一个大于 initialCapacity 的 2 的 n 次方的数
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
                MAXIMUM_CAPACITY :
                tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));

    //3. 赋值给 sizeCtl，这时候 sizeCtl 作用是存放初始时数组的容量
    this.sizeCtl = cap;
}
```

这段代码的逻辑请看注释，很容易理解，如果小于 0 就直接抛出异常，如果指定值大于了所允许的最大值的话就取最大值，否则，在对指定值做进一步处理。最后将 cap 赋值给 sizeCtl,关于 sizeCtl 的说明请看上面的说明，**当调用构造器方法之后，sizeCtl 的大小就代表了 ConcurrentHashMap 的大小，即 table 数组长度**。tableSizeFor 做了哪些事情了？源码为：

```java
private static final int tableSizeFor(int c) {
    int n = c - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    // MAXIMUM_CAPACITY == 1 << 30
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}
```

通过注释就很清楚了，该方法会将调用构造器方法时指定的大小转换成一个 2 的幂次方数，也就是说 ConcurrentHashMap 的大小一定是 2 的幂次方，比如，当指定大小为 18 时，为了满足 2 的幂次方特性，实际上 concurrentHashMapd 的大小为 2 的 5 次方（32）。另外，需要注意的是，**调用构造器方法的时候并未构造出 table 数组（可以理解为 ConcurrentHashMap 的数据容器），只是算出 table 数组的长度，当第一次向 ConcurrentHashMap 插入数据的时候才真正的完成初始化创建 table 数组的工作**。

### 3.2 initTable 方法

通过构造函数声明 ConcurrentHashMap 时，存储数据的 table 还是未空的，只有第一次向里面放数据时，才会进行初始化，initTable 就是初始化的方法

```java
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;

    // table 为空 或者长度为 0
    while ((tab = table) == null || tab.length == 0) {

        // 当前的 sizeCtl 小于 0，表示 ConcurrentHashMap 正在扩容中
        if ((sc = sizeCtl) < 0)
             // 让当前线程让出行时间段，使正在运行中的线程重新变成就绪状态，后面重新竞争 CPU 的调度权
             // 确保当前只有一个线程在初始化
            Thread.yield();

        // 通过 CAS 将 sizeCtl 设置为 -1, 成功了，进行初始化
        // 在初始时，会先将 sizeCtl CAS 为 -1， 也就是其他的线程进入到 while 里面，也会在上面的判断时，判断为 true 然后让出执行权
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            try {
                if ((tab = table) == null || tab.length == 0) {
                    // 如果没有指定大小，这时 n = 默认值，为 16
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;

                    // 初始数组
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;

                    // 计算数组中可用的大小：实际大小 n * 0.75（加载因子）
                    // n >>> 2 相等于 n /2 /2 = n/4 = 0.25
                    sc = n - (n >>> 2);
                }
            } finally {
                // 这时候 sizeCtl 存放的是阈值，不是数组的长度，也不是 -1 了
                sizeCtl = sc;
            }
        }
    }
}
```

代码的逻辑请见注释，有可能存在一个情况是多个线程同时走到这个方法中，为了保证能够正确初始化，会在数组初始时做了一个判断 sizeCtl < 0 的判断，若当前已经有一个线程正在初始化即 sizeCtl 值变为 -1，这个时候其他线程在 if 判断为 true 从而调用 Thread.yield() 让出 CPU 时间片。正在进行初始化的线程会调用 U.compareAndSwapInt 方法将 sizeCtl 改为 -1 即正在初始化的状态。

构造方法 +  initTable 基本就构成了 ConcurrentHashMap 的初始的全部逻辑了

### 3.3 put 方法

使用 ConcurrentHashMap 最长用的也应该是 put 和 get 方法了吧，我们先来看看 put 方法是怎样实现的。调用 put 方法时实际具体实现是 putVal 方法，源码如下：

```java
public V put(K key, V value) {
    return putVal(key, value, false);
}

final V putVal(K key, V value, boolean onlyIfAbsent) {

    // 注意：这里和 HashMap 的区别，HashMap 允许一个 key 为 0 和 多个 value 为 null
    // ConcurrentHashMap 则不允许, 直接抛出异常
    if (key == null || value == null)
        throw new NullPointerException();

    // 通过计算得出 key 对应的 hashCode
    int hash = spread(key.hashCode());

    // 用来计算对应位置的链表的长度
    int binCount = 0;

    // 注意：这里做了一个死循环，自旋操作
    for (Node<K,V>[] tab = table;;) {
        Node<K,V> f; int n, i, fh;
        // 第二步, 当前的数据结构为 null 或者 长度为 0, 进行初始化
        if (tab == null || (n = tab.length) == 0)
            tab = initTable();

    }
}
```
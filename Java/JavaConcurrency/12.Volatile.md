# 12 volatile

synchronized 是阻塞式同步, 在线程竞争激烈的情况下会升级为重量级锁, 而 volatile 则是 Java 虚拟机提供的最轻量级的同步机制。   
在 Java 内存模型中, 各个线程会将共享变量从主内存中拷贝到工作内存，然后执行引擎会基于工作内存中的数据进行操作处理。    

线程在工作内存进行操作后何时会写到主内存中? 这个时机对普通变量是没有规定的。 而针对 volatile 修饰的变量在 Java 虚拟机有特殊的约定:   
线程对 volatile 变量的修改会立刻被其他线程所感知, 即立即刷新到主内容, 不会出现数据脏读的现象，从而保证数据的 "可见性"。

## 12.1 volatile 实现原理

```java
public class Demo {

    private volatile String name;

    private void setName(String name) {
        this.name = name;
    }
}
```

在生成汇编代码时会在 volatile 修饰的共享变量进行写操作的时候会多出 Lock 前缀的指令, 这个指令的作用有:
> 1. 将当前处理器缓存行的数据写回系统内存
> 2. 这个写回内存的操作会使得其他 CPU 里缓存了该内存地址的数据无效

为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存 (L1, L2 或其他) 后再进行操作, 但操作完不知道何时会写到内存。  
对声明了 volatile 的变量进行写操作, JVM 就会向处理器发送一条 Lock 前缀的指令, 将这个变量所在缓存行的数据写回到系统内存。  
写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以, 在多处理器下，为了保证各个处理器的缓存是一致的，就会实现**缓存一致性协议**。
**每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了**， 当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，  
当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里, 经过分析我们可以得出如下结论：  
> 1. Lock 前缀的指令会引起处理器缓存写回内存
> 2. 一个处理器的缓存回写到内存会导致其他处理器的缓存失效
> 3. 当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值

## 12.2 volatile 的 Happens-Before 关系  

volatile 变量可以通过**缓存一致性协议**保证每个线程都能获得最新值，即满足数据的 "可见性"。那么 volatile 和 JMM 的关系可以通过  Happens-Before 关系中的   
**volatile变量规则 (对一个 volatile 变量的写操作 Happens-Before 后续每一个针对该变量的读操作)** 进行分析。

```java
public class VolatileExample {

    private int a = 0;

    private volatile boolean flag = false;

    public void writer(){
        // 1
        a = 1;         
        // 2
        flag = true;
    }

    public void reader(){
        // 3
        if(flag){
            // 4
            int i = a;
        }

    }

}
```

![Alt 'VolatileAndHappensBeforeRelation'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/VolatileAndHappensBeforeRelation.png)


线程 A 先执行 writer 方法, 然后线程 B 执行 reader 方法。图中每一个箭头两个节点就代表一个 Happens-Before 关系。  
黑色的代表根据程序顺序规则推导出来的,    
红色的是根据 volatile 变量的写 Happens-Before 于任意后续对 volatile 变量的读，得到的,    
而蓝色的就是根据传递性规则推导出来的。

这里的 2 Happen-Before 3，同样根据 Happens-Before 规则定义：如果 A Happens-Before B, 则 A 的执行结果对 B 可见，并且 A 的执行顺序先于 B 的执行顺序，  
我们可以知道操作 2 执行结果对操作 3 来说是可见的, 也就是说当线程 A 将 volatile 变量 flag 更改为 true 后线程 B 就能够迅速感知。  

## 12.3 volatile 的内存语义

以上面的代码为例，假设线程 A 先执行 writer 方法，线程 B 随后执行 reader 方法，初始时线程的本地内存中 flag 和 a 都是初始状态，下图是线程 A 执行 volatile 写后的状态图


![Alt 'VolatileSemanticMemoryDemoOne'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/VolatileSemanticMemoryDemoOne.png)


当 volatile 变量写后，线程中本地内存中共享变量就会置为失效的状态，因此线程 B 再需要读取从主内存中去读取该变量的最新值。下图就展示了线程 B 读取同一个 volatile 变量的内存变化示意图

![Alt 'VolatileSemanticMemoryDemoTwo'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/VolatileSemanticMemoryDemoTwo.png)

从横向来看，线程 A 和线程 B 之间进行了一次通信，线程 A 在写 volatile 变量时，实际上就像是给 B 发送了一个消息告诉线程 B 现在的值都是旧的了，  
然后线程 B 读这个 volatile 变量时就像是接收了线程 A 刚刚发送的消息, 直接到主内存获取新的值。


## 12.4 volatile 的内存语义实现

为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了?   
答案是可以添加内存屏障。


| 屏障类型| 说明 | 实例 |
| :-: | :-: | :-: |
| LoadLoadBarriers| Load1; LoadLoadBarriers; Load2 | 确保 Load1 数据的读取在 load2 及后续指令的读取之前 |
| StoreStoreBarriers | Store1; StoreStoreBarriers; Store2; | 确保 Store1 数据的写入 (刷新到主内存) 在 Store2 及后续指令的读取之前 |
| LoadStoreBarriers| Load1; LoadStoreBarriers; Store2; | 确保 Load1 数据的读取在 Store2 及后续指令的写入之前 |
| StoreLoadBarriers | Store1; StoreLoadBarriers; Load2; | 确保 Store2 数据的写入在 Load2 及后续指令的读取之前 |

StoreLoadBarriers 确保 Store1 数据对其他处理器变得可见 (刷新到内存), 先于 Load2 及后续装载指令的装载。 StoreLoadBarriers 会使该屏障之前所有的内存访问指令完成之后, 才执行该屏障之后的内存访问指令。


为了实现 volatile 的内存语义，JMM 会限制特定类型的编译器和处理器重排序，JMM 会针对编译器制定 volatile 重排序规则表：


| 第一个操作 |  第二个操作 |  是否可以重排序 |
| :-: | :-: |   :-:|
| 普通读/写 | 普通读/写 | 可以 |
| 普通读/写 | volatile 读 | 可以 |
| 普通读/写 | volatile 写 | 不可以 |
| volatile 读 | 普通读/写 | 不可以 |
| volatile 读 | volatile 读 | 不可以 |
| volatile 读 | volatile 写 | 不可以 |
| volatile 写 | 普通读/写 | 可以|
| volatile 写 | volatile 读 |不可以|
| volatile 写 | volatile 写|不可以|

volatile 的实现, JMM 采取了保守策略
> 1. 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障
> 2. 在每个 volatile 读操作的后面插入一个 LoadStore 屏障
> 3. 在每个 volatile 写操作的前面插入一个 StoreStore 屏障 
> 4. 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障 

```java

LoadLoadBarrier
volatile 读操作
LoadStoreBarrier

StoreStoreBarrier
volatile 写操作
StoreLoadBarrier

```

StoreStore 屏障: 禁止上面的普通写和下面的 volatile 写重排序；
StoreLoad 屏障: 防止上面的volatile写与下面可能有的 volatile 读/写重排序
LoadLoad 屏障: 禁止下面所有的普通读操作和上面的 volatile 读重排序
LoadStore 屏障: 禁止下面所有的普通写操作和上面的 volatile 读重排序

## 12.5 源码实现

### 12.5.1 字节码内容

```java
public class TestDemo {

    public static volatile int counter = 1;

    public static void main(String[] args){
        counter = 2;
        System.out.println(counter);
    }
}
```

将上面的源码输出为字节码

```

// 省略一部分

{
  // 第一段
  public static volatile int counter;
    descriptor: I
    flags: ACC_PUBLIC, ACC_STATIC, ACC_VOLATILE

  // 省略一部分


  // 第二段
  public static void main(java.lang.String[]);
    descriptor: ([Ljava/lang/String;)V
    flags: ACC_PUBLIC, ACC_STATIC
    Code:
      stack=2, locals=1, args_size=1
         0: iconst_2
         1: putstatic     #2                  // Field counter:I
         4: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;
         7: getstatic     #2                  // Field counter:I
        10: invokevirtual #4                  // Method java/io/PrintStream.println:(I)V
        13: return
      LineNumberTable:
        line 16: 0
        line 17: 4
        line 18: 13

    // 省略一部分
}

// 省略一部分
```

可以从上面的字节码的第一段可以查看 volatile 修饰的 counter, 在字节码中会有一个 ACC_VOLATILE 的标识修饰这个字段, 标识其是 volatile 的字段。

而第二段是整个 main 方法的描述和方法执行过程, 大体的执行流程如下
> 1. 获取常量 2 
> 2. 将其赋值给静态变量 counter
> 3. 获取静态变量 PrintStream
> 4. 获取静态变量 counter
> 5. 调用 PrintStream.println 方法
> 6. 结束

putstatic/getstatic 是针对静态变量的, getfield/putfield 则是针对非静态变量的


### 12.5.2 JVM 的实现

将上面的 Java 代码中修饰 counter 字段的 volatile 去掉, 可以发现上面 main 方法的字节码执行过程是一样的, 而 counter 字段的修饰符 ACC_VOLATILE 没了, 所以可以得到 volatile 的关键就是 ACC_VOLATILE 这个修饰符。  
和 ACC_VOLATILE 搭配起作用的就是上面的 putstatic/getstatic 和  getfield/putfield 2 组字节码。

```C++

// 执行的字节码
switch (opcode) {

    // 前面省略一大部分

    CASE(_putfield):
    CASE(_putstatic): {
        // 省略

        int field_offset = cache->f2_as_index();

        // 判断处理的变量是否为 ACC_VOLATILE 修饰的
        if (cache->is_volatile()) {

            // volatile 变量的赋值逻辑
            // int 类型赋值
            if (tos_type == itos) {

                // release_int_field_put 方法, 最终还是会调用到  OrderAccess::release_store 方法
                obj->release_int_field_put(field_offset, STACK_INT(-1));
            } else if (tos_type == atos) {

                // 对象类型赋值
                VERIFY_OOP(STACK_OBJECT(-1));
                obj->release_obj_field_put(field_offset, STACK_OBJECT(-1));

                OrderAccess::release_store(&BYTE_MAP_BASE[(uintptr_t)obj >> CardTableModRefBS::card_shift], 0);

            }  else if (tos_type == btos) {

                // byte 类型赋值
                obj->release_byte_field_put(field_offset, STACK_INT(-1));

            } // 后面省略其他几个基础数据类型的处理


            // 写完值后的 storeload 屏障 
            OrderAccess::storeload();
        } else {
            // 非 volatile 变量的处理
        }
    }
}
```

### 12.5.3 赋值操作


可以通过上面的实现可以看出最终变量的赋值是通过 **release_???_field_put** 方法, 无论是基础数据类型还是引用类型都是一样的

**release_???_field_put** 类似的方法, 最终会调用到 **/hotspot/src/share/vm/oops/oop.inline.hpp** 中的方法

```C++

// load操作调用的方法
inline jint oopDesc::int_field_acquire(int offset) const                    { return OrderAccess::load_acquire(int_field_addr(offset));      }

// store操作调用的方法
inline void oopDesc::release_int_field_put(int offset, jint contents)       { OrderAccess::release_store(int_field_addr(offset), contents);  }
```

其他的基础数据类型类似的, 可以看出最终无论是基础数据类型还是引用类型, 都是通过 OrderAccess::release_store 实现赋值的。


而 OrderAccess 相关的方法都定义在 **/hotspot/src/share/vm/runtime/orderAccess.hpp** 下, 具体的实现是根据不同的操作系统和不同的 CPU 架构，有不同的实现。

orderAccess_linux_x86.inline.hpp 是 Linux 系统下 x86 架构的实现

```C++
inline void  OrderAccess::release_store(volatile jint*  p, jint  v) { *p = v;}
```

到了这一步, 最终靠的是 C++ 的 volatile 关键字实现的逻辑。C++ 的 volatile 关键字的作用
> 1. volatile 修饰的类型变量表示可以被某些编译器未知的因素更改 (如：操作系统，硬件或者其他线程等)
> 2. 使用 volatile 变量时，避免激进的优化。即：系统总是重新从内存读取数据，即使它前面的指令刚从内存中读取被缓存，防止出现未知更改和主内存中不一致


### 12.5.4 volatile 变量赋值后的处理

通过上面 JVM 的代码实现可以知道, 无论什么类型的 volatile 变量赋值成功后, 都会调用到 **OrderAccess::storeload()** 方法。  
它的定义同样是在 **orderAccess.hpp** 文件下, 基于不同的操作系统和 CPU 不同的实现, 依旧以 orderAccess_linux_x86.inline.hpp 为例, 内部的实现如下:

```C++

// 对应着 4 个内存屏障
inline void OrderAccess::loadload()  { acquire(); }
inline void OrderAccess::storestore()  { release(); }
inline void OrderAccess::loadstrore()  { acquire(); }
inline void OrderAccess::storeload()  { release(); }


inline void OrderAccess::acquire() {
    volatile intptr_t local_dump;

    #ifdef AMD64
      __asm__ volatile ("movq 0(%%rsp), %0" : "=r" (local_dump) : : "memory");
    #else
      __asm__ volatile ("movq 0(%%esp), %0" : "=r" (local_dump) : : "memory"); 
    #endif  
}

inline void OrderAccess::release() {
    volatile jint local_dump = 0;
}


inline void OrderAccess::fence() {
    // 首先使用 is_MP() 判断处理器是单核还是双核的, 如果是单核的没必要每次使用内存屏障，这样反而会浪费资源
    if (os::is_MP()) {
#ifdef AMD64
    // lock 汇编指令, lock 指令会锁住操作的缓存行
    // lock 用于在多核处理器中执行指令时对共享内存的独占使用。 能够将当前处理器对应的缓存的内容刷新到内存中, 并使其他处理器对应的缓存失效
    // 另外还提供了有序的指令无法越过这个内存屏障的作用
    __asm__ volatile ("lock; addl $0,0(%%rsp)" : : : "cc", "memory");
#else
    __asm__ volatile ("lock; addl $0,0(%%esp)" : : : "cc", "memory");
#endif
    }
}
```

代码 `lock; addl $0,0(%%rsp)` 其中的 addl $0,0(%%rsp) 是把寄存器的值加 0，相当于一个空操作 (之所以用它，不用空操作专用指令 nop，是因为 lock 前缀不允许配合 nop 指令使用)  

lock 前缀，会保证某个处理器对共享内存（一般是缓存行cacheline）的独占使用。  
它将本处理器缓存写入内存，该写入操作会引起其他处理器或内核对应的缓存失效。  
通过独占内存、使其他处理器缓存失效，达到了 "指令重排序无法越过内存屏障" 的作用。


## 12.6 参考
[volatile简介](https://github.com/CL0610/Java-concurrency/blob/master/05.%E5%BD%BB%E5%BA%95%E7%90%86%E8%A7%A3volatile/java%E5%85%B3%E9%94%AE%E5%AD%97---volatile.md)  
[volatile底层原理详解](https://zhuanlan.zhihu.com/p/133851347)  


# 4 JMM

JMM 全称: Java Memory Model, Java 内存模式。它是一种虚拟机规范, 用于屏蔽掉各种硬件和操作系统的内存访问差异, 以实现 Java 程序在各种平台下都能达到一致的并发效果。  
主要规定了以下两点
> 1. 一个线程**如何以及何时**可以看到其他线程修改过后的共享变量的值, 即线程之间**共享变量的可见性**
> 2. 如何在需要的时候对共享变量进行同步

在并发编程中, 所要处理的两个关键问题就是这两条标准的体现: **线程之间如何通信**以及**线程之间如何同步**。  

## 4.1 线程通信
通信是指线程之间以何种机制来交换信息。在命令式的编程中, 线程之间的通信机制有两种: **共享内存**和**消息传递**。

在共享内存并发的模型里, 线程之间共享程序的公共状态, 线程之间通过读 - 写内存中的公共状态来隐式进行通信。  
在消息传递的并发模型里, 线程之间没有公共状态, 线程之间必须通过明确的发送消息来显示进行通信, 在 Java 中典型的消息传递方式就是 wait() 和 notify()。

Java 的并发采用的就是 **共享内存模型**, Java 线程之间的通信总是隐式进行的, 整个通信过程对程序员是完全透明的。这里提到的共享内存模型指的就是 Java 内存模型 (简称 JMM )。

## 4.2 线程同步
同步是指程序用于控制不同线程之间操作发生相对顺序的机制。  

在共享内存并发模型里, 同步是显式进行的。程序必须显式指定某个方法或某段代码需要在线程之间互斥执行。
在消息传递的并发模型里, 由于消息的发送必须在消息的接收之前, 因此同步是隐式进行的。

## 4.3 JMM 抽象结构模型  

JMM 定义了线程和主内存之间的抽象关系: 
线程之间的共享变量存储在主内存 (Main Memory) 中, 每个线程都有一个私有的本地内存 (Local Memory), 本地内存中存储了该线程已 读/写 共享变量的副本。  
本地内存是 JMM 的一个抽象概念, 并不真实存在。它涵盖了缓存, 写缓冲区, 寄存器以及其他的硬件和编译器优化。

![Alt 'JMMAbstractModel'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/JMMAbstractModel.png)

从上图来看, 线程 A 与线程 B 之间如要通信的话, 必须要经历下面 2 个步骤
> 1. 线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去
> 2. 线程 B 到主内存中去读取线程 A 更新的共享变量

## 4.4 JVM 对 Java 内存模型的实现

![Alt 'JVMMemoryArea'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/JVMMemoryArea.png)

JVM 在执行 Java 程序的过程中会把它所管理的内存划分为若干不同的数据区域, 这些区域都有各自的用途以及创建和销毁的时间。

主要包含 2 类: 
> 1. 线程共享区域: 方法区 (Method Area) 和 堆 (Heap) 
> 2. 线程私有区域: 虚拟机栈 (VM Stack) , 本地方法栈 (Native Method Stack) , 程序计数器 (PC Register) 

**虚拟机栈**   
每一个运行在 Java 虚拟机上的线程都拥有自己的线程栈。每个方法在执行的时候都会创建一个栈帧用于存储局部变量表、操作数栈、动态链表、方法出口信息等。  
每一个方法从调用直至执行完成的过程, 就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。  
虚拟机栈的生命周期与线程相同。


**本地方法栈**  
本地方法栈与虚拟机栈的作用相似, 不同之处在于虚拟机栈为虚拟机执行的 Java 方法服务, 而本地方法栈则为虚拟机使用到的 Native 方法服务

**程序计数器**   
程序计数器保存着每一条线程下一次执行指令位置

**堆**   
用来保存程序中所创建的所有对象、数组元素等

**方法区**   
方法区是各个线程共享的内存区域, 它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据

### 4.4.1 数据存储总结
> 1. 一个本地变量是原始类型, 它会被完全存储到栈区
> 2. 一个本地变量是引用类型, 这个本地引用会被存储到栈中, 但是对象本身仍然存储在堆区
> 3. 一个对象的成员方法, 方法中包含局部变量, 存储在栈区
> 4. 一个对象的成员变量, 不管它是原始类型还是包装类型, 都存储到堆区
> 5. static 类型的变量以及类本身相关信息都会随着类本身存储在方法区

## 4.5 JMM 带来的问题

### 4.5.1 可见性问题

![Alt 'ShardVariableVisibilityProblem'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/ShardVariableVisibilityProblem.png)

如上图, 3 个 共享变量 count, 2 个为副本。  
启动 2 个线程分别对共享变量操作, 假设原本共享变量 count 为 0。
> 1. 线程 A 从主内存将这个共享变量 count 加载到自己的本地内存, 值为 0
> 2. 线程 B 执行同样的加载操作, 值为 0
> 3. 线程 A 对这个共享变量 count + 1, count 的值变为 1, 没有将这个值同步到主内存
> 4. 线程 B 这时候同样需要对这个共享变量 count + 1, 但是这时候 B 中的 count 还是 0, 没有感知到 A 对其做的修改


在多线程的环境下, 如果某个线程首次读取共享变量, 则首先到主内存中获取该变量, 然后存入工作内存中, 以后只需要在工作内存中读取该变量即可。  
同样如果对该变量执行了修改的操作, 则先将新值写入工作内存中, 然后再刷新至主内存中, 这个刷新时间虽然很短但并不确定。

### 4.5.2 竞争问题

![Alt 'SharedVariableCompetitionProblem'](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/SharedVariableCompetitionProblem.png)

如上图:  
如果这两个加 1 操作是串行的, 最终主内存中的 count 的值应该是 3。  
然而图中两个加 1 操作是并行的, 当它们值更新到工作内存的副本后, 会争相刷新主内存。在这里, 不管是线程 1 还是线程 2 先刷新计算结果到主内存, 最终主内存中的值只能是 2。

### 4.5.3 重排序

可见性和竞争都是由共享内存和工作内存带来的。在并发中, 除了这 2 个地方会引起问题外, 在编译器中还存在重排序问题: 在执行程序时, 为了提高性能, 编译器和处理器常常会对指令做重排序。  
这些系统内部的优化大部分都是有效的, 但是有时在并发编程中, 则会带来某些问题。

#### 4.5.3.1 重排序的类型

一个好的内存模型实际上会放松对处理器和编译器规则的束缚, 也就是说软件技术和硬件技术都为同一个目标而进行奋斗: 在不改变程序执行结果的前提下, 尽可能提高并行度。  
JMM 对底层尽量减少约束, 使其能够发挥自身优势。因此, 在执行程序时, **为了提高性能, 编译器和处理器常常会对指令进行重排序**。一般重排序可以分为如下三种:

![Alt "InstructReorderType"](https://raw.githubusercontent.com/PictureRespository/Java/main/JavaConcurrency/InstructReorderType.png)

> 1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下, 可以重新安排语句的执行顺序
> 2. 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果**不存在数据依赖性**, 处理器可以改变语句对应机器指令的执行顺序
> 3. 内存系统的重排序。由于处理器使用缓存和读 / 写缓冲区, 这使得加载和存储操作看上去可能是在乱序执行的。

注: 指令并行重排序和内存系统重排序统称为处理器排序

#### 4.5.3.2 重排序的影响

我们知道重排序是编译器或者系统的优化。但是如果有些指令存在依赖性的话, 进行重排序会导致错误。

**数据依赖性**   
如果两个操作访问同一个变量, 且这两个操作中有一个为写操作, 此时这两个操作之间就存在数据依赖性。数据依赖分为下列 3 种类型, 这 3 种情况, 只要重排序两个操作的执行顺序, 程序的执行结果就会被改变。

|名称 | 说明 | 示例|
| :-: | :-: | :-: |
|写后读 | 写一个变量, 再读这个变量  | a = 1; b = a; |
|写后写| 写一个变量, 再写这个变量 | a = 1; a = 2; |
|读后写| 读一个变量, 再写这个变量 | a = b; b = 1; |

这三种操作都存在数据依赖性, 如果重排序最终会导致结果受到影响。  

**控制依赖性**

```java
public void method() {
    
    if (flag) {
        int num = a * a;
        return num;
    }
}
```

在上面的代码中, 变量 num 的值依赖于 if(flag) 的判断值, 这里就叫控制依赖。

控制依赖在单线程的情况下, 对存在控制依赖的操作重排序, 不会改变执行结果。但是在多线程的情况下, 就有可能出现问题。

```java
public class Demo {
    int a = 0;
    boolean flag = false;
    
    public void init() {
        // 1
        a = 1;
        // 2
        flag = true;
    }
    
    public void use() {
        // 3
        if (flag) {
            // 4
            int i = a * a;
        }
    }
}
```

在程序中, 当代码中存在控制依赖性时, 会影响指令序列执行的并行度。为此, 编译器和处理器会采用猜测 (Speculation) 执行来克服控制相关性对并行度的影响。  
以处理器的猜测执行为例, 执行线程 B 的处理器可以提前读取并计算 a*a, 然后把计算结果临时保存到一个名为重排序缓冲 (Reorder Buffer, ROB) 的硬件缓存中。  
当操作 3 的条件判断为真时, 就把该计算结果写入变量 i 中。猜测执行实质上对操作 3 和 4 做了重排序, 问题在于这时候, a 的值还没被线程 A 赋值。

当操作 1 和操作 2 重排序, 操作 3 和操作 4 重排序时, 可能会产生什么效果?   
操作 1 和操作 2 做了重排序。程序执行时, 线程 A 首先写标记变量 flag, 随后线程 B 读这个变量。由于条件判断为真, 线程 B 将读取变量 a。  
此时, 变量 a 还没有被线程 A 写入, 这时就会发生错误！

所以在多线程程序中, 对存在控制依赖的操作重排序, 可能会改变程序的执行结果。

#### 4.5.3.3 禁止重排序

通过上面的分析, 重排序可能导致线程安全的问题。所以对于重排序在编译器做了一些限制
> 1. 针对编译器重排序, JMM 的编译器重排序规则会禁止一些特定类型的编译器重排序
> 2. 针对处理器重排序, 编译器在生成指令序列的时候会通过插入**内存屏障指令**来禁止某些特殊的处理器重排序

当然重排序不是随意的, 只有在数据没有任何依赖性时, 才可能发生重排序

```java
// A
double pai = 3.14;
// B
double r = 1;
//
double area = pai * r * r;
```
上面是计算圆面积的代码, 代码 A, B 之间没有任何的关联, 所以 2 者之间可以重排序。  
也可以说 A 和 B 之间没有**数据依赖性**, 具体的定义为**如果两个操作访问同一个变量, 且这两个操作有一个为写操作, 此时这两个操作就存在数据依赖性**。  
这里可以分为 3 种情况: 读后写 / 写后读 / 写后写, 这 3 种情况, 无论哪一种发生了重排序, 最终执行结果会存在影响。

最终的结论为 **编译器和处理器在重排序时, 会遵守数据依赖性, 编译器和处理器不会改变存在数据依赖性关系的两个操作的执行顺序**。

#### 4.5.3.3 as-if-serial

as-if-serial 是一个和重排序相关的一个语义, 器内容大体如下:   
不管怎么重排序, (单线程) 程序的执行结果不能被改变。 编译器, runtime 和处理器都必须遵守这个语义。  

为了遵守 as-if-serial 语义, 编译器和处理器不会对存在数据依赖关系的操作做重排序, 因为这种重排序会改变执行结果。  
但是, 如果操作之间不存在数据依赖关系, 这些操作就可能被编译器和处理器重排序。  

**as-if-serial** 语义把单线程程序保护了起来。遵守 as-if-serial 语义的编译器, runtime 和处理器可以让我们感觉到: **单线程程序看起来是按程序的顺序来执行的**。  
as-if-serial 语义使单线程程序员无需担心重排序会干扰他们, 也无需担心内存可见性问题。  

#### 4.5.3.4 内存屏障 (Memory Barrier)

Java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序, 从而让程序按我们预想的流程去执行
> 1. 保证特定操作的执行顺序
> 2. 影响某些数据 (或则是某条指令的执行结果) 的内存可见性

编译器和 CPU 能够重排序指令, 保证最终相同的结果前提, 尝试优化性能。  
插入一条 Memory Barrier 会告诉编译器和 CPU: 不管什么指令都不能和这条 Memory Barrier 指令重排序。

Memory Barrier 所做的另外一件事是强制刷出各种 CPU Cache, 如一个 Write-Barrier (写入屏障) 将刷出所有在 Barrier 之前写入 cache 的数据。  
因此, 任何 CPU 上的线程都能读取到这些数据的最新版本。

JMM 把内存屏障指令分为4类:

| 屏障类型| 说明 | 实例 |
| :-: | :-: | :-: |
| LoadLoadBarriers| Load1; LoadLoadBarriers; Load2 | 确保 Load1 数据的读取在 load2 及后续指令的读取之前 |
| StoreStoreBarriers | Store1; StoreStoreBarriers; Store2; | 确保 Store1 数据的写入 (刷新到主内存) 在 Store2 及后续指令的读取之前 |
| LoadStoreBarriers| Load1; LoadStoreBarriers; Store2; | 确保 Load1 数据的读取在 Store2 及后续指令的写入之前 |
| StoreLoadBarriers | Store1; StoreLoadBarriers; Load2; | 确保 Store2 数据的写入在 Load2 及后续指令的读取之前 |

StoreLoad Barriers 是一个 "全能型" 的屏障, 它同时具有其他 3 个屏障的效果。现代的多处理器大多支持该屏障 (其他类型的屏障不一定被所有处理器支持) 。

## 4.6 Happens-Before

在上面的分析中, 涉及了大量的底层知识, 如果在编程中需要考虑这么多底层的知识, 那么对于编写程序的人的负担是很大的。  
因此, JMM 为程序员在提供 Happens-Before 的概念来阐述操作之间的内存可见性。 为程序员屏蔽了底层相关的内容, 完全可以根据规则去推论跨线程的内存可见性问题, 而不用再去理解底层重排序的规则。

JMM 这么做的原因是: 程序员对于这两个操作是否真的被重排序并不关心, 程序员关心的是程序执行时的语义不能被改变 (即执行结果不能被改变)。  
因此, Happens-Before 关系本质上和 as-if-serial 语义是一回事。  
as-if-serial 语义保证单线程内程序的执行结果不被改变, 而 Happens-Before 关系保证正确同步的多线程程序的执行结果不被改变。

### 4.6.1 定义
> 1. 如果一个操作 Happens-Before 另一个操作, 那么第一个操作的执行结果将对第二个操作可见, 而且第一个操作的执行顺序排在第二个操作之前
> 2. 两个操作之间存在 Happens-Before 关系, 并不意味着 Java 平台的具体实现必须要按照 Happens-Before 关系指定的顺序来执行。如果重排序之后的执行结果, 与按 Happens-Before 关系来执行的结果一致, 那么这种重排序并不非法 (也就是说, JMM 允许这种重排序) 

第一条是 JMM 对程序员的保证。如果 A Happens-Before B，那么 JMM 将向程序员保证 —— A 操作的结果将对 B 可见, 且 A 的执行顺序排在 B 之前。

第二条是 JMM 对编译器和处理器重排序的约束原则。 JMM 允许，两个操作之间存在 Happens-Before 关系，不要求 Java 平台的具体实现必须要按照 Happens-Before 关系指定的顺序来执行。如果重排序之后的执行结果，与按 Happens-Before 关系来执行的结果一致，那么这种重排序是允许的。

### 4.6.2 as-if-serial VS Happens-Before

> 1. as-if-serial 语义保证单线程内程序的执行结果不被改变，Happens-Before 关系保证正确同步的多线程程序的执行结果不被改变
> 2. as-if-serial 语义给编写单线程程序的程序员创造了一个感觉：单线程程序是按程序的顺序来执行的。Happens-Before 关系给编写正确同步的多线程程序的程序员创造了一个感觉：正确同步的多线程程序是按 Happens-Before 指定的顺序来执行的。
> 3. as-if-serial 语义和 Happens-Before 这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。  

### 4.6.3 具体的规则

**程序顺序规则 (Program Order Rule)**: 一个线程中的每个操作，Happens-Before 于该线程中的任意后续操作。










